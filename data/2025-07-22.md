<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 141]
- [cs.CL](#cs.CL) [Total: 86]
- [cs.RO](#cs.RO) [Total: 43]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Comparative Analysis of Algorithms for the Fitting of Tessellations to 3D Image Data](https://arxiv.org/abs/2507.14268)
*Andreas Alpers,Orkun Furat,Christian Jung,Matthias Neumann,Claudia Redenbach,Aigerim Saken,Volker Schmidt*

Main category: cs.CV

TL;DR: 比较分析用于拟合3D图像数据的算法策略，评估不同优化方法在生成近似晶粒结构时的性能。


<details>
  <summary>Details</summary>
Motivation: 研究如何优化拟合3D图像数据中的材料结构（如多晶体和泡沫），以生成更准确的模型。

Method: 比较线性/非线性规划、随机优化（交叉熵法）和梯度下降等方法，生成Voronoi、Laguerre和广义平衡功率图（GBPDs）。

Result: 评估了不同方法在体积、表面积和拓扑差异上的拟合质量，揭示了模型复杂度、优化复杂度和近似质量之间的权衡。

Conclusion: 为基于数据特征和应用需求选择合适方法提供了指导。

Abstract: This paper presents a comparative analysis of algorithmic strategies for
fitting tessellation models to 3D image data of materials such as polycrystals
and foams. In this steadily advancing field, we review and assess
optimization-based methods -- including linear and nonlinear programming,
stochastic optimization via the cross-entropy method, and gradient descent --
for generating Voronoi, Laguerre, and generalized balanced power diagrams
(GBPDs) that approximate voxelbased grain structures. The quality of fit is
evaluated on real-world datasets using discrepancy measures that quantify
differences in grain volume, surface area, and topology. Our results highlight
trade-offs between model complexity, the complexity of the optimization
routines involved, and the quality of approximation, providing guidance for
selecting appropriate methods based on data characteristics and application
needs.

</details>


### [2] [Semantic Segmentation based Scene Understanding in Autonomous Vehicles](https://arxiv.org/abs/2507.14303)
*Ehsan Rassekh*

Main category: cs.CV

TL;DR: 论文提出几种高效模型用于语义分割的场景理解，使用BDD100k数据集，并探讨不同Backbone对模型性能的影响。结果表明，选择合适的Backbone对语义分割性能至关重要。


<details>
  <summary>Details</summary>
Motivation: AI和深度学习在复杂任务中表现优异，尤其在自动驾驶领域。研究旨在通过语义分割提升场景理解能力。

Method: 提出多种高效模型，采用不同Backbone作为编码器，使用BDD100k数据集进行实验。

Result: 实验表明，Backbone的选择显著影响语义分割性能，模型在准确性、平均IoU和损失函数上均有提升。

Conclusion: 研究证实了Backbone选择对语义分割的重要性，为自动驾驶等领域的场景理解提供了有效方法。

Abstract: In recent years, the concept of artificial intelligence (AI) has become a
prominent keyword because it is promising in solving complex tasks. The need
for human expertise in specific areas may no longer be needed because machines
have achieved successful results using artificial intelligence and can make the
right decisions in critical situations. This process is possible with the help
of deep learning (DL), one of the most popular artificial intelligence
technologies. One of the areas in which the use of DL is used is in the
development of self-driving cars, which is very effective and important. In
this work, we propose several efficient models to investigate scene
understanding through semantic segmentation. We use the BDD100k dataset to
investigate these models. Another contribution of this work is the usage of
several Backbones as encoders for models. The obtained results show that
choosing the appropriate backbone has a great effect on the performance of the
model for semantic segmentation. Better performance in semantic segmentation
allows us to understand better the scene and the environment around the agent.
In the end, we analyze and evaluate the proposed models in terms of accuracy,
mean IoU, and loss function, and the results show that these metrics are
improved.

</details>


### [3] [CLIPTTA: Robust Contrastive Vision-Language Test-Time Adaptation](https://arxiv.org/abs/2507.14312)
*Marc Lafon,Gustavo Adolfo Vargas Hakim,Clément Rambour,Christian Desrosier,Nicolas Thome*

Main category: cs.CV

TL;DR: CLIPTTA是一种基于梯度的测试时适应方法，针对视觉语言模型（VLMs），通过软对比损失改善分布偏移下的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于熵最小化的测试时适应方法（TTA）与VLMs的对比训练目标不一致，导致性能受限和伪标签漂移等问题。

Method: 提出CLIPTTA，利用与CLIP预训练目标一致的软对比损失，并通过理论分析证明其梯度设计可避免崩溃。扩展至开放集场景，使用OCE损失提升OOD检测。

Result: 在75个数据集上评估，CLIPTTA表现优于基于熵的方法，并在许多数据集上超越现有TTA方法，性能更稳定。

Conclusion: CLIPTTA通过对齐预训练目标的损失函数，显著提升了VLMs在分布偏移下的适应能力。

Abstract: Vision-language models (VLMs) like CLIP exhibit strong zero-shot capabilities
but often fail to generalize under distribution shifts. Test-time adaptation
(TTA) allows models to update at inference time without labeled data, typically
via entropy minimization. However, this objective is fundamentally misaligned
with the contrastive image-text training of VLMs, limiting adaptation
performance and introducing failure modes such as pseudo-label drift and class
collapse. We propose CLIPTTA, a new gradient-based TTA method for
vision-language models that leverages a soft contrastive loss aligned with
CLIP's pre-training objective. We provide a theoretical analysis of CLIPTTA's
gradients, showing how its batch-aware design mitigates the risk of collapse.
We further extend CLIPTTA to the open-set setting, where both in-distribution
(ID) and out-of-distribution (OOD) samples are encountered, using an Outlier
Contrastive Exposure (OCE) loss to improve OOD detection. Evaluated on 75
datasets spanning diverse distribution shifts, CLIPTTA consistently outperforms
entropy-based objectives and is highly competitive with state-of-the-art TTA
methods, outperforming them on a large number of datasets and exhibiting more
stable performance across diverse shifts.

</details>


### [4] [A Hidden Stumbling Block in Generalized Category Discovery: Distracted Attention](https://arxiv.org/abs/2507.14315)
*Qiyu Xu,Zhanxuan Hu,Yu Duan,Ercheng Pei,Yonghang Tai*

Main category: cs.CV

TL;DR: 论文提出了一种名为注意力聚焦（AF）的机制，通过剪除非信息性标记来解决广义类别发现（GCD）中的注意力分散问题，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有GCD方法在处理未标记数据时，模型容易关注任务无关的背景区域，导致特征提取不理想。

Method: AF由两个组件组成：标记重要性度量（TIME）和多尺度标记自适应剪枝（TAP），通过剪除非信息性标记来优化注意力。

Result: AF在SimGCD方法中实现了高达15.4%的性能提升，且计算开销极小。

Conclusion: AF是一种轻量级、即插即用的模块，可无缝集成到现有GCD方法中，显著提升性能。

Abstract: Generalized Category Discovery (GCD) aims to classify unlabeled data from
both known and unknown categories by leveraging knowledge from labeled known
categories. While existing methods have made notable progress, they often
overlook a hidden stumbling block in GCD: distracted attention. Specifically,
when processing unlabeled data, models tend to focus not only on key objects in
the image but also on task-irrelevant background regions, leading to suboptimal
feature extraction. To remove this stumbling block, we propose Attention
Focusing (AF), an adaptive mechanism designed to sharpen the model's focus by
pruning non-informative tokens. AF consists of two simple yet effective
components: Token Importance Measurement (TIME) and Token Adaptive Pruning
(TAP), working in a cascade. TIME quantifies token importance across multiple
scales, while TAP prunes non-informative tokens by utilizing the multi-scale
importance scores provided by TIME. AF is a lightweight, plug-and-play module
that integrates seamlessly into existing GCD methods with minimal computational
overhead. When incorporated into one prominent GCD method, SimGCD, AF achieves
up to 15.4% performance improvement over the baseline with minimal
computational overhead. The implementation code is provided in
https://github.com/Afleve/AFGCD.

</details>


### [5] [Hallucination Score: Towards Mitigating Hallucinations in Generative Image Super-Resolution](https://arxiv.org/abs/2507.14367)
*Weiming Ren,Raghav Goyal,Zhiming Hu,Tristan Ty Aumentado-Armstrong,Iqbal Mohomed,Alex Levinshtein*

Main category: cs.CV

TL;DR: 生成超分辨率（GSR）在感知图像质量方面表现优异，但存在与低分辨率图像（LRI）或真实图像（GTI）不匹配的幻觉问题。本文提出了一种基于多模态大语言模型（MLLM）的“幻觉评分”（HS）方法，并结合深度特征距离优化GSR模型以减少幻觉。


<details>
  <summary>Details</summary>
Motivation: GSR模型在感知质量上表现优异，但生成的细节可能与LRI或GTI不匹配，导致幻觉问题。这一问题未被充分研究，限制了GSR的实际应用。

Method: 利用MLLM构建提示，评估幻觉视觉元素并生成HS；发现某些深度特征距离与HS强相关，提出将其作为可微分奖励函数优化GSR模型。

Result: HS与人类评估高度一致，并为超分辨率模型提供了补充性见解；深度特征距离与HS强相关。

Conclusion: 通过HS和深度特征距离优化GSR模型，可以有效减少幻觉问题，提升模型性能。

Abstract: Generative super-resolution (GSR) currently sets the state-of-the-art in
terms of perceptual image quality, overcoming the "regression-to-the-mean" blur
of prior non-generative models. However, from a human perspective, such models
do not fully conform to the optimal balance between quality and fidelity.
Instead, a different class of artifacts, in which generated details fail to
perceptually match the low resolution image (LRI) or ground-truth image (GTI),
is a critical but under studied issue in GSR, limiting its practical
deployments. In this work, we focus on measuring, analyzing, and mitigating
these artifacts (i.e., "hallucinations"). We observe that hallucinations are
not well-characterized with existing image metrics or quality models, as they
are orthogonal to both exact fidelity and no-reference quality. Instead, we
take advantage of a multimodal large language model (MLLM) by constructing a
prompt that assesses hallucinatory visual elements and generates a
"Hallucination Score" (HS). We find that our HS is closely aligned with human
evaluations, and also provides complementary insights to prior image metrics
used for super-resolution (SR) models. In addition, we find certain deep
feature distances have strong correlations with HS. We therefore propose to
align the GSR models by using such features as differentiable reward functions
to mitigate hallucinations.

</details>


### [6] [DUSTrack: Semi-automated point tracking in ultrasound videos](https://arxiv.org/abs/2507.14368)
*Praneeth Namburi,Roger Pallarès-López,Jessica Rosendorf,Duarte Folgado,Brian W. Anthony*

Main category: cs.CV

TL;DR: DUSTrack是一个结合深度学习和光流的半自动化工具包，用于B型超声视频中的点跟踪，解决了噪声和运动模糊等问题。


<details>
  <summary>Details</summary>
Motivation: B型超声中组织运动跟踪因噪声和低对比度而困难，需要一种通用工具来量化组织动态。

Method: 结合深度学习和光流，提供图形界面生成训练数据，并采用新型光流滤波技术减少噪声。

Result: DUSTrack在精度上优于零样本跟踪器，与专用方法相当，适用于多种应用场景。

Conclusion: DUSTrack是一个开源工具，为临床和生物力学研究提供了强大的组织运动量化框架。

Abstract: Ultrasound technology enables safe, non-invasive imaging of dynamic tissue
behavior, making it a valuable tool in medicine, biomechanics, and sports
science. However, accurately tracking tissue motion in B-mode ultrasound
remains challenging due to speckle noise, low edge contrast, and out-of-plane
movement. These challenges complicate the task of tracking anatomical landmarks
over time, which is essential for quantifying tissue dynamics in many clinical
and research applications. This manuscript introduces DUSTrack (Deep learning
and optical flow-based toolkit for UltraSound Tracking), a semi-automated
framework for tracking arbitrary points in B-mode ultrasound videos. We combine
deep learning with optical flow to deliver high-quality and robust tracking
across diverse anatomical structures and motion patterns. The toolkit includes
a graphical user interface that streamlines the generation of high-quality
training data and supports iterative model refinement. It also implements a
novel optical-flow-based filtering technique that reduces high-frequency
frame-to-frame noise while preserving rapid tissue motion. DUSTrack
demonstrates superior accuracy compared to contemporary zero-shot point
trackers and performs on par with specialized methods, establishing its
potential as a general and foundational tool for clinical and biomechanical
research. We demonstrate DUSTrack's versatility through three use cases:
cardiac wall motion tracking in echocardiograms, muscle deformation analysis
during reaching tasks, and fascicle tracking during ankle plantarflexion. As an
open-source solution, DUSTrack offers a powerful, flexible framework for point
tracking to quantify tissue motion from ultrasound videos. DUSTrack is
available at https://github.com/praneethnamburi/DUSTrack.

</details>


### [7] [CRAFT: A Neuro-Symbolic Framework for Visual Functional Affordance Grounding](https://arxiv.org/abs/2507.14426)
*Zhou Chen,Joe Lin,Sathyanarayanan N. Aakur*

Main category: cs.CV

TL;DR: CRAFT是一个神经符号框架，用于可解释的affordance grounding，通过结合ConceptNet和语言模型的常识先验与CLIP的视觉证据，提升场景理解的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 解决场景中对象与动作关联的可解释性问题，提升场景理解的鲁棒性和可信度。

Method: 整合ConceptNet和语言模型的常识先验与CLIP的视觉证据，通过基于能量的推理循环迭代优化预测。

Result: 在多对象、无标签设置下，CRAFT提高了准确性并增强了可解释性。

Conclusion: CRAFT为鲁棒且可信的场景理解提供了新方向。

Abstract: We introduce CRAFT, a neuro-symbolic framework for interpretable affordance
grounding, which identifies the objects in a scene that enable a given action
(e.g., "cut"). CRAFT integrates structured commonsense priors from ConceptNet
and language models with visual evidence from CLIP, using an energy-based
reasoning loop to refine predictions iteratively. This process yields
transparent, goal-driven decisions to ground symbolic and perceptual
structures. Experiments in multi-object, label-free settings demonstrate that
CRAFT enhances accuracy while improving interpretability, providing a step
toward robust and trustworthy scene understanding.

</details>


### [8] [Adaptive 3D Gaussian Splatting Video Streaming](https://arxiv.org/abs/2507.14432)
*Han Gong,Qiyue Li,Zhi Liu,Hao Zhou,Peng Yuan Zhou,Zhu Li,Jie Li*

Main category: cs.CV

TL;DR: 提出了一种基于高斯变形场的3DGS视频流媒体框架，通过混合显著性分块和差异化质量建模，实现了高效压缩和带宽适应，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 3DGS视频因其数据量大和传输复杂性高，对流媒体提出了挑战，因此需要一种高效的压缩和传输方法。

Method: 设计了基于高斯变形场的3DGS视频构建方法，结合混合显著性分块和差异化质量建模，优化压缩和传输。

Result: 实验表明，该方法在视频质量、压缩效率和传输速率上均优于现有方法。

Conclusion: 提出的框架有效解决了3DGS视频流媒体的挑战，具有实际应用潜力。

Abstract: The advent of 3D Gaussian splatting (3DGS) has significantly enhanced the
quality of volumetric video representation. Meanwhile, in contrast to
conventional volumetric video, 3DGS video poses significant challenges for
streaming due to its substantially larger data volume and the heightened
complexity involved in compression and transmission. To address these issues,
we introduce an innovative framework for 3DGS volumetric video streaming.
Specifically, we design a 3DGS video construction method based on the Gaussian
deformation field. By employing hybrid saliency tiling and differentiated
quality modeling of 3DGS video, we achieve efficient data compression and
adaptation to bandwidth fluctuations while ensuring high transmission quality.
Then we build a complete 3DGS video streaming system and validate the
transmission performance. Through experimental evaluation, our method
demonstrated superiority over existing approaches in various aspects, including
video quality, compression effectiveness, and transmission rate.

</details>


### [9] [IRGPT: Understanding Real-world Infrared Image with Bi-cross-modal Curriculum on Large-scale Benchmark](https://arxiv.org/abs/2507.14449)
*Zhe Cao,Jin Zhang,Ruiheng Zhang*

Main category: cs.CV

TL;DR: IRGPT是首个针对真实红外图像的多模态大语言模型，基于26万真实红外-文本对数据集（IR-TD），通过双向跨模态课程迁移学习策略，在9项任务中达到最优性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法依赖合成红外图像导致无法捕捉红外模态独特特性的问题。

Method: 构建大规模真实红外-文本对数据集（IR-TD），并提出双向跨模态课程迁移学习策略。

Result: 在9项任务中表现优于现有方法，包括识别和定位等。

Conclusion: IRGPT通过真实数据集和迁移学习策略，显著提升了红外图像的多模态处理能力。

Abstract: Real-world infrared imagery presents unique challenges for vision-language
models due to the scarcity of aligned text data and domain-specific
characteristics. Although existing methods have advanced the field, their
reliance on synthetic infrared images generated through style transfer from
visible images, which limits their ability to capture the unique
characteristics of the infrared modality. To address this, we propose IRGPT,
the first multi-modal large language model for real-world infrared images,
built upon a large-scale InfraRed-Text Dataset (IR-TD) comprising over 260K
authentic image-text pairs. The proposed IR-TD dataset contains real infrared
images paired with meticulously handcrafted texts, where the initial drafts
originated from two complementary processes: (1) LLM-generated descriptions of
visible images, and (2) rule-based descriptions of annotations. Furthermore, we
introduce a bi-cross-modal curriculum transfer learning strategy that
systematically transfers knowledge from visible to infrared domains by
considering the difficulty scores of both infrared-visible and infrared-text.
Evaluated on a benchmark of 9 tasks (e.g., recognition, grounding), IRGPT
achieves state-of-the-art performance even compared with larger-scale models.

</details>


### [10] [GPI-Net: Gestalt-Guided Parallel Interaction Network via Orthogonal Geometric Consistency for Robust Point Cloud Registration](https://arxiv.org/abs/2507.14452)
*Weikang Gu,Mingyue Han,Li Xue,Heng Dong,Changcai Yang,Riqing Chen,Lifang Wei*

Main category: cs.CV

TL;DR: 提出了一种基于Gestalt原则的并行交互网络（GPI-Net），用于点云配准中高质量对应关系的识别，通过正交几何一致性优化局部与全局特征的融合。


<details>
  <summary>Details</summary>
Motivation: 点云配准中高质量对应关系的识别面临局部与全局特征融合的挑战，Gestalt原则为分析这种关系提供了优势。

Method: 设计了正交集成策略减少冗余信息，引入Gestalt特征注意力（GFA）块和双路径多粒度并行交互（DMG）块，优化特征交互。

Result: 在多个挑战性任务上的实验表明，GPI-Net优于现有方法。

Conclusion: GPI-Net通过Gestalt原则和并行交互机制，显著提升了点云配准中对应关系的识别质量。

Abstract: The accurate identification of high-quality correspondences is a prerequisite
task in feature-based point cloud registration. However, it is extremely
challenging to handle the fusion of local and global features due to feature
redundancy and complex spatial relationships. Given that Gestalt principles
provide key advantages in analyzing local and global relationships, we propose
a novel Gestalt-guided Parallel Interaction Network via orthogonal geometric
consistency (GPI-Net) in this paper. It utilizes Gestalt principles to
facilitate complementary communication between local and global information.
Specifically, we introduce an orthogonal integration strategy to optimally
reduce redundant information and generate a more compact global structure for
high-quality correspondences. To capture geometric features in correspondences,
we leverage a Gestalt Feature Attention (GFA) block through a hybrid
utilization of self-attention and cross-attention mechanisms. Furthermore, to
facilitate the integration of local detail information into the global
structure, we design an innovative Dual-path Multi-Granularity parallel
interaction aggregation (DMG) block to promote information exchange across
different granularities. Extensive experiments on various challenging tasks
demonstrate the superior performance of our proposed GPI-Net in comparison to
existing methods. The code will be released at https://github.com/gwk/GPI-Net.

</details>


### [11] [Adaptive 3D Gaussian Splatting Video Streaming: Visual Saliency-Aware Tiling and Meta-Learning-Based Bitrate Adaptation](https://arxiv.org/abs/2507.14454)
*Han Gong,Qiyue Li,Jie Li,Zhi Liu*

Main category: cs.CV

TL;DR: 本文提出了一种自适应3D高斯溅射视频（3DGS）流媒体解决方案，包括基于显著性的分块技术、质量评估框架和基于元学习的比特率自适应算法，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 3DGS流媒体因其沉浸式体验成为研究热点，但仍面临分块、质量评估和比特率自适应等挑战。

Method: 提出自适应3DGS分块技术（结合显著性和时空特征）、质量评估框架（联合评估3DGS流媒体中的空间域退化和2D渲染质量）和基于元学习的比特率自适应算法。

Result: 实验表明，所提方法显著优于现有技术。

Conclusion: 本文为3DGS流媒体的关键挑战提供了全面解决方案，性能优越。

Abstract: 3D Gaussian splatting video (3DGS) streaming has recently emerged as a
research hotspot in both academia and industry, owing to its impressive ability
to deliver immersive 3D video experiences. However, research in this area is
still in its early stages, and several fundamental challenges, such as tiling,
quality assessment, and bitrate adaptation, require further investigation. In
this paper, we tackle these challenges by proposing a comprehensive set of
solutions. Specifically, we propose an adaptive 3DGS tiling technique guided by
saliency analysis, which integrates both spatial and temporal features. Each
tile is encoded into versions possessing dedicated deformation fields and
multiple quality levels for adaptive selection. We also introduce a novel
quality assessment framework for 3DGS video that jointly evaluates
spatial-domain degradation in 3DGS representations during streaming and the
quality of the resulting 2D rendered images. Additionally, we develop a
meta-learning-based adaptive bitrate algorithm specifically tailored for 3DGS
video streaming, achieving optimal performance across varying network
conditions. Extensive experiments demonstrate that our proposed approaches
significantly outperform state-of-the-art methods.

</details>


### [12] [GEMINUS: Dual-aware Global and Scene-Adaptive Mixture-of-Experts for End-to-End Autonomous Driving](https://arxiv.org/abs/2507.14456)
*Chi Wan,Yixin Cui,Jiatong Du,Shuo Yang,Yulong Bai,Yanjun Huang*

Main category: cs.CV

TL;DR: GEMINUS提出了一种混合专家框架，结合全局专家和场景自适应专家，通过双感知路由器实现自适应和鲁棒的自动驾驶性能。


<details>
  <summary>Details</summary>
Motivation: 现有单模式规划方法难以处理多样化场景，需要一种能适应复杂交通环境的自适应框架。

Method: GEMINUS框架包括全局专家、场景自适应专家组和双感知路由器，动态激活专家模块。

Result: 在Bench2Drive基准测试中表现优异，驾驶分数和成功率均达到SOTA，仅使用单目视觉输入。

Conclusion: GEMINUS通过混合专家框架显著提升了自动驾驶的适应性和鲁棒性。

Abstract: End-to-end autonomous driving requires adaptive and robust handling of
complex and diverse traffic environments. However, prevalent single-mode
planning methods attempt to learn an overall policy while struggling to acquire
diversified driving skills to handle diverse scenarios. Therefore, this paper
proposes GEMINUS, a Mixture-of-Experts end-to-end autonomous driving framework
featuring a Global Expert, a Scene-Adaptive Experts Group, and equipped with a
Dual-aware Router. Specifically, the Global Expert is trained on the overall
dataset, possessing robust performance. The Scene-Adaptive Experts are trained
on corresponding scene subsets, achieving adaptive performance. The Dual-aware
Router simultaneously considers scenario-level features and routing uncertainty
to dynamically activate expert modules. Through the effective coupling of the
Global Expert and the Scene-Adaptive Experts Group via the Dual-aware Router,
GEMINUS achieves adaptive and robust performance in diverse scenarios. GEMINUS
outperforms existing methods in the Bench2Drive closed-loop benchmark and
achieves state-of-the-art performance in Driving Score and Success Rate, even
with only monocular vision input. Furthermore, ablation studies demonstrate
significant improvements over the original single-expert baseline: 7.67% in
Driving Score, 22.06% in Success Rate, and 19.41% in MultiAbility-Mean. The
code will be available at https://github.com/newbrains1/GEMINUS.

</details>


### [13] [VisGuard: Securing Visualization Dissemination through Tamper-Resistant Data Retrieval](https://arxiv.org/abs/2507.14459)
*Huayuan Ye,Juntong Chen,Shenzhuo Zhang,Yipeng Zhang,Changbo Wang,Chenhui Li*

Main category: cs.CV

TL;DR: VisGuard是一种抗篡改的可视化图像数据检索框架，通过嵌入可恢复的元数据链接，解决了现有方法在图像篡改时失效的问题。


<details>
  <summary>Details</summary>
Motivation: 现有可视化图像数据检索方法在图像被裁剪或编辑时易失效，导致关键信息丢失。

Method: VisGuard采用重复数据平铺、可逆信息广播和基于锚点的裁剪定位技术，增强嵌入数据的鲁棒性。

Result: 实验表明，VisGuard在数据检索准确性、嵌入容量和抗篡改安全性方面表现优异。

Conclusion: VisGuard能有效保护和促进可视化传播及信息传递。

Abstract: The dissemination of visualizations is primarily in the form of raster
images, which often results in the loss of critical information such as source
code, interactive features, and metadata. While previous methods have proposed
embedding metadata into images to facilitate Visualization Image Data Retrieval
(VIDR), most existing methods lack practicability since they are fragile to
common image tampering during online distribution such as cropping and editing.
To address this issue, we propose VisGuard, a tamper-resistant VIDR framework
that reliably embeds metadata link into visualization images. The embedded data
link remains recoverable even after substantial tampering upon images. We
propose several techniques to enhance robustness, including repetitive data
tiling, invertible information broadcasting, and an anchor-based scheme for
crop localization. VisGuard enables various applications, including interactive
chart reconstruction, tampering detection, and copyright protection. We conduct
comprehensive experiments on VisGuard's superior performance in data retrieval
accuracy, embedding capacity, and security against tampering and steganalysis,
demonstrating VisGuard's competence in facilitating and safeguarding
visualization dissemination and information conveyance.

</details>


### [14] [OptiCorNet: Optimizing Sequence-Based Context Correlation for Visual Place Recognition](https://arxiv.org/abs/2507.14477)
*Zhenyu Li,Tianyi Shang,Pengjie Xu,Ruirui Zhang,Fanchen Kong*

Main category: cs.CV

TL;DR: OptiCorNet提出了一种新颖的序列建模框架，结合空间特征提取和时间差分，通过端到端训练提升动态环境中的视觉地点识别性能。


<details>
  <summary>Details</summary>
Motivation: 动态和感知混淆环境中的视觉地点识别（VPR）是长期定位的核心挑战，现有方法多忽略图像序列的时间连贯性。

Method: OptiCorNet采用轻量级1D卷积编码器和可学习的时间差分算子（DSD），结合LSTM优化和四元组损失函数，直接学习序列级嵌入。

Result: 在多个公开基准测试中，OptiCorNet在季节和视角变化下表现优于现有方法。

Conclusion: OptiCorNet通过端到端学习序列级嵌入，显著提升了动态环境中的地点识别效果。

Abstract: Visual Place Recognition (VPR) in dynamic and perceptually aliased
environments remains a fundamental challenge for long-term localization.
Existing deep learning-based solutions predominantly focus on single-frame
embeddings, neglecting the temporal coherence present in image sequences. This
paper presents OptiCorNet, a novel sequence modeling framework that unifies
spatial feature extraction and temporal differencing into a differentiable,
end-to-end trainable module. Central to our approach is a lightweight 1D
convolutional encoder combined with a learnable differential temporal operator,
termed Differentiable Sequence Delta (DSD), which jointly captures short-term
spatial context and long-range temporal transitions. The DSD module models
directional differences across sequences via a fixed-weight differencing
kernel, followed by an LSTM-based refinement and optional residual projection,
yielding compact, discriminative descriptors robust to viewpoint and appearance
shifts. To further enhance inter-class separability, we incorporate a
quadruplet loss that optimizes both positive alignment and multi-negative
divergence within each batch. Unlike prior VPR methods that treat temporal
aggregation as post-processing, OptiCorNet learns sequence-level embeddings
directly, enabling more effective end-to-end place recognition. Comprehensive
evaluations on multiple public benchmarks demonstrate that our approach
outperforms state-of-the-art baselines under challenging seasonal and viewpoint
variations.

</details>


### [15] [DFQ-ViT: Data-Free Quantization for Vision Transformers without Fine-tuning](https://arxiv.org/abs/2507.14481)
*Yujia Tong,Jingling Yuan,Tian Zhang,Jianquan Liu,Chuang Hu*

Main category: cs.CV

TL;DR: DFQ-ViT提出了一种无需数据的ViT量化方法，通过合成高质量样本和激活校正矩阵，显著提升了量化模型的性能，且无需微调。


<details>
  <summary>Details</summary>
Motivation: 现有方法在合成样本时未能充分平衡全局和局部特征，且量化模型与全精度模型的中间层激活分布差异大，导致性能下降。

Method: 按难度递增顺序合成样本，引入激活校正矩阵以对齐中间层激活分布。

Result: DFQ-ViT性能优于现有DFQ方法，接近真实数据量化模型，如3位量化DeiT-T性能提升4.29%。

Conclusion: DFQ-ViT无需微调，降低计算开销和部署门槛，符合绿色学习原则。

Abstract: Data-Free Quantization (DFQ) enables the quantization of Vision Transformers
(ViTs) without requiring access to data, allowing for the deployment of ViTs on
devices with limited resources. In DFQ, the quantization model must be
calibrated using synthetic samples, making the quality of these synthetic
samples crucial. Existing methods fail to fully capture and balance the global
and local features within the samples, resulting in limited synthetic data
quality. Moreover, we have found that during inference, there is a significant
difference in the distributions of intermediate layer activations between the
quantized and full-precision models. These issues lead to a severe performance
degradation of the quantized model. To address these problems, we propose a
pipeline for Data-Free Quantization for Vision Transformers (DFQ-ViT).
Specifically, we synthesize samples in order of increasing difficulty,
effectively enhancing the quality of synthetic data. During the calibration and
inference stage, we introduce the activation correction matrix for the
quantized model to align the intermediate layer activations with those of the
full-precision model. Extensive experiments demonstrate that DFQ-ViT achieves
remarkable superiority over existing DFQ methods and its performance is on par
with models quantized through real data. For example, the performance of DeiT-T
with 3-bit weights quantization is 4.29% higher than the state-of-the-art. Our
method eliminates the need for fine-tuning, which not only reduces
computational overhead but also lowers the deployment barriers for edge
devices. This characteristic aligns with the principles of Green Learning by
improving energy efficiency and facilitating real-world applications in
resource-constrained environments.

</details>


### [16] [Benefit from Reference: Retrieval-Augmented Cross-modal Point Cloud Completion](https://arxiv.org/abs/2507.14485)
*Hongye Hou,Liu Zhan,Yang Yang*

Main category: cs.CV

TL;DR: 提出了一种基于检索增强的点云补全框架，通过跨模态检索学习结构先验信息，生成精细点云。


<details>
  <summary>Details</summary>
Motivation: 解决不完整点云补全任务中缺乏典型结构特征的挑战，提升生成能力和泛化性。

Method: 设计了结构共享特征编码器（SSFE）和渐进检索增强生成器（PRAG），结合双通道控制门和分层特征融合机制。

Result: 在多个数据集和真实场景中验证了方法的有效性，能够处理稀疏数据和未见类别。

Conclusion: 该方法在生成精细点云和泛化能力方面表现出色。

Abstract: Completing the whole 3D structure based on an incomplete point cloud is a
challenging task, particularly when the residual point cloud lacks typical
structural characteristics. Recent methods based on cross-modal learning
attempt to introduce instance images to aid the structure feature learning.
However, they still focus on each particular input class, limiting their
generation abilities. In this work, we propose a novel retrieval-augmented
point cloud completion framework. The core idea is to incorporate cross-modal
retrieval into completion task to learn structural prior information from
similar reference samples. Specifically, we design a Structural Shared Feature
Encoder (SSFE) to jointly extract cross-modal features and reconstruct
reference features as priors. Benefiting from a dual-channel control gate in
the encoder, relevant structural features in the reference sample are enhanced
and irrelevant information interference is suppressed. In addition, we propose
a Progressive Retrieval-Augmented Generator (PRAG) that employs a hierarchical
feature fusion mechanism to integrate reference prior information with input
features from global to local. Through extensive evaluations on multiple
datasets and real-world scenes, our method shows its effectiveness in
generating fine-grained point clouds, as well as its generalization capability
in handling sparse data and unseen categories.

</details>


### [17] [Efficient Whole Slide Pathology VQA via Token Compression](https://arxiv.org/abs/2507.14497)
*Weimin Lyu,Qingqiao Hu,Kehan Qi,Zhan Shi,Wentao Huang,Saumya Gupta,Chao Chen*

Main category: cs.CV

TL;DR: TCP-LLaVA是一种新型多模态大语言模型，通过令牌压缩技术解决病理学全切片图像（WSI）的视觉问答（VQA）问题，显著降低计算成本并提高准确性。


<details>
  <summary>Details</summary>
Motivation: 病理学全切片图像（WSI）的高分辨率和长上下文长度对多模态大语言模型（MLLM）提出了巨大挑战，现有方法在生成能力和资源消耗方面存在不足。

Method: 提出TCP-LLaVA，通过可训练的压缩令牌聚合视觉和文本信息，仅将压缩后的令牌输入语言模型，减少计算负担。

Result: 在十种TCGA肿瘤亚型的实验中，TCP-LLaVA在VQA准确性上优于现有基线模型，同时大幅降低训练资源消耗。

Conclusion: TCP-LLaVA为WSI的VQA任务提供了一种高效且准确的解决方案，具有实际应用潜力。

Abstract: Whole-slide images (WSIs) in pathology can reach up to 10,000 x 10,000
pixels, posing significant challenges for multimodal large language model
(MLLM) due to long context length and high computational demands. Previous
methods typically focus on patch-level analysis or slide-level classification
using CLIP-based models with multi-instance learning, but they lack the
generative capabilities needed for visual question answering (VQA). More recent
MLLM-based approaches address VQA by feeding thousands of patch tokens directly
into the language model, which leads to excessive resource consumption. To
address these limitations, we propose Token Compression Pathology LLaVA
(TCP-LLaVA), the first MLLM architecture to perform WSI VQA via token
compression. TCP-LLaVA introduces a set of trainable compression tokens that
aggregate visual and textual information through a modality compression module,
inspired by the [CLS] token mechanism in BERT. Only the compressed tokens are
forwarded to the LLM for answer generation, significantly reducing input length
and computational cost. Experiments on ten TCGA tumor subtypes show that
TCP-LLaVA outperforms existing MLLM baselines in VQA accuracy while reducing
training resource consumption by a substantial margin.

</details>


### [18] [Motion Segmentation and Egomotion Estimation from Event-Based Normal Flow](https://arxiv.org/abs/2507.14500)
*Zhiyuan Hua,Dehao Yuan,Cornelia Fermüller*

Main category: cs.CV

TL;DR: 提出了一种基于事件法向流的运动分割和自运动估计框架，适用于神经形态视觉传感器，无需完整光流计算。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖光流或深度估计，而事件数据具有稀疏性和高时间分辨率，结合几何约束可提升性能。

Method: 采用优化流程，包括事件过分割、残差分析分离运动物体、基于运动相似性和时间一致性的层次聚类。

Result: 在EVIMO2v2数据集上验证了准确的分割和平移运动估计，尤其在物体边界表现优异。

Conclusion: 该方法在实时机器人及导航应用中具有显著潜力和可扩展性。

Abstract: This paper introduces a robust framework for motion segmentation and
egomotion estimation using event-based normal flow, tailored specifically for
neuromorphic vision sensors. In contrast to traditional methods that rely
heavily on optical flow or explicit depth estimation, our approach exploits the
sparse, high-temporal-resolution event data and incorporates geometric
constraints between normal flow, scene structure, and inertial measurements.
The proposed optimization-based pipeline iteratively performs event
over-segmentation, isolates independently moving objects via residual analysis,
and refines segmentations using hierarchical clustering informed by motion
similarity and temporal consistency. Experimental results on the EVIMO2v2
dataset validate that our method achieves accurate segmentation and
translational motion estimation without requiring full optical flow
computation. This approach demonstrates significant advantages at object
boundaries and offers considerable potential for scalable, real-time robotic
and navigation applications.

</details>


### [19] [Advances in Feed-Forward 3D Reconstruction and View Synthesis: A Survey](https://arxiv.org/abs/2507.14501)
*Jiahui Zhang,Yuelei Li,Anpei Chen,Muyu Xu,Kunhao Liu,Jianyuan Wang,Xiao-Xiao Long,Hanxue Liang,Zexiang Xu,Hao Su,Christian Theobalt,Christian Rupprecht,Andrea Vedaldi,Hanspeter Pfister,Shijian Lu,Fangneng Zhan*

Main category: cs.CV

TL;DR: 该论文综述了基于前馈方法的3D重建与视图合成技术，分类讨论了不同表示架构，并探讨了其应用与未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 传统3D重建与视图合成方法计算复杂且不适用于实时场景，前馈方法通过深度学习提供了快速且通用的解决方案。

Method: 论文按表示架构（如点云、3D高斯泼溅、NeRF等）分类，并分析了关键任务（如无姿态重建、动态3D重建等）。

Result: 总结了常用数据集、评估协议及在数字人、SLAM等领域的应用，展示了前馈方法的潜力。

Conclusion: 讨论了开放研究挑战与未来方向，强调前馈方法在3D视觉领域的推动作用。

Abstract: 3D reconstruction and view synthesis are foundational problems in computer
vision, graphics, and immersive technologies such as augmented reality (AR),
virtual reality (VR), and digital twins. Traditional methods rely on
computationally intensive iterative optimization in a complex chain, limiting
their applicability in real-world scenarios. Recent advances in feed-forward
approaches, driven by deep learning, have revolutionized this field by enabling
fast and generalizable 3D reconstruction and view synthesis. This survey offers
a comprehensive review of feed-forward techniques for 3D reconstruction and
view synthesis, with a taxonomy according to the underlying representation
architectures including point cloud, 3D Gaussian Splatting (3DGS), Neural
Radiance Fields (NeRF), etc. We examine key tasks such as pose-free
reconstruction, dynamic 3D reconstruction, and 3D-aware image and video
synthesis, highlighting their applications in digital humans, SLAM, robotics,
and beyond. In addition, we review commonly used datasets with detailed
statistics, along with evaluation protocols for various downstream tasks. We
conclude by discussing open research challenges and promising directions for
future work, emphasizing the potential of feed-forward approaches to advance
the state of the art in 3D vision.

</details>


### [20] [DCHM: Depth-Consistent Human Modeling for Multiview Detection](https://arxiv.org/abs/2507.14505)
*Jiahao Ma,Tianyu Wang,Miaomiao Liu,David Ahmedt-Aristizabal,Chuong Nguyen*

Main category: cs.CV

TL;DR: 提出了一种名为DCHM的框架，通过深度一致性建模和多视角融合，在稀疏视角、大规模和拥挤场景中实现精确的行人检测。


<details>
  <summary>Details</summary>
Motivation: 现有方法在行人建模中引入噪声且精度低，依赖昂贵的多视角3D标注，难以泛化到多样化场景。

Method: 采用超像素级高斯泼溅技术，实现全局坐标系中的深度一致性和多视角融合。

Result: 显著减少噪声，优于现有方法，首次在挑战性场景中重建行人并完成多视角分割。

Conclusion: DCHM框架有效解决了行人建模中的噪声问题，无需依赖人工标注，适用于复杂场景。

Abstract: Multiview pedestrian detection typically involves two stages: human modeling
and pedestrian localization. Human modeling represents pedestrians in 3D space
by fusing multiview information, making its quality crucial for detection
accuracy. However, existing methods often introduce noise and have low
precision. While some approaches reduce noise by fitting on costly multiview 3D
annotations, they often struggle to generalize across diverse scenes. To
eliminate reliance on human-labeled annotations and accurately model humans, we
propose Depth-Consistent Human Modeling (DCHM), a framework designed for
consistent depth estimation and multiview fusion in global coordinates.
Specifically, our proposed pipeline with superpixel-wise Gaussian Splatting
achieves multiview depth consistency in sparse-view, large-scaled, and crowded
scenarios, producing precise point clouds for pedestrian localization.
Extensive validations demonstrate that our method significantly reduces noise
during human modeling, outperforming previous state-of-the-art baselines.
Additionally, to our knowledge, DCHM is the first to reconstruct pedestrians
and perform multiview segmentation in such a challenging setting. Code is
available on the \href{https://jiahao-ma.github.io/DCHM/}{project page}.

</details>


### [21] [ArtiMuse: Fine-Grained Image Aesthetics Assessment with Joint Scoring and Expert-Level Understanding](https://arxiv.org/abs/2507.14533)
*Shuo Cao,Nan Ma,Jiayang Li,Xiaohui Li,Lihao Shao,Kaiwen Zhu,Yu Zhou,Yuandong Pu,Jiarui Wu,Jiaquan Wang,Bo Qu,Wenhai Wang,Yu Qiao,Dajuin Yao,Yihao Liu*

Main category: cs.CV

TL;DR: 提出ArtiMuse模型和ArtiMuse-10K数据集，解决多模态图像美学评估中的模态偏差和细粒度属性分解问题。


<details>
  <summary>Details</summary>
Motivation: 教育、艺术创作和AI生成内容的发展对图像美学评估提出更高要求，现有方法存在模态偏差和缺乏细粒度分析。

Method: 开发ArtiMuse模型，结合评分和专家级理解能力；构建ArtiMuse-10K数据集，包含10,000张专家标注图像。

Result: ArtiMuse模型和ArtiMuse-10K数据集填补了现有方法的不足，支持更全面的美学评估。

Conclusion: 公开模型和数据集以推动图像美学评估领域的发展。

Abstract: The rapid advancement of educational applications, artistic creation, and
AI-generated content (AIGC) technologies has substantially increased practical
requirements for comprehensive Image Aesthetics Assessment (IAA), particularly
demanding methods capable of delivering both quantitative scoring and
professional understanding. Multimodal Large Language Model (MLLM)-based IAA
methods demonstrate stronger perceptual and generalization capabilities
compared to traditional approaches, yet they suffer from modality bias
(score-only or text-only) and lack fine-grained attribute decomposition,
thereby failing to support further aesthetic assessment. In this paper, we
present:(1) ArtiMuse, an innovative MLLM-based IAA model with Joint Scoring and
Expert-Level Understanding capabilities; (2) ArtiMuse-10K, the first
expert-curated image aesthetic dataset comprising 10,000 images spanning 5 main
categories and 15 subcategories, each annotated by professional experts with
8-dimensional attributes analysis and a holistic score. Both the model and
dataset will be made public to advance the field.

</details>


### [22] [Real Time Captioning of Sign Language Gestures in Video Meetings](https://arxiv.org/abs/2507.14543)
*Sharanya Mukherjee,Md Hishaam Akhtar,Kannadasan R*

Main category: cs.CV

TL;DR: 提出了一种浏览器扩展，用于在视频会议中将手语自动翻译为字幕，以帮助听障人士与非听障人士沟通。


<details>
  <summary>Details</summary>
Motivation: 解决听障人士与非听障人士之间的沟通障碍，尤其是在疫情期间视频会议成为主要沟通方式的情况下。

Method: 利用包含2000多个单词级ASL视频的大规模数据集，开发浏览器扩展实现手语到字幕的自动翻译。

Result: 通过浏览器扩展实现了手语到字幕的实时翻译，提升了视频会议中听障人士的沟通体验。

Conclusion: 该浏览器扩展有效减少了听障人士与非听障人士之间的沟通障碍，尤其是在视频会议场景中。

Abstract: It has always been a rather tough task to communicate with someone possessing
a hearing impairment. One of the most tested ways to establish such a
communication is through the use of sign based languages. However, not many
people are aware of the smaller intricacies involved with sign language. Sign
language recognition using computer vision aims at eliminating the
communication barrier between deaf-mute and ordinary people so that they can
properly communicate with others. Recently the pandemic has left the whole
world shaken up and has transformed the way we communicate. Video meetings have
become essential for everyone, even people with a hearing disability. In recent
studies, it has been found that people with hearing disabilities prefer to sign
over typing during these video calls. In this paper, we are proposing a browser
extension that will automatically translate sign language to subtitles for
everyone else in the video call. The Large-scale dataset which contains more
than 2000 Word-Level ASL videos, which were performed by over 100 signers will
be used.

</details>


### [23] [Multimodal AI for Gastrointestinal Diagnostics: Tackling VQA in MEDVQA-GI 2025](https://arxiv.org/abs/2507.14544)
*Sujata Gaihre,Amir Thapa Magar,Prasuna Pokharel,Laxmi Tiwari*

Main category: cs.CV

TL;DR: 本文介绍了一种基于Florence模型的医学视觉问答方法，用于胃肠道内窥镜图像，通过领域增强和微调提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决医学视觉问答（VQA）在胃肠道内窥镜领域的挑战，提升临床相关答案的准确性。

Method: 采用Florence多模态基础模型，结合视觉和文本编码器，并应用领域特定的数据增强。

Result: 在KASVIR数据集上微调后，模型在官方指标上表现优异。

Conclusion: 展示了大型多模态模型在医学VQA中的潜力，为未来研究提供了基线。

Abstract: This paper describes our approach to Subtask 1 of the ImageCLEFmed MEDVQA
2025 Challenge, which targets visual question answering (VQA) for
gastrointestinal endoscopy. We adopt the Florence model-a large-scale
multimodal foundation model-as the backbone of our VQA pipeline, pairing a
powerful vision encoder with a text encoder to interpret endoscopic images and
produce clinically relevant answers. To improve generalization, we apply
domain-specific augmentations that preserve medical features while increasing
training diversity. Experiments on the KASVIR dataset show that fine-tuning
Florence yields accurate responses on the official challenge metrics. Our
results highlight the potential of large multimodal models in medical VQA and
provide a strong baseline for future work on explainability, robustness, and
clinical integration. The code is publicly available at:
https://github.com/TiwariLaxuu/VQA-Florence.git

</details>


### [24] [Synthesizing Images on Perceptual Boundaries of ANNs for Uncovering Human Perceptual Variability on Facial Expressions](https://arxiv.org/abs/2507.14549)
*Haotian Deng,Chi Zhang,Chen Wei,Quanying Liu*

Main category: cs.CV

TL;DR: 研究探讨了人工神经网络（ANN）与人类情感感知的个体差异之间的关系，发现ANN分类模糊的刺激同样引发人类感知的不确定性，并通过行为数据微调ANN，实现了与人类感知模式的匹配。


<details>
  <summary>Details</summary>
Motivation: 解决情感认知科学中外部情感刺激与人类内部体验关系的建模问题，特别是探索ANN在模拟个体感知差异方面的潜力。

Method: 引入一种新颖的感知边界采样方法，生成位于ANN决策边界的面部表情刺激，构建varEmotion数据集，并通过大规模人类行为实验验证。

Result: 发现ANN分类模糊的刺激同样导致人类感知的不确定性，通过微调ANN，其预测与人类群体及个体感知模式一致。

Conclusion: 建立了ANN决策边界与人类感知变异性之间的系统性联系，为情感解释的个性化建模提供了新视角。

Abstract: A fundamental challenge in affective cognitive science is to develop models
that accurately capture the relationship between external emotional stimuli and
human internal experiences. While ANNs have demonstrated remarkable accuracy in
facial expression recognition, their ability to model inter-individual
differences in human perception remains underexplored. This study investigates
the phenomenon of high perceptual variability-where individuals exhibit
significant differences in emotion categorization even when viewing the same
stimulus. Inspired by the similarity between ANNs and human perception, we
hypothesize that facial expression samples that are ambiguous for ANN
classifiers also elicit divergent perceptual judgments among human observers.
To examine this hypothesis, we introduce a novel perceptual boundary sampling
method to generate facial expression stimuli that lie along ANN decision
boundaries. These ambiguous samples form the basis of the varEmotion dataset,
constructed through large-scale human behavioral experiments. Our analysis
reveals that these ANN-confusing stimuli also provoke heightened perceptual
uncertainty in human participants, highlighting shared computational principles
in emotion perception. Finally, by fine-tuning ANN representations using
behavioral data, we achieve alignment between ANN predictions and both
group-level and individual-level human perceptual patterns. Our findings
establish a systematic link between ANN decision boundaries and human
perceptual variability, offering new insights into personalized modeling of
emotional interpretation.

</details>


### [25] [Clutter Detection and Removal by Multi-Objective Analysis for Photographic Guidance](https://arxiv.org/abs/2507.14553)
*Xiaoran Wu*

Main category: cs.CV

TL;DR: 开发了一个相机引导系统，帮助用户识别和去除照片中的杂乱内容，提升照片美学质量。


<details>
  <summary>Details</summary>
Motivation: 摄影爱好者常因疏忽或经验不足在照片中留下杂乱内容，影响情感和故事的传达。

Method: 系统通过美学评估算法识别杂乱对象，并提供交互式去除工具，使用生成对抗网络进行图像修复。

Result: 用户研究表明，系统能帮助用户更高效地识别杂乱并提升照片质量。

Conclusion: 该系统通过灵活界面和准确算法，显著提升了用户的摄影体验和作品质量。

Abstract: Clutter in photos is a distraction preventing photographers from conveying
the intended emotions or stories to the audience. Photography amateurs
frequently include clutter in their photos due to unconscious negligence or the
lack of experience in creating a decluttered, aesthetically appealing scene for
shooting. We are thus motivated to develop a camera guidance system that
provides solutions and guidance for clutter identification and removal. We
estimate and visualize the contribution of objects to the overall aesthetics
and content of a photo, based on which users can interactively identify
clutter. Suggestions on getting rid of clutter, as well as a tool that removes
cluttered objects computationally, are provided to guide users to deal with
different kinds of clutter and improve their photographic work. Two technical
novelties underpin interactions in our system: a clutter distinguishment
algorithm with aesthetics evaluations for objects and an iterative image
inpainting algorithm based on generative adversarial nets that reconstructs
missing regions of removed objects for high-resolution images. User studies
demonstrate that our system provides flexible interfaces and accurate
algorithms that allow users to better identify distractions and take higher
quality images within less time.

</details>


### [26] [Descrip3D: Enhancing Large Language Model-based 3D Scene Understanding with Object-Level Text Descriptions](https://arxiv.org/abs/2507.14555)
*Jintang Xue,Ganning Zhao,Jie-En Yao,Hong-En Chen,Yue Hu,Meida Chen,Suya You,C. -C. Jay Kuo*

Main category: cs.CV

TL;DR: Descrip3D是一个通过自然语言编码物体关系的新框架，显著提升了3D场景理解能力。


<details>
  <summary>Details</summary>
Motivation: 当前3D场景-语言模型在理解物体间空间和语义关系方面表现不足，Descrip3D旨在解决这一问题。

Method: Descrip3D通过文本描述增强物体表示，结合嵌入融合和提示级注入的双层次集成方法。

Result: 在五个基准数据集上，Descrip3D均优于基线模型。

Conclusion: 语言引导的关系表示能有效提升复杂室内场景的理解能力。

Abstract: Understanding 3D scenes goes beyond simply recognizing objects; it requires
reasoning about the spatial and semantic relationships between them. Current 3D
scene-language models often struggle with this relational understanding,
particularly when visual embeddings alone do not adequately convey the roles
and interactions of objects. In this paper, we introduce Descrip3D, a novel and
powerful framework that explicitly encodes the relationships between objects
using natural language. Unlike previous methods that rely only on 2D and 3D
embeddings, Descrip3D enhances each object with a textual description that
captures both its intrinsic attributes and contextual relationships. These
relational cues are incorporated into the model through a dual-level
integration: embedding fusion and prompt-level injection. This allows for
unified reasoning across various tasks such as grounding, captioning, and
question answering, all without the need for task-specific heads or additional
supervision. When evaluated on five benchmark datasets, including ScanRefer,
Multi3DRefer, ScanQA, SQA3D, and Scan2Cap, Descrip3D consistently outperforms
strong baseline models, demonstrating the effectiveness of language-guided
relational representation for understanding complex indoor scenes.

</details>


### [27] [LEAD: Exploring Logit Space Evolution for Model Selection](https://arxiv.org/abs/2507.14559)
*Zixuan Hu,Xiaotong Li,Shixiang Tang,Jun Liu,Yichun Hu,Ling-Yu Duan*

Main category: cs.CV

TL;DR: LEAD提出了一种基于网络输出的优化方法，通过ODE建模非线性优化过程，有效预测预训练模型在下游任务中的迁移性能。


<details>
  <summary>Details</summary>
Motivation: 预训练模型数量激增，如何高效选择适合下游任务的模型成为挑战，现有方法未能准确捕捉优化中的非线性动态。

Method: LEAD基于logits提出理论框架，用ODE描述非线性优化过程，并设计类感知分解方法以适应不同类的动态。

Result: 在24个预训练模型和10个下游数据集上的实验表明，LEAD在性能和适应性上表现优异，尤其在低数据场景。

Conclusion: LEAD通过优化目标对齐和非线性建模，单步解决优化差距，为预训练模型选择提供了高效解决方案。

Abstract: The remarkable success of pretrain-then-finetune paradigm has led to a
proliferation of available pre-trained models for vision tasks. This surge
presents a significant challenge in efficiently choosing the most suitable
pre-trained models for downstream tasks. The critical aspect of this challenge
lies in effectively predicting the model transferability by considering the
underlying fine-tuning dynamics. Existing methods often model fine-tuning
dynamics in feature space with linear transformations, which do not precisely
align with the fine-tuning objective and fail to grasp the essential
nonlinearity from optimization. To this end, we present LEAD, a
finetuning-aligned approach based on the network output of logits. LEAD
proposes a theoretical framework to model the optimization process and derives
an ordinary differential equation (ODE) to depict the nonlinear evolution
toward the final logit state. Additionally, we design a class-aware
decomposition method to consider the varying evolution dynamics across classes
and further ensure practical applicability. Integrating the closely aligned
optimization objective and nonlinear modeling capabilities derived from the
differential equation, our method offers a concise solution to effectively
bridge the optimization gap in a single step, bypassing the lengthy fine-tuning
process. The comprehensive experiments on 24 supervised and self-supervised
pre-trained models across 10 downstream datasets demonstrate impressive
performances and showcase its broad adaptability even in low-data scenarios.

</details>


### [28] [Benchmarking GANs, Diffusion Models, and Flow Matching for T1w-to-T2w MRI Translation](https://arxiv.org/abs/2507.14575)
*Andrea Moschetto,Lemuel Puglisi,Alec Sargood,Pierluigi Dell'Acqua,Francesco Guarnera,Sebastiano Battiato,Daniele Ravì*

Main category: cs.CV

TL;DR: 论文比较了GAN、扩散模型和流匹配技术在MRI图像合成中的表现，发现GAN-based Pix2Pix模型在结构保真度和计算效率上优于其他方法。


<details>
  <summary>Details</summary>
Motivation: 减少MRI扫描时间和成本，通过计算合成缺失的模态图像。

Method: 使用GAN、扩散模型和流匹配技术进行T1w到T2w的2D MRI图像翻译，并在三个公开数据集上评估。

Result: GAN-based Pix2Pix模型在结构保真度、图像质量和计算效率上表现最佳。

Conclusion: GAN更适合小数据集和简单任务，流匹配模型可能需要更多数据才能超越GAN。研究为实际MRI工作流程提供了指导。

Abstract: Magnetic Resonance Imaging (MRI) enables the acquisition of multiple image
contrasts, such as T1-weighted (T1w) and T2-weighted (T2w) scans, each offering
distinct diagnostic insights. However, acquiring all desired modalities
increases scan time and cost, motivating research into computational methods
for cross-modal synthesis. To address this, recent approaches aim to synthesize
missing MRI contrasts from those already acquired, reducing acquisition time
while preserving diagnostic quality. Image-to-image (I2I) translation provides
a promising framework for this task. In this paper, we present a comprehensive
benchmark of generative models$\unicode{x2013}$specifically, Generative
Adversarial Networks (GANs), diffusion models, and flow matching (FM)
techniques$\unicode{x2013}$for T1w-to-T2w 2D MRI I2I translation. All
frameworks are implemented with comparable settings and evaluated on three
publicly available MRI datasets of healthy adults. Our quantitative and
qualitative analyses show that the GAN-based Pix2Pix model outperforms
diffusion and FM-based methods in terms of structural fidelity, image quality,
and computational efficiency. Consistent with existing literature, these
results suggest that flow-based models are prone to overfitting on small
datasets and simpler tasks, and may require more data to match or surpass GAN
performance. These findings offer practical guidance for deploying I2I
translation techniques in real-world MRI workflows and highlight promising
directions for future research in cross-modal medical image synthesis. Code and
models are publicly available at
https://github.com/AndreaMoschetto/medical-I2I-benchmark.

</details>


### [29] [Performance comparison of medical image classification systems using TensorFlow Keras, PyTorch, and JAX](https://arxiv.org/abs/2507.14587)
*Merjem Bećirović,Amina Kurtović,Nordin Smajlović,Medina Kapo,Amila Akagić*

Main category: cs.CV

TL;DR: 该论文比较了TensorFlow、PyTorch和JAX三种深度学习框架在BloodMNIST数据集上的性能，重点关注推理时间和分类准确性。


<details>
  <summary>Details</summary>
Motivation: 尽管深度学习在血液图像分析中表现出潜力，但对具体框架的性能分析不足。

Method: 比较三种框架在BloodMNIST数据集上的分类性能，分析推理时间和图像大小的影响。

Result: JAX和PyTorch的分类准确性接近当前基准，性能受图像分辨率和框架优化影响。

Conclusion: JAX和PyTorch在医学图像分类中表现出高效性，适合相关应用。

Abstract: Medical imaging plays a vital role in early disease diagnosis and monitoring.
Specifically, blood microscopy offers valuable insights into blood cell
morphology and the detection of hematological disorders. In recent years, deep
learning-based automated classification systems have demonstrated high
potential in enhancing the accuracy and efficiency of blood image analysis.
However, a detailed performance analysis of specific deep learning frameworks
appears to be lacking. This paper compares the performance of three popular
deep learning frameworks, TensorFlow with Keras, PyTorch, and JAX, in
classifying blood cell images from the publicly available BloodMNIST dataset.
The study primarily focuses on inference time differences, but also
classification performance for different image sizes. The results reveal
variations in performance across frameworks, influenced by factors such as
image resolution and framework-specific optimizations. Classification accuracy
for JAX and PyTorch was comparable to current benchmarks, showcasing the
efficiency of these frameworks for medical image classification.

</details>


### [30] [DiSCO-3D : Discovering and segmenting Sub-Concepts from Open-vocabulary queries in NeRF](https://arxiv.org/abs/2507.14596)
*Doriand Petit,Steve Bourgeois,Vincent Gay-Bellile,Florian Chabot,Loïc Barthe*

Main category: cs.CV

TL;DR: DiSCO-3D是首个解决3D开放词汇子概念发现的方法，结合无监督分割和弱开放词汇指导，在适应场景和用户查询方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统方法仅适应特定任务目标或场景内容，无法同时满足场景和用户查询的需求。DiSCO-3D旨在填补这一空白。

Method: 基于神经场表示，结合无监督分割和弱开放词汇指导。

Result: 在开放词汇子概念发现中表现优异，同时在开放词汇和无监督分割的边缘案例中达到最先进水平。

Conclusion: DiSCO-3D为3D语义分割提供了更灵活的解决方案，适应性强且性能优越。

Abstract: 3D semantic segmentation provides high-level scene understanding for
applications in robotics, autonomous systems, \textit{etc}. Traditional methods
adapt exclusively to either task-specific goals (open-vocabulary segmentation)
or scene content (unsupervised semantic segmentation). We propose DiSCO-3D, the
first method addressing the broader problem of 3D Open-Vocabulary Sub-concepts
Discovery, which aims to provide a 3D semantic segmentation that adapts to both
the scene and user queries. We build DiSCO-3D on Neural Fields representations,
combining unsupervised segmentation with weak open-vocabulary guidance. Our
evaluations demonstrate that DiSCO-3D achieves effective performance in
Open-Vocabulary Sub-concepts Discovery and exhibits state-of-the-art results in
the edge cases of both open-vocabulary and unsupervised segmentation.

</details>


### [31] [Exp-Graph: How Connections Learn Facial Attributes in Graph-based Expression Recognition](https://arxiv.org/abs/2507.14608)
*Nandani Sharma,Dinesh Singh*

Main category: cs.CV

TL;DR: 提出Exp-Graph框架，利用图结构和视觉Transformer增强面部表情识别的准确性，在多个数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 面部表情识别在人机交互等领域至关重要，但面部属性的结构变化需被有效建模以提高识别效果。

Method: 通过图结构建模面部属性关系，结合视觉Transformer和图卷积网络捕捉局部与全局依赖。

Result: 在Oulu-CASIA、eNTERFACE05和AFEW数据集上分别达到98.09%、79.01%和56.39%的准确率。

Conclusion: Exp-Graph在实验室和真实环境中均表现出强大的泛化能力，适用于实际应用。

Abstract: Facial expression recognition is crucial for human-computer interaction
applications such as face animation, video surveillance, affective computing,
medical analysis, etc. Since the structure of facial attributes varies with
facial expressions, incorporating structural information into facial attributes
is essential for facial expression recognition. In this paper, we propose
Exp-Graph, a novel framework designed to represent the structural relationships
among facial attributes using graph-based modeling for facial expression
recognition. For facial attributes graph representation, facial landmarks are
used as the graph's vertices. At the same time, the edges are determined based
on the proximity of the facial landmark and the similarity of the local
appearance of the facial attributes encoded using the vision transformer.
Additionally, graph convolutional networks are utilized to capture and
integrate these structural dependencies into the encoding of facial attributes,
thereby enhancing the accuracy of expression recognition. Thus, Exp-Graph
learns from the facial attribute graphs highly expressive semantic
representations. On the other hand, the vision transformer and graph
convolutional blocks help the framework exploit the local and global
dependencies among the facial attributes that are essential for the recognition
of facial expressions. We conducted comprehensive evaluations of the proposed
Exp-Graph model on three benchmark datasets: Oulu-CASIA, eNTERFACE05, and AFEW.
The model achieved recognition accuracies of 98.09\%, 79.01\%, and 56.39\%,
respectively. These results indicate that Exp-Graph maintains strong
generalization capabilities across both controlled laboratory settings and
real-world, unconstrained environments, underscoring its effectiveness for
practical facial expression recognition applications.

</details>


### [32] [Depthwise-Dilated Convolutional Adapters for Medical Object Tracking and Segmentation Using the Segment Anything Model 2](https://arxiv.org/abs/2507.14613)
*Guoping Xu,Christopher Kabat,You Zhang*

Main category: cs.CV

TL;DR: DD-SAM2是一种高效适配框架，通过Depthwise-Dilated Adapter增强SAM2的多尺度特征提取，适用于医学视频分割与跟踪，性能优越。


<details>
  <summary>Details</summary>
Motivation: 现有医学图像分割方法多为模态特定设计，适应性差，且SAM2在医学视频场景中需要大规模数据集重新训练，计算成本高。

Method: 提出DD-SAM2框架，结合Depthwise-Dilated Adapter，以最小参数量增强多尺度特征提取，实现有限数据下的高效微调。

Result: 在TrackRad2025和EchoNet-Dynamic数据集上分别达到Dice分数0.93和0.97，性能优越。

Conclusion: DD-SAM2首次系统探索了基于适配器的SAM2微调方法，为医学视频分割与跟踪提供了高效解决方案。

Abstract: Recent advances in medical image segmentation have been driven by deep
learning; however, most existing methods remain limited by modality-specific
designs and exhibit poor adaptability to dynamic medical imaging scenarios. The
Segment Anything Model 2 (SAM2) and its related variants, which introduce a
streaming memory mechanism for real-time video segmentation, present new
opportunities for prompt-based, generalizable solutions. Nevertheless, adapting
these models to medical video scenarios typically requires large-scale datasets
for retraining or transfer learning, leading to high computational costs and
the risk of catastrophic forgetting. To address these challenges, we propose
DD-SAM2, an efficient adaptation framework for SAM2 that incorporates a
Depthwise-Dilated Adapter (DD-Adapter) to enhance multi-scale feature
extraction with minimal parameter overhead. This design enables effective
fine-tuning of SAM2 on medical videos with limited training data. Unlike
existing adapter-based methods focused solely on static images, DD-SAM2 fully
exploits SAM2's streaming memory for medical video object tracking and
segmentation. Comprehensive evaluations on TrackRad2025 (tumor segmentation)
and EchoNet-Dynamic (left ventricle tracking) datasets demonstrate superior
performance, achieving Dice scores of 0.93 and 0.97, respectively. To the best
of our knowledge, this work provides an initial attempt at systematically
exploring adapter-based SAM2 fine-tuning for medical video segmentation and
tracking. Code, datasets, and models will be publicly available at
https://github.com/apple1986/DD-SAM2.

</details>


### [33] [BusterX++: Towards Unified Cross-Modal AI-Generated Content Detection and Explanation with MLLM](https://arxiv.org/abs/2507.14632)
*Haiquan Wen,Tianxiao Li,Zhenglin Huang,Yiwei He,Guangliang Cheng*

Main category: cs.CV

TL;DR: BusterX++是一个新型跨模态检测框架，用于识别和解释合成媒体，通过强化学习后训练策略和多阶段训练方法提升性能。GenBuster++是一个跨模态基准数据集，用于全面评估。


<details>
  <summary>Details</summary>
Motivation: 生成式AI的进步增加了虚假信息的风险，现有单模态检测方法无法应对跨模态合成内容。

Method: BusterX++采用强化学习后训练策略，结合多阶段训练、思维奖励和混合推理。

Result: 实验证明BusterX++在性能和泛化能力上表现优异。

Conclusion: BusterX++和GenBuster++为跨模态合成媒体检测提供了有效解决方案。

Abstract: Recent advances in generative AI have dramatically improved image and video
synthesis capabilities, significantly increasing the risk of misinformation
through sophisticated fake content. In response, detection methods have evolved
from traditional approaches to multimodal large language models (MLLMs),
offering enhanced transparency and interpretability in identifying synthetic
media. However, current detection systems remain fundamentally limited by their
single-modality design. These approaches analyze images or videos separately,
making them ineffective against synthetic content that combines multiple media
formats. To address these challenges, we introduce \textbf{BusterX++}, a novel
framework designed specifically for cross-modal detection and explanation of
synthetic media. Our approach incorporates an advanced reinforcement learning
(RL) post-training strategy that eliminates cold-start. Through Multi-stage
Training, Thinking Reward, and Hybrid Reasoning, BusterX++ achieves stable and
substantial performance improvements. To enable comprehensive evaluation, we
also present \textbf{GenBuster++}, a cross-modal benchmark leveraging
state-of-the-art image and video generation techniques. This benchmark
comprises 4,000 images and video clips, meticulously curated by human experts
using a novel filtering methodology to ensure high quality, diversity, and
real-world applicability. Extensive experiments demonstrate the effectiveness
and generalizability of our approach.

</details>


### [34] [Multispectral State-Space Feature Fusion: Bridging Shared and Cross-Parametric Interactions for Object Detection](https://arxiv.org/abs/2507.14643)
*Jifeng Shen,Haibo Zhan,Shaohua Dong,Xin Zuo,Wankou Yang,Haibin Ling*

Main category: cs.CV

TL;DR: MS2Fusion提出了一种基于状态空间模型的双路径参数交互机制，解决了多光谱特征融合中的局部偏好和计算复杂度问题，显著提升了目标检测性能。


<details>
  <summary>Details</summary>
Motivation: 解决多光谱特征融合中过度依赖局部互补特征和计算复杂度与感受野大小的权衡问题。

Method: 采用双路径参数交互机制，分别挖掘互补信息和共享语义特征，并通过状态空间模型统一优化。

Result: 在FLIR、M3FD和LLVIP等基准测试中显著优于现有方法，并在RGB-T语义分割和RGBT显著目标检测中表现出通用性。

Conclusion: MS2Fusion通过双路径设计实现了高效的多光谱特征融合，具有广泛的应用潜力。

Abstract: Modern multispectral feature fusion for object detection faces two critical
limitations: (1) Excessive preference for local complementary features over
cross-modal shared semantics adversely affects generalization performance; and
(2) The trade-off between the receptive field size and computational complexity
present critical bottlenecks for scalable feature modeling. Addressing these
issues, a novel Multispectral State-Space Feature Fusion framework, dubbed
MS2Fusion, is proposed based on the state space model (SSM), achieving
efficient and effective fusion through a dual-path parametric interaction
mechanism. More specifically, the first cross-parameter interaction branch
inherits the advantage of cross-attention in mining complementary information
with cross-modal hidden state decoding in SSM. The second shared-parameter
branch explores cross-modal alignment with joint embedding to obtain
cross-modal similar semantic features and structures through parameter sharing
in SSM. Finally, these two paths are jointly optimized with SSM for fusing
multispectral features in a unified framework, allowing our MS2Fusion to enjoy
both functional complementarity and shared semantic space. In our extensive
experiments on mainstream benchmarks including FLIR, M3FD and LLVIP, our
MS2Fusion significantly outperforms other state-of-the-art multispectral object
detection methods, evidencing its superiority. Moreover, MS2Fusion is general
and applicable to other multispectral perception tasks. We show that, even
without specific design, MS2Fusion achieves state-of-the-art results on RGB-T
semantic segmentation and RGBT salient object detection, showing its
generality. The source code will be available at
https://github.com/61s61min/MS2Fusion.git.

</details>


### [35] [AI-Powered Precision in Sport Taekwondo: Enhancing Fairness, Speed, and Trust in Competition (FST.ai)](https://arxiv.org/abs/2507.14657)
*Keivan Shariatmadar,Ahmad Osman*

Main category: cs.CV

TL;DR: FST.ai是一个基于AI的框架，用于提升体育裁判的实时决策能力，特别是在跆拳道中实时头部踢击检测和评分。


<details>
  <summary>Details</summary>
Motivation: 传统裁判系统存在延迟、主观性和不一致的问题，影响公平性和运动员信任。

Method: 利用计算机视觉、深度学习和边缘推理，通过姿态估计、动作分类和影响分析实现自动化决策。

Result: 系统将决策时间从分钟缩短到秒，提高了裁判的一致性和透明度。

Conclusion: FST.ai展示了在多种体育项目中提升裁判标准的潜力和可扩展性。

Abstract: The integration of Artificial Intelligence (AI) into sports officiating
represents a paradigm shift in how decisions are made in competitive
environments. Traditional manual systems, even when supported by Instant Video
Replay (IVR), often suffer from latency, subjectivity, and inconsistent
enforcement, undermining fairness and athlete trust. This paper introduces
FST.ai, a novel AI-powered framework designed to enhance officiating in Sport
Taekwondo, particularly focusing on the complex task of real-time head kick
detection and scoring. Leveraging computer vision, deep learning, and edge
inference, the system automates the identification and classification of key
actions, significantly reducing decision time from minutes to seconds while
improving consistency and transparency. Importantly, the methodology is not
limited to Taekwondo. The underlying framework -- based on pose estimation,
motion classification, and impact analysis -- can be adapted to a wide range of
sports requiring action detection, such as judo, karate, fencing, or even team
sports like football and basketball, where foul recognition or performance
tracking is critical. By addressing one of Taekwondo's most challenging
scenarios -- head kick scoring -- we demonstrate the robustness, scalability,
and sport-agnostic potential of FST.ai to transform officiating standards
across multiple disciplines.

</details>


### [36] [Artificial Intelligence in the Food Industry: Food Waste Estimation based on Computer Vision, a Brief Case Study in a University Dining Hall](https://arxiv.org/abs/2507.14662)
*Shayan Rokhva,Babak Teimourpour*

Main category: cs.CV

TL;DR: 研究提出了一种基于计算机视觉的成本效益框架，通过语义分割RGB图像来量化餐盘级食物浪费，适用于五种伊朗菜肴。模型性能良好，部分食物类型的分割准确率达90%以上。


<details>
  <summary>Details</summary>
Motivation: 量化餐后食物浪费对制定数据驱动的可持续发展策略至关重要。

Method: 使用四种全监督模型（U-Net、U-Net++及其轻量版），结合动态逆频率损失和AdamW优化器，通过多种指标评估性能。

Result: 模型性能满意，部分食物分割准确率高，轻量模型实现实时推理。干燥和刚性食物分割效果更好。

Conclusion: 该框架为大规模食物服务环境中的实时浪费监测提供了可扩展的无接触解决方案，并为减少食物浪费提供了可行方向。

Abstract: Quantifying post-consumer food waste in institutional dining settings is
essential for supporting data-driven sustainability strategies. This study
presents a cost-effective computer vision framework that estimates plate-level
food waste by utilizing semantic segmentation of RGB images taken before and
after meal consumption across five Iranian dishes. Four fully supervised models
(U-Net, U-Net++, and their lightweight variants) were trained using a capped
dynamic inverse-frequency loss and AdamW optimizer, then evaluated through a
comprehensive set of metrics, including Pixel Accuracy, Dice, IoU, and a
custom-defined Distributional Pixel Agreement (DPA) metric tailored to the
task. All models achieved satisfying performance, and for each food type, at
least one model approached or surpassed 90% DPA, demonstrating strong alignment
in pixel-wise proportion estimates. Lighter models with reduced parameter
counts offered faster inference, achieving real-time throughput on an NVIDIA T4
GPU. Further analysis showed superior segmentation performance for dry and more
rigid components (e.g., rice and fries), while more complex, fragmented, or
viscous dishes, such as stews, showed reduced performance, specifically
post-consumption. Despite limitations such as reliance on 2D imaging,
constrained food variety, and manual data collection, the proposed framework is
pioneering and represents a scalable, contactless solution for continuous
monitoring of food consumption. This research lays foundational groundwork for
automated, real-time waste tracking systems in large-scale food service
environments and offers actionable insights and outlines feasible future
directions for dining hall management and policymakers aiming to reduce
institutional food waste.

</details>


### [37] [Gene-DML: Dual-Pathway Multi-Level Discrimination for Gene Expression Prediction from Histopathology Images](https://arxiv.org/abs/2507.14670)
*Yaxuan Song,Jianan Fan,Hang Chang,Weidong Cai*

Main category: cs.CV

TL;DR: Gene-DML通过双路径多级判别框架提升组织病理学图像与基因表达谱的跨模态对齐，显著提高基因表达预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法未能充分利用组织病理学图像与基因表达谱的多层次跨模态对齐，限制了预测性能。

Method: 提出Gene-DML框架，通过双路径多级判别（多尺度实例级判别和跨级实例-组判别）增强形态与转录模态的对应关系。

Result: 在公共空间转录组数据集上，Gene-DML实现了最先进的基因表达预测性能。

Conclusion: Gene-DML通过学习鲁棒的跨模态表示，提升了预测准确性和泛化能力。

Abstract: Accurately predicting gene expression from histopathology images offers a
scalable and non-invasive approach to molecular profiling, with significant
implications for precision medicine and computational pathology. However,
existing methods often underutilize the cross-modal representation alignment
between histopathology images and gene expression profiles across multiple
representational levels, thereby limiting their prediction performance. To
address this, we propose Gene-DML, a unified framework that structures latent
space through Dual-pathway Multi-Level discrimination to enhance correspondence
between morphological and transcriptional modalities. The multi-scale
instance-level discrimination pathway aligns hierarchical histopathology
representations extracted at local, neighbor, and global levels with gene
expression profiles, capturing scale-aware morphological-transcriptional
relationships. In parallel, the cross-level instance-group discrimination
pathway enforces structural consistency between individual (image/gene)
instances and modality-crossed (gene/image, respectively) groups, strengthening
the alignment across modalities. By jointly modelling fine-grained and
structural-level discrimination, Gene-DML is able to learn robust cross-modal
representations, enhancing both predictive accuracy and generalization across
diverse biological contexts. Extensive experiments on public spatial
transcriptomics datasets demonstrate that Gene-DML achieves state-of-the-art
performance in gene expression prediction. The code and checkpoints will be
released soon.

</details>


### [38] [Docopilot: Improving Multimodal Models for Document-Level Understanding](https://arxiv.org/abs/2507.14675)
*Yuchen Duan,Zhe Chen,Yusong Hu,Weiyun Wang,Shenglong Ye,Botian Shi,Lewei Lu,Qibin Hou,Tong Lu,Hongsheng Li,Jifeng Dai,Wenhai Wang*

Main category: cs.CV

TL;DR: 该论文提出了一个高质量文档级数据集Doc-750K，并开发了原生多模态模型Docopilot，解决了现有MLLMs在复杂文档理解上的不足。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在复杂文档理解上表现不佳，主要由于缺乏高质量的文档级数据集，且现有RAG方法存在上下文碎片化、多阶段错误累积和额外检索时间成本等问题。

Method: 构建了Doc-750K数据集，包含多样文档结构和跨页依赖关系，并基于此开发了原生多模态模型Docopilot，无需依赖RAG。

Result: Docopilot在文档理解任务和多轮交互中表现出更高的连贯性、准确性和效率，为文档级多模态理解设定了新基准。

Conclusion: Doc-750K和Docopilot为复杂文档理解提供了有效解决方案，推动了多模态文档理解的发展。

Abstract: Despite significant progress in multimodal large language models (MLLMs),
their performance on complex, multi-page document comprehension remains
inadequate, largely due to the lack of high-quality, document-level datasets.
While current retrieval-augmented generation (RAG) methods offer partial
solutions, they suffer from issues, such as fragmented retrieval contexts,
multi-stage error accumulation, and extra time costs of retrieval. In this
work, we present a high-quality document-level dataset, Doc-750K, designed to
support in-depth understanding of multimodal documents. This dataset includes
diverse document structures, extensive cross-page dependencies, and real
question-answer pairs derived from the original documents. Building on the
dataset, we develop a native multimodal model, Docopilot, which can accurately
handle document-level dependencies without relying on RAG. Experiments
demonstrate that Docopilot achieves superior coherence, accuracy, and
efficiency in document understanding tasks and multi-turn interactions, setting
a new baseline for document-level multimodal understanding. Data, code, and
models are released at https://github.com/OpenGVLab/Docopilot

</details>


### [39] [WSI-Agents: A Collaborative Multi-Agent System for Multi-Modal Whole Slide Image Analysis](https://arxiv.org/abs/2507.14680)
*Xinheng Lyu,Yuci Liang,Wenting Chen,Meidan Ding,Jiaqi Yang,Guolin Huang,Daokun Zhang,Xiangjian He,Linlin Shen*

Main category: cs.CV

TL;DR: WSI-Agents是一种新型协作多智能体系统，通过任务分配、验证机制和总结模块提升多模态WSI分析的准确性和多功能性。


<details>
  <summary>Details</summary>
Motivation: 解决多模态大语言模型（MLLMs）在WSI分析中表现不如任务专用模型的问题，探索协作多智能体系统在病理学领域的潜力。

Method: 提出WSI-Agents，包括任务分配模块、验证机制和总结模块，结合专家智能体和知识库。

Result: 在多种任务中，WSI-Agents优于现有的WSI MLLMs和医疗智能体框架。

Conclusion: WSI-Agents通过协作智能体系统实现了WSI分析的高准确性和多功能性。

Abstract: Whole slide images (WSIs) are vital in digital pathology, enabling gigapixel
tissue analysis across various pathological tasks. While recent advancements in
multi-modal large language models (MLLMs) allow multi-task WSI analysis through
natural language, they often underperform compared to task-specific models.
Collaborative multi-agent systems have emerged as a promising solution to
balance versatility and accuracy in healthcare, yet their potential remains
underexplored in pathology-specific domains. To address these issues, we
propose WSI-Agents, a novel collaborative multi-agent system for multi-modal
WSI analysis. WSI-Agents integrates specialized functional agents with robust
task allocation and verification mechanisms to enhance both task-specific
accuracy and multi-task versatility through three components: (1) a task
allocation module assigning tasks to expert agents using a model zoo of patch
and WSI level MLLMs, (2) a verification mechanism ensuring accuracy through
internal consistency checks and external validation using pathology knowledge
bases and domain-specific models, and (3) a summary module synthesizing the
final summary with visual interpretation maps. Extensive experiments on
multi-modal WSI benchmarks show WSI-Agents's superiority to current WSI MLLMs
and medical agent frameworks across diverse tasks.

</details>


### [40] [From Semantics, Scene to Instance-awareness: Distilling Foundation Model for Open-vocabulary Situation Recognition](https://arxiv.org/abs/2507.14686)
*Chen Cai,Tianyi Liu,Jianjun Gao,Wenyang Liu,Kejun Wu,Ruoyu Wang,Yi Wang,Soo Chin Liew*

Main category: cs.CV

TL;DR: 论文提出了一种名为MIPD的新框架，通过从多模态大语言模型（MLLM）中蒸馏知识，提升小模型的泛化和零样本能力，解决了复杂场景识别（GSR）中的资源消耗和泛化不足问题。


<details>
  <summary>Details</summary>
Motivation: 现有的MLLM在零样本能力上表现优异，但在复杂GSR任务中资源消耗大且效果不佳；传统GSR模型泛化能力不足，难以识别未见或罕见场景。

Method: 提出MIPD框架，利用LLM生成正负理性数据，通过场景感知和实例感知提示对齐视觉信息，最终将知识蒸馏到学生模型中。

Result: 在Ov-SWiG和HICO-DET数据集上，MIPD在已知、罕见和未见场景中均表现优异，提升了未见场景的检测能力。

Conclusion: MIPD通过知识蒸馏有效提升了小模型的泛化和零样本能力，为复杂场景识别提供了更高效的解决方案。

Abstract: Recent Multimodal Large Language Models (MLLMs) exhibit strong zero-shot
abilities but struggle with complex Grounded Situation Recognition (GSR) and
are resource-intensive for edge device deployment. Meanwhile, conventional GSR
models often lack generalization ability, falling short in recognizing unseen
and rare situations. In this paper, we exploit transferring knowledge from a
teacher MLLM to a small GSR model to enhance its generalization and zero-shot
abilities, thereby introducing the task of Open-vocabulary Grounded Situation
Recognition (Ov-GSR). To achieve this, we propose Multimodal Interactive Prompt
Distillation (MIPD), a novel framework that distills enriched multimodal
knowledge from the foundation model, enabling the student Ov-GSR model to
recognize unseen situations and be better aware of rare situations.
Specifically, the MIPD framework first leverages the LLM-based Judgmental
Rationales Generator (JRG) to construct positive and negative glimpse and gaze
rationales enriched with contextual semantic information. The proposed
scene-aware and instance-perception prompts are then introduced to align
rationales with visual information from the MLLM teacher via the
Negative-Guided Multimodal Prompting Alignment (NMPA) module, effectively
capturing holistic and perceptual multimodal knowledge. Finally, the aligned
multimodal knowledge is distilled into the student Ov-GSR model, providing a
stronger foundation for generalization that enhances situation understanding,
bridges the gap between seen and unseen scenarios, and mitigates prediction
bias in rare cases. We evaluate MIPD on the refined Ov-SWiG dataset, achieving
superior performance on seen, rare, and unseen situations, and further
demonstrate improved unseen detection on the HICO-DET dataset.

</details>


### [41] [GTPBD: A Fine-Grained Global Terraced Parcel and Boundary Dataset](https://arxiv.org/abs/2507.14697)
*Zhiwei Zhang,Zi Ye,Yibin Wen,Shuai Yuan,Haohuan Fu,Jianxi Huang,Juepeng Zheng*

Main category: cs.CV

TL;DR: GTPBD是全球首个精细梯田地块数据集，覆盖全球主要梯田区域，包含超过20万个复杂梯田地块，适用于多种遥感任务。


<details>
  <summary>Details</summary>
Motivation: 现有农业地块提取研究多关注中分辨率或平坦农田，缺乏对复杂梯田地形的精细表达，难以满足精准农业需求。

Method: 提出GTPBD数据集，包含47,537张高分辨率图像和三级标注（边界、掩码、地块标签），覆盖中国七大地理区域及全球跨气候带梯田。

Result: GTPBD在语义分割、边缘检测、地块提取和无监督域适应任务中进行了基准测试，填补了梯田遥感研究的空白。

Conclusion: GTPBD为精细农业地形分析和跨场景知识迁移提供了基础设施，具有重要研究价值。

Abstract: Agricultural parcels serve as basic units for conducting agricultural
practices and applications, which is vital for land ownership registration,
food security assessment, soil erosion monitoring, etc. However, existing
agriculture parcel extraction studies only focus on mid-resolution mapping or
regular plain farmlands while lacking representation of complex terraced
terrains due to the demands of precision agriculture.In this paper, we
introduce a more fine-grained terraced parcel dataset named GTPBD (Global
Terraced Parcel and Boundary Dataset), which is the first fine-grained dataset
covering major worldwide terraced regions with more than 200,000 complex
terraced parcels with manual annotation. GTPBD comprises 47,537 high-resolution
images with three-level labels, including pixel-level boundary labels, mask
labels, and parcel labels. It covers seven major geographic zones in China and
transcontinental climatic regions around the world.Compared to the existing
datasets, the GTPBD dataset brings considerable challenges due to the: (1)
terrain diversity; (2) complex and irregular parcel objects; and (3) multiple
domain styles. Our proposed GTPBD dataset is suitable for four different tasks,
including semantic segmentation, edge detection, terraced parcel extraction,
and unsupervised domain adaptation (UDA) tasks.Accordingly, we benchmark the
GTPBD dataset on eight semantic segmentation methods, four edge extraction
methods, three parcel extraction methods, and five UDA methods, along with a
multi-dimensional evaluation framework integrating pixel-level and object-level
metrics. GTPBD fills a critical gap in terraced remote sensing research,
providing a basic infrastructure for fine-grained agricultural terrain analysis
and cross-scenario knowledge transfer.

</details>


### [42] [MultiRetNet: A Multimodal Vision Model and Deferral System for Staging Diabetic Retinopathy](https://arxiv.org/abs/2507.14738)
*Jeannie She,Katie Spivakovsky*

Main category: cs.CV

TL;DR: MultiRetNet结合视网膜成像、社会经济因素和共病资料，通过多模态融合和临床延迟系统，提高糖尿病视网膜病变分期准确性，尤其服务于低收入人群。


<details>
  <summary>Details</summary>
Motivation: 糖尿病视网膜病变是全球可预防失明的主要原因，低收入人群因筛查机会有限，病情易进展至晚期。共病条件进一步加速疾病发展。

Method: 提出MultiRetNet，整合视网膜成像、社会经济因素和共病资料，采用三种多模态融合方法，并通过全连接层进行最优融合。合成对抗性低质量图像，利用对比学习训练延迟系统，识别需临床复查的样本。

Result: 全连接层融合方法表现最佳，系统在低质量图像上保持诊断准确性，整合关键健康数据，提高早期检测率。

Conclusion: MultiRetNet可降低医疗成本，提高早期检测率，减少医疗资源分配不均，促进医疗公平。

Abstract: Diabetic retinopathy (DR) is a leading cause of preventable blindness,
affecting over 100 million people worldwide. In the United States, individuals
from lower-income communities face a higher risk of progressing to advanced
stages before diagnosis, largely due to limited access to screening. Comorbid
conditions further accelerate disease progression. We propose MultiRetNet, a
novel pipeline combining retinal imaging, socioeconomic factors, and
comorbidity profiles to improve DR staging accuracy, integrated with a clinical
deferral system for a clinical human-in-the-loop implementation. We experiment
with three multimodal fusion methods and identify fusion through a fully
connected layer as the most versatile methodology. We synthesize adversarial,
low-quality images and use contrastive learning to train the deferral system,
guiding the model to identify out-of-distribution samples that warrant
clinician review. By maintaining diagnostic accuracy on suboptimal images and
integrating critical health data, our system can improve early detection,
particularly in underserved populations where advanced DR is often first
identified. This approach may reduce healthcare costs, increase early detection
rates, and address disparities in access to care, promoting healthcare equity.

</details>


### [43] [Light Future: Multimodal Action Frame Prediction via InstructPix2Pix](https://arxiv.org/abs/2507.14809)
*Zesen Zhong,Duomin Zhang,Yijia Li*

Main category: cs.CV

TL;DR: 本文提出了一种轻量级、高效的机器人动作预测方法，通过改进InstructPix2Pix模型实现多模态未来帧预测，显著降低了计算成本和延迟。


<details>
  <summary>Details</summary>
Motivation: 预测未来运动轨迹在机器人、自动驾驶等领域至关重要，但现有视频预测模型计算成本高且延迟大。

Method: 利用改进的InstructPix2Pix模型，结合视觉和文本输入进行多模态未来帧预测，仅需单张图像和文本提示。

Result: 在RoboTWin数据集上，该方法在SSIM和PSNR指标上优于现有基线模型，且计算更高效。

Conclusion: 该方法为机器人动作预测提供了一种轻量级解决方案，适用于对运动轨迹精度要求高的场景。

Abstract: Predicting future motion trajectories is a critical capability across domains
such as robotics, autonomous systems, and human activity forecasting, enabling
safer and more intelligent decision-making. This paper proposes a novel,
efficient, and lightweight approach for robot action prediction, offering
significantly reduced computational cost and inference latency compared to
conventional video prediction models. Importantly, it pioneers the adaptation
of the InstructPix2Pix model for forecasting future visual frames in robotic
tasks, extending its utility beyond static image editing. We implement a deep
learning-based visual prediction framework that forecasts what a robot will
observe 100 frames (10 seconds) into the future, given a current image and a
textual instruction. We repurpose and fine-tune the InstructPix2Pix model to
accept both visual and textual inputs, enabling multimodal future frame
prediction. Experiments on the RoboTWin dataset (generated based on real-world
scenarios) demonstrate that our method achieves superior SSIM and PSNR compared
to state-of-the-art baselines in robot action prediction tasks. Unlike
conventional video prediction models that require multiple input frames, heavy
computation, and slow inference latency, our approach only needs a single image
and a text prompt as input. This lightweight design enables faster inference,
reduced GPU demands, and flexible multimodal control, particularly valuable for
applications like robotics and sports motion trajectory analytics, where motion
trajectory precision is prioritized over visual fidelity.

</details>


### [44] [InterAct-Video: Reasoning-Rich Video QA for Urban Traffic](https://arxiv.org/abs/2507.14743)
*Joseph Raj Vishal,Rutuja Patil,Manas Srinivas Gowda,Katha Naik,Yezhou Yang,Bharatesh Chakravarthi*

Main category: cs.CV

TL;DR: 论文提出了InterAct VideoQA数据集，用于提升视频问答模型在复杂交通场景中的表现，并展示了其在智能交通系统中的潜力。


<details>
  <summary>Details</summary>
Motivation: 现有视频问答模型难以处理真实交通场景中的复杂时空事件，需要专门的数据集来提升模型性能。

Method: 构建了包含8小时真实交通视频和25,000个问答对的InterAct VideoQA数据集，并评估了现有模型的表现。

Result: 实验表明现有模型在复杂交通场景中表现不佳，但通过微调可显著提升性能。

Conclusion: InterAct VideoQA数据集为智能交通系统中的视频问答研究提供了重要基准。

Abstract: Traffic monitoring is crucial for urban mobility, road safety, and
intelligent transportation systems (ITS). Deep learning has advanced
video-based traffic monitoring through video question answering (VideoQA)
models, enabling structured insight extraction from traffic videos. However,
existing VideoQA models struggle with the complexity of real-world traffic
scenes, where multiple concurrent events unfold across spatiotemporal
dimensions. To address these challenges, this paper introduces \textbf{InterAct
VideoQA}, a curated dataset designed to benchmark and enhance VideoQA models
for traffic monitoring tasks. The InterAct VideoQA dataset comprises 8 hours of
real-world traffic footage collected from diverse intersections, segmented into
10-second video clips, with over 25,000 question-answer (QA) pairs covering
spatiotemporal dynamics, vehicle interactions, incident detection, and other
critical traffic attributes. State-of-the-art VideoQA models are evaluated on
InterAct VideoQA, exposing challenges in reasoning over fine-grained
spatiotemporal dependencies within complex traffic scenarios. Additionally,
fine-tuning these models on InterAct VideoQA yields notable performance
improvements, demonstrating the necessity of domain-specific datasets for
VideoQA. InterAct VideoQA is publicly available as a benchmark dataset to
facilitate future research in real-world deployable VideoQA models for
intelligent transportation systems. GitHub Repo:
https://github.com/joe-rabbit/InterAct_VideoQA

</details>


### [45] [EBA-AI: Ethics-Guided Bias-Aware AI for Efficient Underwater Image Enhancement and Coral Reef Monitoring](https://arxiv.org/abs/2507.15036)
*Lyes Saad Saoud,Irfan Hussain*

Main category: cs.CV

TL;DR: EBA-AI框架通过CLIP嵌入和自适应处理解决水下图像增强中的数据集偏差和高计算成本问题，同时提升透明度和效率。


<details>
  <summary>Details</summary>
Motivation: 水下图像增强对海洋保护至关重要，但现有AI模型存在数据集偏差、高计算成本和透明度不足的问题。

Method: EBA-AI利用CLIP嵌入检测和缓解数据集偏差，并采用自适应处理优化能效，减少GPU使用。

Result: 实验表明，EBA-AI在PSNR略有下降（1.0 dB）的情况下显著节省计算资源，支持实时大规模监测。

Conclusion: EBA-AI在效率、公平性和可解释性方面优于现有方法，为可持续海洋保护提供了新工具。

Abstract: Underwater image enhancement is vital for marine conservation, particularly
coral reef monitoring. However, AI-based enhancement models often face dataset
bias, high computational costs, and lack of transparency, leading to potential
misinterpretations. This paper introduces EBA-AI, an ethics-guided bias-aware
AI framework to address these challenges. EBA-AI leverages CLIP embeddings to
detect and mitigate dataset bias, ensuring balanced representation across
varied underwater environments. It also integrates adaptive processing to
optimize energy efficiency, significantly reducing GPU usage while maintaining
competitive enhancement quality. Experiments on LSUI400, Oceanex, and UIEB100
show that while PSNR drops by a controlled 1.0 dB, computational savings enable
real-time feasibility for large-scale marine monitoring. Additionally,
uncertainty estimation and explainability techniques enhance trust in AI-driven
environmental decisions. Comparisons with CycleGAN, FunIEGAN, RAUNENet,
WaterNet, UGAN, PUGAN, and UTUIE validate EBA-AI's effectiveness in balancing
efficiency, fairness, and interpretability in underwater image processing. By
addressing key limitations of AI-driven enhancement, this work contributes to
sustainable, bias-aware, and computationally efficient marine conservation
efforts. For interactive visualizations, animations, source code, and access to
the preprint, visit: https://lyessaadsaoud.github.io/EBA-AI/

</details>


### [46] [LeAdQA: LLM-Driven Context-Aware Temporal Grounding for Video Question Answering](https://arxiv.org/abs/2507.14784)
*Xinxin Dong,Baoyun Peng,Haokai Ma,Yufei Wang,Zixuan Dong,Fei Hu,Xiaodong Wang*

Main category: cs.CV

TL;DR: LeAdQA通过结合因果感知查询优化和细粒度视觉定位，解决了VideoQA中任务无关采样和启发式检索的局限性，显著提升了复杂推理任务的性能。


<details>
  <summary>Details</summary>
Motivation: 当前VideoQA方法因任务无关采样和启发式检索的局限性，无法有效处理长视频中的稀疏关键事件和复杂因果关系。

Method: LeAdQA利用LLM优化问题-选项对以消除因果歧义，并通过时间定位模型精确检索关键片段，结合自适应融合机制生成答案。

Result: 在NExT-QA、IntentQA和NExT-GQA数据集上，LeAdQA实现了最先进的性能，同时保持计算效率。

Conclusion: LeAdQA通过因果感知和视觉定位的协同作用，显著提升了复杂推理任务的VideoQA性能。

Abstract: Video Question Answering (VideoQA) requires identifying sparse critical
moments in long videos and reasoning about their causal relationships to answer
semantically complex questions. While recent advances in multimodal learning
have improved alignment and fusion, current approaches remain limited by two
prevalent but fundamentally flawed strategies: (1) task-agnostic sampling
indiscriminately processes all frames, overwhelming key events with irrelevant
content; and (2) heuristic retrieval captures superficial patterns but misses
causal-temporal structures needed for complex reasoning. To address these
challenges, we introduce LeAdQA, an innovative approach that bridges these gaps
through synergizing causal-aware query refinement with fine-grained visual
grounding. Our method first leverages LLMs to reformulate question-option
pairs, resolving causal ambiguities and sharpening temporal focus. These
refined queries subsequently direct a temporal grounding model to precisely
retrieve the most salient segments, complemented by an adaptive fusion
mechanism dynamically integrating the evidence to maximize relevance. The
integrated visual-textual cues are then processed by an MLLM to generate
accurate, contextually-grounded answers. Experiments on NExT-QA, IntentQA, and
NExT-GQA demonstrate that our method's precise visual grounding substantially
enhances the understanding of video-question relationships, achieving
state-of-the-art (SOTA) performance on complex reasoning tasks while
maintaining computational efficiency.

</details>


### [47] [Visual Place Recognition for Large-Scale UAV Applications](https://arxiv.org/abs/2507.15089)
*Ioannis Tsampikos Papapetros,Ioannis Kansizoglou,Antonios Gasteratos*

Main category: cs.CV

TL;DR: 论文提出了LASED数据集和可转向CNN，用于解决无人机视觉地点识别中的数据集不足和旋转模糊问题，显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 无人机视觉地点识别（vPR）面临数据集规模小和旋转模糊的挑战，限制了模型的泛化能力。

Method: 引入LASED大规模数据集，并提出使用可转向CNN处理旋转模糊。

Result: LASED数据集和可转向CNN显著提升了召回率，后者平均比传统CNN高12%。

Conclusion: 结合大规模数据集和旋转等变网络，显著增强了无人机vPR的鲁棒性和泛化能力。

Abstract: Visual Place Recognition (vPR) plays a crucial role in Unmanned Aerial
Vehicle (UAV) navigation, enabling robust localization across diverse
environments. Despite significant advancements, aerial vPR faces unique
challenges due to the limited availability of large-scale, high-altitude
datasets, which limits model generalization, along with the inherent rotational
ambiguity in UAV imagery. To address these challenges, we introduce LASED, a
large-scale aerial dataset with approximately one million images,
systematically sampled from 170,000 unique locations throughout Estonia over a
decade, offering extensive geographic and temporal diversity. Its structured
design ensures clear place separation significantly enhancing model training
for aerial scenarios. Furthermore, we propose the integration of steerable
Convolutional Neural Networks (CNNs) to explicitly handle rotational variance,
leveraging their inherent rotational equivariance to produce robust,
orientation-invariant feature representations. Our extensive benchmarking
demonstrates that models trained on LASED achieve significantly higher recall
compared to those trained on smaller, less diverse datasets, highlighting the
benefits of extensive geographic coverage and temporal diversity. Moreover,
steerable CNNs effectively address rotational ambiguity inherent in aerial
imagery, consistently outperforming conventional convolutional architectures,
achieving on average 12\% recall improvement over the best-performing
non-steerable network. By combining structured, large-scale datasets with
rotation-equivariant neural networks, our approach significantly enhances model
robustness and generalization for aerial vPR.

</details>


### [48] [FOCUS: Fused Observation of Channels for Unveiling Spectra](https://arxiv.org/abs/2507.14787)
*Xi Xiao,Aristeidis Tsaris,Anika Tabassum,John Lagergren,Larry M. York,Tianyang Wang,Xiao Wang*

Main category: cs.CV

TL;DR: FOCUS框架解决了Vision Transformers在HSI数据中的解释性问题，通过类特定光谱提示和可学习的[SINK]令牌，实现了高效且可靠的空间-光谱解释。


<details>
  <summary>Details</summary>
Motivation: HSI数据的高维性和现有显著性方法的局限性使得ViTs的解释性成为挑战，FOCUS旨在填补这一空白。

Method: FOCUS引入类特定光谱提示和[SINK]令牌，通过单次前向传递生成3D显著性图和光谱重要性曲线。

Result: FOCUS显著提高了波段级IoU（15%），减少了注意力崩溃（40%），并与专家标注高度一致。

Conclusion: FOCUS以极低的参数开销实现了高分辨率ViT解释性，为HSI决策提供了可信赖的工具。

Abstract: Hyperspectral imaging (HSI) captures hundreds of narrow, contiguous
wavelength bands, making it a powerful tool in biology, agriculture, and
environmental monitoring. However, interpreting Vision Transformers (ViTs) in
this setting remains largely unexplored due to two key challenges: (1) existing
saliency methods struggle to capture meaningful spectral cues, often collapsing
attention onto the class token, and (2) full-spectrum ViTs are computationally
prohibitive for interpretability, given the high-dimensional nature of HSI
data. We present FOCUS, the first framework that enables reliable and efficient
spatial-spectral interpretability for frozen ViTs. FOCUS introduces two core
components: class-specific spectral prompts that guide attention toward
semantically meaningful wavelength groups, and a learnable [SINK] token trained
with an attraction loss to absorb noisy or redundant attention. Together, these
designs make it possible to generate stable and interpretable 3D saliency maps
and spectral importance curves in a single forward pass, without any gradient
backpropagation or backbone modification. FOCUS improves band-level IoU by 15
percent, reduces attention collapse by over 40 percent, and produces saliency
results that align closely with expert annotations. With less than 1 percent
parameter overhead, our method makes high-resolution ViT interpretability
practical for real-world hyperspectral applications, bridging a long-standing
gap between black-box modeling and trustworthy HSI decision-making.

</details>


### [49] [Dense-depth map guided deep Lidar-Visual Odometry with Sparse Point Clouds and Images](https://arxiv.org/abs/2507.15496)
*JunYing Huang,Ao Xu,DongSun Yong,KeRen Li,YuanFeng Wang,Qi Qin*

Main category: cs.CV

TL;DR: 提出了一种新型的LiDAR-视觉里程计框架，结合LiDAR点云和图像，通过深度补全和多尺度特征提取网络实现高精度姿态估计。


<details>
  <summary>Details</summary>
Motivation: 自主系统需要准确的自我定位和导航，现有方法在动态环境和遮挡区域表现不佳。

Method: 利用深度补全生成稠密深度图，结合多尺度特征提取和注意力机制，通过层次化姿态优化模块逐步优化运动估计。

Result: 在KITTI里程计基准测试中，性能优于或接近当前最先进的视觉和LiDAR里程计方法。

Conclusion: 该方法在准确性和鲁棒性上表现优异，适用于动态环境和复杂场景。

Abstract: Odometry is a critical task for autonomous systems for self-localization and
navigation. We propose a novel LiDAR-Visual odometry framework that integrates
LiDAR point clouds and images for accurate and robust pose estimation. Our
method utilizes a dense-depth map estimated from point clouds and images
through depth completion, and incorporates a multi-scale feature extraction
network with attention mechanisms, enabling adaptive depth-aware
representations. Furthermore, we leverage dense depth information to refine
flow estimation and mitigate errors in occlusion-prone regions. Our
hierarchical pose refinement module optimizes motion estimation progressively,
ensuring robust predictions against dynamic environments and scale ambiguities.
Comprehensive experiments on the KITTI odometry benchmark demonstrate that our
approach achieves similar or superior accuracy and robustness compared to
state-of-the-art visual and LiDAR odometry methods.

</details>


### [50] [A Novel Downsampling Strategy Based on Information Complementarity for Medical Image Segmentation](https://arxiv.org/abs/2507.14790)
*Wenbo Yue,Chang Li,Guoping Xu*

Main category: cs.CV

TL;DR: 该研究提出了一种基于信息互补的下采样方法HPD，通过MinMaxPooling替代传统方法，在语义分割任务中提升了性能。


<details>
  <summary>Details</summary>
Motivation: 传统下采样方法可能导致关键空间信息丢失，影响像素级预测精度，因此需要一种能保留图像细节的新方法。

Method: 提出Hybrid Pooling Downsampling (HPD)，结合MinMaxPooling以保留图像的明暗对比和细节特征。

Result: 在ACDC和Synapse数据集上的实验表明，HPD平均提升DSC系数0.5%，优于传统方法。

Conclusion: HPD模块为语义分割任务提供了一种高效解决方案。

Abstract: In convolutional neural networks (CNNs), downsampling operations are crucial
to model performance. Although traditional downsampling methods (such as
maximum pooling and cross-row convolution) perform well in feature aggregation,
receptive field expansion, and computational reduction, they may lead to the
loss of key spatial information in semantic segmentation tasks, thereby
affecting the pixel-by-pixel prediction accuracy.To this end, this study
proposes a downsampling method based on information complementarity - Hybrid
Pooling Downsampling (HPD). The core is to replace the traditional method with
MinMaxPooling, and effectively retain the light and dark contrast and detail
features of the image by extracting the maximum value information of the local
area.Experiment on various CNN architectures on the ACDC and Synapse datasets
show that HPD outperforms traditional methods in segmentation performance, and
increases the DSC coefficient by 0.5% on average. The results show that the HPD
module provides an efficient solution for semantic segmentation tasks.

</details>


### [51] [Being-H0: Vision-Language-Action Pretraining from Large-Scale Human Videos](https://arxiv.org/abs/2507.15597)
*Hao Luo,Yicheng Feng,Wanpeng Zhang,Sipeng Zheng,Ye Wang,Haoqi Yuan,Jiazheng Liu,Chaoyi Xu,Qin Jin,Zongqing Lu*

Main category: cs.CV

TL;DR: Being-H0是一个基于大规模人类视频训练的灵巧视觉-语言-动作模型（VLA），通过物理指令调优和部分级运动标记化方法，解决了现有VLA在复杂操作任务中的泛化问题。


<details>
  <summary>Details</summary>
Motivation: 现有VLA依赖合成数据或有限规模的遥操作演示，导致在复杂操作任务中泛化能力差。利用人类手的灵巧性和网络数据的规模性，提出解决数据瓶颈的新方法。

Method: 采用物理指令调优训练范式，结合大规模VLA预训练、物理空间对齐和机器人任务后适应；提出部分级运动标记化方法以实现毫米级重建精度。

Result: Being-H0在手部运动生成和指令跟随方面表现优异，且能随模型和数据规模扩展；在真实机器人操作任务中展现出预期增益。

Conclusion: 通过物理指令调优和多样化数据整合，Being-H0显著提升了VLA在复杂操作任务中的性能，为机器人操作提供了新思路。

Abstract: We introduce Being-H0, a dexterous Vision-Language-Action model (VLA) trained
on large-scale human videos. Existing VLAs struggle with complex manipulation
tasks requiring high dexterity and generalize poorly to novel scenarios and
tasks, primarily due to their reliance on synthetic data with significant
sim-to-real gaps or teleoperated demonstrations lacking scale and diversity. To
address this data bottleneck, we propose leveraging human hands as a foundation
manipulator, capitalizing on the rich dexterity and scalability present in web
data. Our approach centers on physical instruction tuning, a novel training
paradigm that combines large-scale VLA pretraining from human videos, physical
space alignment for 3D reasoning, and post-training adaptation for robotic
tasks. Additionally, we introduce a part-level motion tokenization method which
achieves millimeter-level reconstruction accuracy to model precise hand
trajectories for action learning. To support our proposed paradigm, we further
develop a comprehensive data curation pipeline that integrates heterogeneous
sources -- including motion capture, VR, and RGB-only videos -- into a
large-scale dataset with millions of motion-based instructional instances. We
empirically show the excellence of Being-H0 in hand motion generation and
instruction following, and it also scales well with model and data sizes.
Importantly, we observe the expected gains of Being-H0 in real-world robotic
manipulation as physical instruction tuning is applied. More details are
available at https://beingbeyond.github.io/Being-H0.

</details>


### [52] [Distilling Parallel Gradients for Fast ODE Solvers of Diffusion Models](https://arxiv.org/abs/2507.14797)
*Beier Zhu,Ruoyu Wang,Tong Zhao,Hanwang Zhang,Chi Zhang*

Main category: cs.CV

TL;DR: 提出了一种名为EPD的新型ODE求解器，通过并行梯度评估减少截断误差，实现高质量低延迟采样。


<details>
  <summary>Details</summary>
Motivation: 扩散模型采样延迟高，现有加速方法在低延迟预算下图像质量下降。

Method: EPD利用多个并行梯度评估优化ODE求解器，参数可学习且训练开销小。

Result: 在多个图像合成基准测试中，EPD在5 NFE延迟下显著优于现有方法，如CIFAR-10上FID为4.47。

Conclusion: EPD是一种高效且通用的ODE求解器插件，显著提升采样质量和速度。

Abstract: Diffusion models (DMs) have achieved state-of-the-art generative performance
but suffer from high sampling latency due to their sequential denoising nature.
Existing solver-based acceleration methods often face image quality degradation
under a low-latency budget. In this paper, we propose the Ensemble Parallel
Direction solver (dubbed as \ours), a novel ODE solver that mitigates
truncation errors by incorporating multiple parallel gradient evaluations in
each ODE step. Importantly, since the additional gradient computations are
independent, they can be fully parallelized, preserving low-latency sampling.
  Our method optimizes a small set of learnable parameters in a distillation
fashion, ensuring minimal training overhead.
  In addition, our method can serve as a plugin to improve existing ODE
samplers. Extensive experiments on various image synthesis benchmarks
demonstrate the effectiveness of our \ours~in achieving high-quality and
low-latency sampling. For example, at the same latency level of 5 NFE, EPD
achieves an FID of 4.47 on CIFAR-10, 7.97 on FFHQ, 8.17 on ImageNet, and 8.26
on LSUN Bedroom, surpassing existing learning-based solvers by a significant
margin. Codes are available in https://github.com/BeierZhu/EPD.

</details>


### [53] [An Evaluation of DUSt3R/MASt3R/VGGT 3D Reconstruction on Photogrammetric Aerial Blocks](https://arxiv.org/abs/2507.14798)
*Xinyi Wu,Steven Landgraf,Markus Ulrich,Rongjun Qin*

Main category: cs.CV

TL;DR: 论文评估了DUSt3R、MASt3R和VGGT三种3D重建模型在航拍图像上的表现，发现它们能从极稀疏图像集（少于10张）准确重建密集点云，但高分辨率和大图像集时效果下降。


<details>
  <summary>Details</summary>
Motivation: 探索基于Transformer的3D重建模型在航拍图像上的潜力，填补现有研究空白。

Method: 在UseGeo数据集的航拍图像块上评估预训练的DUSt3R、MASt3R和VGGT模型，测试姿态估计和密集3D重建能力。

Result: 模型能从极稀疏图像集（分辨率最高518像素）重建密集点云，完整性比COLMAP提升50%，VGGT计算效率更高。但高分辨率和大图像集时姿态估计可靠性下降。

Conclusion: Transformer方法无法完全替代传统SfM和MVS，但在低分辨率、稀疏场景中可作为补充方案。

Abstract: State-of-the-art 3D computer vision algorithms continue to advance in
handling sparse, unordered image sets. Recently developed foundational models
for 3D reconstruction, such as Dense and Unconstrained Stereo 3D Reconstruction
(DUSt3R), Matching and Stereo 3D Reconstruction (MASt3R), and Visual Geometry
Grounded Transformer (VGGT), have attracted attention due to their ability to
handle very sparse image overlaps. Evaluating DUSt3R/MASt3R/VGGT on typical
aerial images matters, as these models may handle extremely low image overlaps,
stereo occlusions, and textureless regions. For redundant collections, they can
accelerate 3D reconstruction by using extremely sparsified image sets. Despite
tests on various computer vision benchmarks, their potential on photogrammetric
aerial blocks remains unexplored. This paper conducts a comprehensive
evaluation of the pre-trained DUSt3R/MASt3R/VGGT models on the aerial blocks of
the UseGeo dataset for pose estimation and dense 3D reconstruction. Results
show these methods can accurately reconstruct dense point clouds from very
sparse image sets (fewer than 10 images, up to 518 pixels resolution), with
completeness gains up to +50% over COLMAP. VGGT also demonstrates higher
computational efficiency, scalability, and more reliable camera pose
estimation. However, all exhibit limitations with high-resolution images and
large sets, as pose reliability declines with more images and geometric
complexity. These findings suggest transformer-based methods cannot fully
replace traditional SfM and MVS, but offer promise as complementary approaches,
especially in challenging, low-resolution, and sparse scenarios.

</details>


### [54] [Exploring Scalable Unified Modeling for General Low-Level Vision](https://arxiv.org/abs/2507.14801)
*Xiangyu Chen,Kaiwen Zhu,Yuandong Pu,Shuo Cao,Xiaohui Li,Wenlong Zhang,Yihao Liu,Yu Qiao,Jiantao Zhou,Chao Dong*

Main category: cs.CV

TL;DR: 提出了一种基于视觉提示的统一低层视觉任务处理框架VPIP，通过输入-目标图像对作为提示，支持多种任务。开发了统一模型GenLV，并在大规模任务上验证了其性能和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 解决低层视觉任务多样性带来的统一建模挑战。

Method: 设计了包含图像处理主干、提示编码器和提示交互模块的VPIP框架，支持灵活架构集成和任务特定表示利用。

Result: 在多任务基准测试中表现优异，增加任务数量提升泛化能力，尤其在数据有限任务中。

Conclusion: VPIP框架有效、可扩展，为通用低层视觉建模提供了统一基础。

Abstract: Low-level vision involves a wide spectrum of tasks, including image
restoration, enhancement, stylization, and feature extraction, which differ
significantly in both task formulation and output domains. To address the
challenge of unified modeling across such diverse tasks, we propose a Visual
task Prompt-based Image Processing (VPIP) framework that leverages input-target
image pairs as visual prompts to guide the model in performing a variety of
low-level vision tasks. The framework comprises an end-to-end image processing
backbone, a prompt encoder, and a prompt interaction module, enabling flexible
integration with various architectures and effective utilization of
task-specific visual representations. Based on this design, we develop a
unified low-level vision model, GenLV, and evaluate its performance across
multiple representative tasks. To explore the scalability of this approach, we
extend the framework along two dimensions: model capacity and task diversity.
We construct a large-scale benchmark consisting of over 100 low-level vision
tasks and train multiple versions of the model with varying scales.
Experimental results show that the proposed method achieves considerable
performance across a wide range of tasks. Notably, increasing the number of
training tasks enhances generalization, particularly for tasks with limited
data, indicating the model's ability to learn transferable representations
through joint training. Further evaluations in zero-shot generalization,
few-shot transfer, and task-specific fine-tuning scenarios demonstrate the
model's strong adaptability, confirming the effectiveness, scalability, and
potential of the proposed framework as a unified foundation for general
low-level vision modeling.

</details>


### [55] [Seeing Through Deepfakes: A Human-Inspired Framework for Multi-Face Detection](https://arxiv.org/abs/2507.14807)
*Juan Hu,Shaojing Fan,Terence Sim*

Main category: cs.CV

TL;DR: 论文提出了一种基于人类认知的多脸深度伪造视频检测方法HICOM，通过分析人类依赖的四种关键线索，显著提升了检测准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 多脸深度伪造视频在自然社交场景中日益普遍，现有方法因缺乏对上下文线索的关注而表现不佳。

Method: 通过人类研究识别四种关键线索，并开发HICOM框架，结合LLM提供可解释性。

Result: HICOM在基准数据集上平均准确率提升3.3%，泛化能力优于现有方法5.8%。

Conclusion: 研究揭示了人类因素在防御深度伪造中的重要性，HICOM为多脸场景提供了高效且可解释的解决方案。

Abstract: Multi-face deepfake videos are becoming increasingly prevalent, often
appearing in natural social settings that challenge existing detection methods.
Most current approaches excel at single-face detection but struggle in
multi-face scenarios, due to a lack of awareness of crucial contextual cues. In
this work, we develop a novel approach that leverages human cognition to
analyze and defend against multi-face deepfake videos. Through a series of
human studies, we systematically examine how people detect deepfake faces in
social settings. Our quantitative analysis reveals four key cues humans rely
on: scene-motion coherence, inter-face appearance compatibility, interpersonal
gaze alignment, and face-body consistency. Guided by these insights, we
introduce \textsf{HICOM}, a novel framework designed to detect every fake face
in multi-face scenarios. Extensive experiments on benchmark datasets show that
\textsf{HICOM} improves average accuracy by 3.3\% in in-dataset detection and
2.8\% under real-world perturbations. Moreover, it outperforms existing methods
by 5.8\% on unseen datasets, demonstrating the generalization of human-inspired
cues. \textsf{HICOM} further enhances interpretability by incorporating an LLM
to provide human-readable explanations, making detection results more
transparent and convincing. Our work sheds light on involving human factors to
enhance defense against deepfakes.

</details>


### [56] [SegQuant: A Semantics-Aware and Generalizable Quantization Framework for Diffusion Models](https://arxiv.org/abs/2507.14811)
*Jiaji Zhang,Ruichao Sun,Hailiang Zhao,Jiaju Wu,Peng Chen,Hao Li,Xinkui Zhao,Kingsum Chow,Gang Xiong,Lin Ye,Shuiguang Deng*

Main category: cs.CV

TL;DR: SegQuant是一个统一的量化框架，通过自适应结合互补技术提升跨模型通用性，解决了扩散模型量化中的通用性和工业部署问题。


<details>
  <summary>Details</summary>
Motivation: 扩散模型计算成本高，现有后训练量化方法通用性不足，难以适应工业部署需求。

Method: 提出SegQuant框架，包含SegLinear（分段感知的图量化策略）和DualScale（双尺度量化方案），以保持生成输出的视觉保真度。

Result: SegQuant在多种扩散模型上表现优异，且与主流部署工具兼容。

Conclusion: SegQuant为扩散模型量化提供了通用且高效的解决方案，适合工业部署。

Abstract: Diffusion models have demonstrated exceptional generative capabilities but
are computationally intensive, posing significant challenges for deployment in
resource-constrained or latency-sensitive environments. Quantization offers an
effective means to reduce model size and computational cost, with post-training
quantization (PTQ) being particularly appealing due to its compatibility with
pre-trained models without requiring retraining or training data. However,
existing PTQ methods for diffusion models often rely on architecture-specific
heuristics that limit their generalizability and hinder integration with
industrial deployment pipelines. To address these limitations, we propose
SegQuant, a unified quantization framework that adaptively combines
complementary techniques to enhance cross-model versatility. SegQuant consists
of a segment-aware, graph-based quantization strategy (SegLinear) that captures
structural semantics and spatial heterogeneity, along with a dual-scale
quantization scheme (DualScale) that preserves polarity-asymmetric activations,
which is crucial for maintaining visual fidelity in generated outputs. SegQuant
is broadly applicable beyond Transformer-based diffusion models, achieving
strong performance while ensuring seamless compatibility with mainstream
deployment tools.

</details>


### [57] [FinChart-Bench: Benchmarking Financial Chart Comprehension in Vision-Language Models](https://arxiv.org/abs/2507.14823)
*Dong Shu,Haoyang Yuan,Yuchen Wang,Yanguang Liu,Huopu Zhang,Haiyan Zhao,Mengnan Du*

Main category: cs.CV

TL;DR: FinChart-Bench是首个专注于真实世界金融图表的基准测试，包含1,200张金融图表和7,016个问题，评估了25种LVLM模型，揭示了当前模型在金融图表理解中的局限性。


<details>
  <summary>Details</summary>
Motivation: 金融图表因其复杂的时间结构和领域特定术语，尚未被充分研究，因此需要专门的基准测试。

Method: 构建FinChart-Bench数据集，包含1,200张金融图表和7,016个问题，并对25种LVLM模型进行全面评估。

Result: 发现开源与闭源模型性能差距缩小、升级模型性能下降、模型在指令遵循和空间推理方面表现不佳，且当前LVLM不适合作为自动评估器。

Conclusion: 当前LVLM在金融图表理解中存在显著局限性，FinChart-Bench为未来研究提供了重要基准。

Abstract: Large vision-language models (LVLMs) have made significant progress in chart
understanding. However, financial charts, characterized by complex temporal
structures and domain-specific terminology, remain notably underexplored. We
introduce FinChart-Bench, the first benchmark specifically focused on
real-world financial charts. FinChart-Bench comprises 1,200 financial chart
images collected from 2015 to 2024, each annotated with True/False (TF),
Multiple Choice (MC), and Question Answering (QA) questions, totaling 7,016
questions. We conduct a comprehensive evaluation of 25 state-of-the-art LVLMs
on FinChart-Bench. Our evaluation reveals critical insights: (1) the
performance gap between open-source and closed-source models is narrowing, (2)
performance degradation occurs in upgraded models within families, (3) many
models struggle with instruction following, (4) both advanced models show
significant limitations in spatial reasoning abilities, and (5) current LVLMs
are not reliable enough to serve as automated evaluators. These findings
highlight important limitations in current LVLM capabilities for financial
chart understanding. The FinChart-Bench dataset is available at
https://huggingface.co/datasets/Tizzzzy/FinChart-Bench.

</details>


### [58] [PHATNet: A Physics-guided Haze Transfer Network for Domain-adaptive Real-world Image Dehazing](https://arxiv.org/abs/2507.14826)
*Fu-Jen Tsai,Yan-Tsung Peng,Yen-Yu Lin,Chia-Wen Lin*

Main category: cs.CV

TL;DR: PHATNet提出了一种基于物理引导的雾霾转移网络，通过将未见目标域的雾霾模式转移到源域无雾图像上，生成特定领域的微调数据集，从而提升去雾模型的域适应能力。


<details>
  <summary>Details</summary>
Motivation: 现有去雾模型在未见真实雾霾图像上性能下降明显，主要由于训练数据有限，因此需要一种灵活的域适应方法提升测试时的去雾效果。

Method: 提出PHATNet，通过转移雾霾模式生成域特定微调集，并引入雾霾转移一致性和内容泄漏损失以增强解耦能力。

Result: 实验表明，PHATNet显著提升了现有去雾模型在真实图像数据集上的性能。

Conclusion: PHATNet通过域适应和解耦损失设计，有效提升了去雾模型在未见真实雾霾图像上的表现。

Abstract: Image dehazing aims to remove unwanted hazy artifacts in images. Although
previous research has collected paired real-world hazy and haze-free images to
improve dehazing models' performance in real-world scenarios, these models
often experience significant performance drops when handling unseen real-world
hazy images due to limited training data. This issue motivates us to develop a
flexible domain adaptation method to enhance dehazing performance during
testing. Observing that predicting haze patterns is generally easier than
recovering clean content, we propose the Physics-guided Haze Transfer Network
(PHATNet) which transfers haze patterns from unseen target domains to
source-domain haze-free images, creating domain-specific fine-tuning sets to
update dehazing models for effective domain adaptation. Additionally, we
introduce a Haze-Transfer-Consistency loss and a Content-Leakage Loss to
enhance PHATNet's disentanglement ability. Experimental results demonstrate
that PHATNet significantly boosts state-of-the-art dehazing models on benchmark
real-world image dehazing datasets.

</details>


### [59] [Paired Image Generation with Diffusion-Guided Diffusion Models](https://arxiv.org/abs/2507.14833)
*Haoxuan Zhang,Wenju Cui,Yuzhu Cao,Tao Tan,Jie Liu,Yunsong Peng,Jian Zheng*

Main category: cs.CV

TL;DR: 提出了一种用于数字乳腺断层合成（DBT）图像中肿块分割的配对图像生成方法，解决了现有扩散模型在生成质量和标注数据不足方面的问题。


<details>
  <summary>Details</summary>
Motivation: 高密度乳腺组织导致肿块隐蔽，手动标注困难且耗时，现有扩散模型生成质量低且无法生成标注，限制了监督训练的效果。

Method: 通过训练额外的扩散引导器，实现条件扩散模型的配对图像生成，无需外部条件。

Result: 实验表明，该方法提高了生成质量，缓解了标注数据短缺问题，并提升了下游任务的性能。

Conclusion: 提出的方法在无外部条件下有效生成高质量配对图像，有助于改善肿块分割任务的监督训练效果。

Abstract: The segmentation of mass lesions in digital breast tomosynthesis (DBT) images
is very significant for the early screening of breast cancer. However, the
high-density breast tissue often leads to high concealment of the mass lesions,
which makes manual annotation difficult and time-consuming. As a result, there
is a lack of annotated data for model training. Diffusion models are commonly
used for data augmentation, but the existing methods face two challenges.
First, due to the high concealment of lesions, it is difficult for the model to
learn the features of the lesion area. This leads to the low generation quality
of the lesion areas, thus limiting the quality of the generated images. Second,
existing methods can only generate images and cannot generate corresponding
annotations, which restricts the usability of the generated images in
supervised training. In this work, we propose a paired image generation method.
The method does not require external conditions and can achieve the generation
of paired images by training an extra diffusion guider for the conditional
diffusion model. During the experimental phase, we generated paired DBT slices
and mass lesion masks. Then, we incorporated them into the supervised training
process of the mass lesion segmentation task. The experimental results show
that our method can improve the generation quality without external conditions.
Moreover, it contributes to alleviating the shortage of annotated data, thus
enhancing the performance of downstream tasks.

</details>


### [60] [Training Self-Supervised Depth Completion Using Sparse Measurements and a Single Image](https://arxiv.org/abs/2507.14845)
*Rizhao Fan,Zhigen Li,Heping Li,Ning An*

Main category: cs.CV

TL;DR: 提出了一种仅需稀疏深度测量和对应图像的自监督深度补全方法，无需密集标签或多帧数据。


<details>
  <summary>Details</summary>
Motivation: 密集深度标注成本高，多帧依赖限制了自监督方法在静态或单帧场景的应用。

Method: 利用深度分布特性设计新损失函数，结合视觉基础模型的分割图增强深度估计。

Result: 实验证明该方法有效。

Conclusion: 新方法解决了密集标签和多帧依赖的限制，提升了深度补全效果。

Abstract: Depth completion is an important vision task, and many efforts have been made
to enhance the quality of depth maps from sparse depth measurements. Despite
significant advances, training these models to recover dense depth from sparse
measurements remains a challenging problem. Supervised learning methods rely on
dense depth labels to predict unobserved regions, while self-supervised
approaches require image sequences to enforce geometric constraints and
photometric consistency between frames. However, acquiring dense annotations is
costly, and multi-frame dependencies limit the applicability of self-supervised
methods in static or single-frame scenarios. To address these challenges, we
propose a novel self-supervised depth completion paradigm that requires only
sparse depth measurements and their corresponding image for training. Unlike
existing methods, our approach eliminates the need for dense depth labels or
additional images captured from neighboring viewpoints. By leveraging the
characteristics of depth distribution, we design novel loss functions that
effectively propagate depth information from observed points to unobserved
regions. Additionally, we incorporate segmentation maps generated by vision
foundation models to further enhance depth estimation. Extensive experiments
demonstrate the effectiveness of our proposed method.

</details>


### [61] [Grounding Degradations in Natural Language for All-In-One Video Restoration](https://arxiv.org/abs/2507.14851)
*Muhammad Kamran Janjua,Amirhosein Ghasemabadi,Kunlin Zhang,Mohammad Salameh,Chao Gao,Di Niu*

Main category: cs.CV

TL;DR: 提出了一种基于自然语言描述的视频修复框架，无需预知退化类型，通过基础模型提供可解释的灵活指导，并在多个新基准测试中取得最优性能。


<details>
  <summary>Details</summary>
Motivation: 现有视频修复方法通常需要预知退化类型，限制了灵活性和实用性。本文旨在通过自然语言描述实现无需退化知识的视频修复。

Method: 利用基础模型从视频帧中提取退化感知的语义上下文，并将其转化为自然语言描述，从而提供可解释的修复指导。训练时学习退化知识的近似表示，推理时无需额外成本。

Result: 在多个新提出的基准测试（包括多退化和时变复合退化）上，该方法均优于现有方法，达到最优性能。

Conclusion: 该框架为视频修复提供了一种无需退化知识的灵活解决方案，并呼吁标准化基准测试以推动领域发展。

Abstract: In this work, we propose an all-in-one video restoration framework that
grounds degradation-aware semantic context of video frames in natural language
via foundation models, offering interpretable and flexible guidance. Unlike
prior art, our method assumes no degradation knowledge in train or test time
and learns an approximation to the grounded knowledge such that the foundation
model can be safely disentangled during inference adding no extra cost.
Further, we call for standardization of benchmarks in all-in-one video
restoration, and propose two benchmarks in multi-degradation setting,
three-task (3D) and four-task (4D), and two time-varying composite degradation
benchmarks; one of the latter being our proposed dataset with varying snow
intensity, simulating how weather degradations affect videos naturally. We
compare our method with prior works and report state-of-the-art performance on
all benchmarks.

</details>


### [62] [An Uncertainty-aware DETR Enhancement Framework for Object Detection](https://arxiv.org/abs/2507.14855)
*Xingshu Chen,Sicheng Yu,Chong Cheng,Hao Wang,Ting Tian*

Main category: cs.CV

TL;DR: 本文提出了一种基于DETR的不确定性感知增强框架，通过建模边界框为多元高斯分布并引入Gromov-Wasserstein距离损失，提升定位精度和预测可靠性。


<details>
  <summary>Details</summary>
Motivation: 传统检测器忽略预测不确定性，限制了模型的鲁棒性。本文旨在通过显式建模不确定性来改进DETR检测器的性能。

Method: 将边界框建模为多元高斯分布，引入Gromov-Wasserstein距离损失，并提出贝叶斯风险公式过滤高风险信息。此外，提出了一种量化定位不确定性的算法。

Result: 在COCO基准测试中有效提升了DETR变体的性能，并在白细胞检测任务（LISC和WBCDD数据集）上取得了最先进的结果。

Conclusion: 该框架在通用和特定领域检测任务中均具有可扩展性，验证了其有效性。

Abstract: This paper investigates the problem of object detection with a focus on
improving both the localization accuracy of bounding boxes and explicitly
modeling prediction uncertainty. Conventional detectors rely on deterministic
bounding box regression, ignoring uncertainty in predictions and limiting model
robustness. In this paper, we propose an uncertainty-aware enhancement
framework for DETR-based object detectors. We model bounding boxes as
multivariate Gaussian distributions and incorporate the Gromov-Wasserstein
distance into the loss function to better align the predicted and ground-truth
distributions. Building on this, we derive a Bayes Risk formulation to filter
high-risk information and improve detection reliability. We also propose a
simple algorithm to quantify localization uncertainty via confidence intervals.
Experiments on the COCO benchmark show that our method can be effectively
integrated into existing DETR variants, enhancing their performance. We further
extend our framework to leukocyte detection tasks, achieving state-of-the-art
results on the LISC and WBCDD datasets. These results confirm the scalability
of our framework across both general and domain-specific detection tasks. Code
page:
https://github.com/ParadiseforAndaChen/An-Uncertainty-aware-DETR-Enhancement-Framework-for-Object-Detection.

</details>


### [63] [Hybrid-supervised Hypergraph-enhanced Transformer for Micro-gesture Based Emotion Recognition](https://arxiv.org/abs/2507.14867)
*Zhaoqiang Xia,Hexiang Huang,Haoyu Chen,Xiaoyi Feng,Guoying Zhao*

Main category: cs.CV

TL;DR: 本文提出了一种基于微手势的情感识别方法，通过超图增强的Transformer在混合监督框架下重建行为模式，并在两个公开数据集上取得了最佳性能。


<details>
  <summary>Details</summary>
Motivation: 微手势能传达人类情感状态，但基于微手势的情感建模尚未充分探索。

Method: 使用超图增强的Transformer编码器和解码器，结合自监督和监督学习，设计了超图增强的自注意力模块和情感识别头。

Result: 在两个公开数据集（iMiGUE和SMG）上，该方法在多项指标上优于现有方法。

Conclusion: 提出的方法有效捕捉微手势的细微运动，实现了情感识别的最佳性能。

Abstract: Micro-gestures are unconsciously performed body gestures that can convey the
emotion states of humans and start to attract more research attention in the
fields of human behavior understanding and affective computing as an emerging
topic. However, the modeling of human emotion based on micro-gestures has not
been explored sufficiently. In this work, we propose to recognize the emotion
states based on the micro-gestures by reconstructing the behavior patterns with
a hypergraph-enhanced Transformer in a hybrid-supervised framework. In the
framework, hypergraph Transformer based encoder and decoder are separately
designed by stacking the hypergraph-enhanced self-attention and multiscale
temporal convolution modules. Especially, to better capture the subtle motion
of micro-gestures, we construct a decoder with additional upsampling operations
for a reconstruction task in a self-supervised learning manner. We further
propose a hypergraph-enhanced self-attention module where the hyperedges
between skeleton joints are gradually updated to present the relationships of
body joints for modeling the subtle local motion. Lastly, for exploiting the
relationship between the emotion states and local motion of micro-gestures, an
emotion recognition head from the output of encoder is designed with a shallow
architecture and learned in a supervised way. The end-to-end framework is
jointly trained in a one-stage way by comprehensively utilizing
self-reconstruction and supervision information. The proposed method is
evaluated on two publicly available datasets, namely iMiGUE and SMG, and
achieves the best performance under multiple metrics, which is superior to the
existing methods.

</details>


### [64] [Region-aware Depth Scale Adaptation with Sparse Measurements](https://arxiv.org/abs/2507.14879)
*Rizhao Fan,Tianfang Ma,Zhigen Li,Ning An,Jian Cheng*

Main category: cs.CV

TL;DR: 提出了一种无需训练或微调的方法，利用稀疏深度测量将基础模型的相对尺度深度预测转换为度量尺度深度。


<details>
  <summary>Details</summary>
Motivation: 基础模型的深度预测通常为相对尺度，限制了实际应用。现有方法成本高且可能损害模型的泛化能力。

Method: 非学习型方法，利用稀疏深度测量调整相对尺度预测为度量尺度。

Result: 实验证明方法有效，能在不增加计算成本或牺牲泛化能力的情况下实现度量深度预测。

Conclusion: 该方法为相对尺度与度量尺度深度之间的转换提供了高效解决方案。

Abstract: In recent years, the emergence of foundation models for depth prediction has
led to remarkable progress, particularly in zero-shot monocular depth
estimation. These models generate impressive depth predictions; however, their
outputs are often in relative scale rather than metric scale. This limitation
poses challenges for direct deployment in real-world applications. To address
this, several scale adaptation methods have been proposed to enable foundation
models to produce metric depth. However, these methods are typically costly, as
they require additional training on new domains and datasets. Moreover,
fine-tuning these models often compromises their original generalization
capabilities, limiting their adaptability across diverse scenes. In this paper,
we introduce a non-learning-based approach that leverages sparse depth
measurements to adapt the relative-scale predictions of foundation models into
metric-scale depth. Our method requires neither retraining nor fine-tuning,
thereby preserving the strong generalization ability of the original foundation
models while enabling them to produce metric depth. Experimental results
demonstrate the effectiveness of our approach, high-lighting its potential to
bridge the gap between relative and metric depth without incurring additional
computational costs or sacrificing generalization ability.

</details>


### [65] [BeatFormer: Efficient motion-robust remote heart rate estimation through unsupervised spectral zoomed attention filters](https://arxiv.org/abs/2507.14885)
*Joaquim Comas,Federico Sukno*

Main category: cs.CV

TL;DR: BeatFormer是一个轻量级光谱注意力模型，结合了手工方法和深度学习的优势，用于远程光电容积描记术（rPPG）估计，并通过光谱对比学习（SCL）实现无标签训练。


<details>
  <summary>Details</summary>
Motivation: 现有rPPG方法中，手工方法泛化能力强但性能有限，深度学习方法性能优越但依赖大数据集。需要一种结合两者优势的混合方法。

Method: 提出BeatFormer模型，整合了缩放正交复数注意力和频域能量测量，并引入SCL实现无标签训练。

Result: 在PURE、UBFC-rPPG和MMPD数据集上验证了BeatFormer的鲁棒性和性能，尤其在运动场景下的跨数据集评估中表现优异。

Conclusion: BeatFormer通过结合手工方法和深度学习的优势，提供了一种高效且泛化能力强的rPPG解决方案。

Abstract: Remote photoplethysmography (rPPG) captures cardiac signals from facial
videos and is gaining attention for its diverse applications. While deep
learning has advanced rPPG estimation, it relies on large, diverse datasets for
effective generalization. In contrast, handcrafted methods utilize
physiological priors for better generalization in unseen scenarios like motion
while maintaining computational efficiency. However, their linear assumptions
limit performance in complex conditions, where deep learning provides superior
pulsatile information extraction. This highlights the need for hybrid
approaches that combine the strengths of both methods. To address this, we
present BeatFormer, a lightweight spectral attention model for rPPG estimation,
which integrates zoomed orthonormal complex attention and frequency-domain
energy measurement, enabling a highly efficient model. Additionally, we
introduce Spectral Contrastive Learning (SCL), which allows BeatFormer to be
trained without any PPG or HR labels. We validate BeatFormer on the PURE,
UBFC-rPPG, and MMPD datasets, demonstrating its robustness and performance,
particularly in cross-dataset evaluations under motion scenarios.

</details>


### [66] [TriCLIP-3D: A Unified Parameter-Efficient Framework for Tri-Modal 3D Visual Grounding based on CLIP](https://arxiv.org/abs/2507.14904)
*Fan Li,Zanyi Wang,Zeyi Huang,Guang Dai,Jingdong Wang,Mengmeng Wang*

Main category: cs.CV

TL;DR: 提出了一种基于2D预训练多模态网络的统一方法，简化了3D视觉定位的架构，减少了参数并提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有3D视觉定位方法依赖多模态分离编码器，导致模型复杂且训练低效，需要改进。

Method: 利用2D CLIP双模态模型，通过适配器微调适应三模态设置，结合GARF模块融合几何特征和多模态解码器。

Result: 参数减少58%，3D检测任务提升6.52%，3D视觉定位任务提升6.25%。

Conclusion: 统一方法显著简化架构并提升性能，为3D视觉定位提供了高效解决方案。

Abstract: 3D visual grounding allows an embodied agent to understand visual information
in real-world 3D environments based on human instructions, which is crucial for
embodied intelligence. Existing 3D visual grounding methods typically rely on
separate encoders for different modalities (e.g., RGB images, text, and 3D
point clouds), resulting in large and complex models that are inefficient to
train. While some approaches use pre-trained 2D multi-modal models like CLIP
for 3D tasks, they still struggle with aligning point cloud data to 2D
encoders. As a result, these methods continue to depend on 3D encoders for
feature extraction, further increasing model complexity and training
inefficiency. In this paper, we propose a unified 2D pre-trained multi-modal
network to process all three modalities (RGB images, text, and point clouds),
significantly simplifying the architecture. By leveraging a 2D CLIP bi-modal
model with adapter-based fine-tuning, this framework effectively adapts to the
tri-modal setting, improving both adaptability and performance across
modalities. Our Geometric-Aware 2D-3D Feature Recovery and Fusion (GARF) module
is designed to fuse geometric multi-scale features from point clouds and
images. We then integrate textual features for final modality fusion and
introduce a multi-modal decoder to facilitate deep cross-modal understanding.
Together, our method achieves unified feature extraction and fusion across the
three modalities, enabling an end-to-end 3D visual grounding model. Compared to
the baseline, our method reduces the number of trainable parameters by
approximately 58\%, while achieving a 6.52\% improvement in the 3D detection
task and a 6.25\% improvement in the 3D visual grounding task.

</details>


### [67] [Semantic-Aware Representation Learning for Multi-label Image Classification](https://arxiv.org/abs/2507.14918)
*Ren-Dong Xie,Zhi-Fen He,Bo Li,Bin Liu,Jin-Yan Hu*

Main category: cs.CV

TL;DR: 提出了一种语义感知表示学习方法（SARL），用于多标签图像分类，通过语义相关特征学习和最优传输注意力机制提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如注意力机制或图卷积网络）的表示可能包含噪声且无法精确定位对象，因此需要更精确的语义表示。

Method: 1. 使用标签语义相关特征学习模块提取特征；2. 设计基于最优传输的注意力机制；3. 采用区域分数聚合策略进行多标签预测。

Result: 在PASCAL VOC 2007和MS-COCO数据集上，SARL优于现有方法。

Conclusion: SARL通过语义对齐和精确表示，显著提升了多标签图像分类的性能。

Abstract: Multi-label image classification, an important research area in computer
vision, focuses on identifying multiple labels or concepts within an image.
Existing approaches often employ attention mechanisms or graph convolutional
networks (GCNs) to learn image representation. However, this representation may
contain noise and may not locate objects precisely. Therefore, this paper
proposes a Semantic-Aware Representation Learning (SARL) for multi-label image
classification. First, a label semantic-related feature learning module is
utilized to extract semantic-related features. Then, an optimal transport-based
attention mechanism is designed to obtain semantically aligned image
representation. Finally, a regional score aggregation strategy is used for
multi-label prediction. Experimental results on two benchmark datasets, PASCAL
VOC 2007 and MS-COCO, demonstrate the superiority of SARL over existing
methods.

</details>


### [68] [Stereo-GS: Multi-View Stereo Vision Model for Generalizable 3D Gaussian Splatting Reconstruction](https://arxiv.org/abs/2507.14921)
*Xiufeng Huang,Ka Chun Cheung,Runmin Cong,Simon See,Renjie Wan*

Main category: cs.CV

TL;DR: 提出了一种解耦框架\method，用于高效预测3D高斯分布，通过立体视觉提取特征并融合，实现无姿态的高质量3D重建。


<details>
  <summary>Details</summary>
Motivation: 现有方法在3D高斯几何和外观预测上耦合度高，依赖数据驱动先验且回归速度慢，需大量计算资源和数据。

Method: 使用立体视觉骨干网络提取局部图像对特征，通过全局注意力块融合，生成几何点图和外观高斯特征，结合为GS图表示3D对象，并通过细化网络提升质量。

Result: 实现了无姿态的3D重建，提高了鲁棒性和实用性，同时减少了资源需求。

Conclusion: \method为实际3D内容生成提供了高效、可扩展的解决方案。

Abstract: Generalizable 3D Gaussian Splatting reconstruction showcases advanced
Image-to-3D content creation but requires substantial computational resources
and large datasets, posing challenges to training models from scratch. Current
methods usually entangle the prediction of 3D Gaussian geometry and appearance,
which rely heavily on data-driven priors and result in slow regression speeds.
To address this, we propose \method, a disentangled framework for efficient 3D
Gaussian prediction. Our method extracts features from local image pairs using
a stereo vision backbone and fuses them via global attention blocks. Dedicated
point and Gaussian prediction heads generate multi-view point-maps for geometry
and Gaussian features for appearance, combined as GS-maps to represent the 3DGS
object. A refinement network enhances these GS-maps for high-quality
reconstruction. Unlike existing methods that depend on camera parameters, our
approach achieves pose-free 3D reconstruction, improving robustness and
practicality. By reducing resource demands while maintaining high-quality
outputs, \method provides an efficient, scalable solution for real-world 3D
content generation.

</details>


### [69] [3-Dimensional CryoEM Pose Estimation and Shift Correction Pipeline](https://arxiv.org/abs/2507.14924)
*Kaishva Chintan Shah,Virajith Boddapati,Karthik S. Gurumoorthy,Sandip Kaledhonkar,Ajit Rajwade*

Main category: cs.CV

TL;DR: 提出了一种基于多维度缩放（MDS）的稳健方法，用于冷冻电镜（cryo-EM）中的姿态估计和位移校正，通过鲁棒优化和迭代位移校正提升3D重建精度。


<details>
  <summary>Details</summary>
Motivation: 冷冻电镜中极低信噪比（SNR）导致姿态估计和位移校正困难，直接影响3D重建的准确性。

Method: 利用MDS技术估计旋转矩阵，结合鲁棒优化框架（ℓ₁范数目标）和迭代位移校正算法，确保单位范数和正交约束。

Result: 在欧拉角精度和重建保真度（FSC测量）上优于现有方法。

Conclusion: 该方法通过鲁棒优化和全局一致性校正，显著提升了低SNR条件下的姿态估计和重建效果。

Abstract: Accurate pose estimation and shift correction are key challenges in cryo-EM
due to the very low SNR, which directly impacts the fidelity of 3D
reconstructions. We present an approach for pose estimation in cryo-EM that
leverages multi-dimensional scaling (MDS) techniques in a robust manner to
estimate the 3D rotation matrix of each particle from pairs of dihedral angles.
We express the rotation matrix in the form of an axis of rotation and a unit
vector in the plane perpendicular to the axis. The technique leverages the
concept of common lines in 3D reconstruction from projections. However, common
line estimation is ridden with large errors due to the very low SNR of cryo-EM
projection images. To address this challenge, we introduce two complementary
components: (i) a robust joint optimization framework for pose estimation based
on an $\ell_1$-norm objective or a similar robust norm, which simultaneously
estimates rotation axes and in-plane vectors while exactly enforcing unit norm
and orthogonality constraints via projected coordinate descent; and (ii) an
iterative shift correction algorithm that estimates consistent in-plane
translations through a global least-squares formulation. While prior approaches
have leveraged such embeddings and common-line geometry for orientation
recovery, existing formulations typically rely on $\ell_2$-based objectives
that are sensitive to noise, and enforce geometric constraints only
approximately. These choices, combined with a sequential pipeline structure,
can lead to compounding errors and suboptimal reconstructions in low-SNR
regimes. Our pipeline consistently outperforms prior methods in both Euler
angle accuracy and reconstruction fidelity, as measured by the Fourier Shell
Correlation (FSC).

</details>


### [70] [Probabilistic smooth attention for deep multiple instance learning in medical imaging](https://arxiv.org/abs/2507.14932)
*Francisco M. Castro-Macías,Pablo Morales-Álvarez,Yunan Wu,Rafael Molina,Aggelos K. Katsaggelos*

Main category: cs.CV

TL;DR: 提出了一种新的概率框架，用于多实例学习（MIL）中的注意力机制，通过估计注意力值的概率分布来捕捉全局和局部交互，并在医学图像分类中取得了优异性能。


<details>
  <summary>Details</summary>
Motivation: 现有MIL方法通常确定性处理注意力值，忽略了实例贡献的不确定性，限制了模型的解释性和性能。

Method: 提出概率框架，估计注意力值的概率分布，同时考虑全局和局部交互。

Result: 在三个医学数据集和十一个基线模型上，该方法在预测性能和不确定性解释性方面表现最佳。

Conclusion: 概率化注意力机制不仅提升了预测性能，还提供了可解释的不确定性映射，有助于疾病定位。

Abstract: The Multiple Instance Learning (MIL) paradigm is attracting plenty of
attention in medical imaging classification, where labeled data is scarce. MIL
methods cast medical images as bags of instances (e.g. patches in whole slide
images, or slices in CT scans), and only bag labels are required for training.
Deep MIL approaches have obtained promising results by aggregating
instance-level representations via an attention mechanism to compute the
bag-level prediction. These methods typically capture both local interactions
among adjacent instances and global, long-range dependencies through various
mechanisms. However, they treat attention values deterministically, potentially
overlooking uncertainty in the contribution of individual instances. In this
work we propose a novel probabilistic framework that estimates a probability
distribution over the attention values, and accounts for both global and local
interactions. In a comprehensive evaluation involving {\color{review} eleven}
state-of-the-art baselines and three medical datasets, we show that our
approach achieves top predictive performance in different metrics. Moreover,
the probabilistic treatment of the attention provides uncertainty maps that are
interpretable in terms of illness localization.

</details>


### [71] [Open-set Cross Modal Generalization via Multimodal Unified Representation](https://arxiv.org/abs/2507.14935)
*Hai Huang,Yan Xia,Shulei Wang,Hanting Wang,Minghui Fang,Shengpeng Ji,Sashuai Zhou,Tao Jin,Zhou Zhao*

Main category: cs.CV

TL;DR: 论文提出开放集跨模态泛化（OSCMG）任务，扩展了跨模态泛化（CMG）到开放集环境，并提出了MICU方法，包含FCMI和CUJP两个组件，实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有跨模态统一表示方法未考虑开放集环境，而真实场景常需处理未见类别和新模态，因此提出OSCMG任务以填补这一空白。

Method: 提出MICU方法，包括FCMI（细粒度与粗粒度掩码多模态对比学习）和CUJP（跨模态统一拼图），分别增强多模态对齐和特征多样性。

Result: 在CMG和新提出的OSCMG任务上进行了广泛实验，验证了方法的有效性。

Conclusion: MICU方法通过FCMI和CUJP有效解决了开放集跨模态泛化问题，填补了现有研究的不足。

Abstract: This paper extends Cross Modal Generalization (CMG) to open-set environments
by proposing the more challenging Open-set Cross Modal Generalization (OSCMG)
task. This task evaluates multimodal unified representations in open-set
conditions, addressing the limitations of prior closed-set cross-modal
evaluations. OSCMG requires not only cross-modal knowledge transfer but also
robust generalization to unseen classes within new modalities, a scenario
frequently encountered in real-world applications. Existing multimodal unified
representation work lacks consideration for open-set environments. To tackle
this, we propose MICU, comprising two key components: Fine-Coarse Masked
multimodal InfoNCE (FCMI) and Cross modal Unified Jigsaw Puzzles (CUJP). FCMI
enhances multimodal alignment by applying contrastive learning at both holistic
semantic and temporal levels, incorporating masking to enhance generalization.
CUJP enhances feature diversity and model uncertainty by integrating
modality-agnostic feature selection with self-supervised learning, thereby
strengthening the model's ability to handle unknown categories in open-set
tasks. Extensive experiments on CMG and the newly proposed OSCMG validate the
effectiveness of our approach. The code is available at
https://github.com/haihuangcode/CMG.

</details>


### [72] [Polymorph: Energy-Efficient Multi-Label Classification for Video Streams on Embedded Devices](https://arxiv.org/abs/2507.14959)
*Saeid Ghafouri,Mohsen Fayyaz,Xiangchen Li,Deepu John,Bo Ji,Dimitrios Nikolopoulos,Hans Vandierendonck*

Main category: cs.CV

TL;DR: Polymorph是一个实时多标签视频分类框架，通过动态激活轻量级适配器（LoRA）来降低能耗并提高性能。


<details>
  <summary>Details</summary>
Motivation: 嵌入式设备上的实时多标签视频分类受限于计算和能源预算，但视频流具有标签稀疏性、时间连续性和标签共现性等结构特性，可被利用以提高效率。

Method: Polymorph框架动态选择和组合轻量级LoRA适配器，每个适配器专注于基于共现模式的子类，避免了全模型切换和权重合并。

Result: 在TAO数据集上，Polymorph能耗降低40%，mAP提高9个百分点。

Conclusion: Polymorph通过模块化策略显著提升了嵌入式设备上视频分类的效率和性能。

Abstract: Real-time multi-label video classification on embedded devices is constrained
by limited compute and energy budgets. Yet, video streams exhibit structural
properties such as label sparsity, temporal continuity, and label co-occurrence
that can be leveraged for more efficient inference. We introduce Polymorph, a
context-aware framework that activates a minimal set of lightweight Low Rank
Adapters (LoRA) per frame. Each adapter specializes in a subset of classes
derived from co-occurrence patterns and is implemented as a LoRA weight over a
shared backbone. At runtime, Polymorph dynamically selects and composes only
the adapters needed to cover the active labels, avoiding full-model switching
and weight merging. This modular strategy improves scalability while reducing
latency and energy overhead. Polymorph achieves 40% lower energy consumption
and improves mAP by 9 points over strong baselines on the TAO dataset.
Polymorph is open source at https://github.com/inference-serving/polymorph/.

</details>


### [73] [Decision PCR: Decision version of the Point Cloud Registration task](https://arxiv.org/abs/2507.14965)
*Yaojie Zhang,Tianlun Huang,Weijun Wang,Wei Feng*

Main category: cs.CV

TL;DR: 本文提出了一种数据驱动的方法来解决低重叠点云配准（PCR）任务中的评估问题，通过深度学习框架显著提升了现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 传统评估指标在极低内点率下失效，因此需要重新审视PCR任务的评估问题。

Method: 构建基于3DMatch的数据集，训练深度学习分类器评估配准质量，并将其集成到标准PCR流程中。

Result: 与GeoTransformer结合后，在3DLoMatch基准上达到86.97%的配准召回率，并在ETH数据集上表现出强泛化能力。

Conclusion: 该方法首次通过深度学习框架解决了PCR任务评估问题，显著提升了配准性能。

Abstract: Low-overlap point cloud registration (PCR) remains a significant challenge in
3D vision. Traditional evaluation metrics, such as Maximum Inlier Count, become
ineffective under extremely low inlier ratios. In this paper, we revisit the
registration result evaluation problem and identify the Decision version of the
PCR task as the fundamental problem. To address this Decision PCR task, we
propose a data-driven approach. First, we construct a corresponding dataset
based on the 3DMatch dataset. Then, a deep learning-based classifier is trained
to reliably assess registration quality, overcoming the limitations of
traditional metrics. To our knowledge, this is the first comprehensive study to
address this task through a deep learning framework. We incorporate this
classifier into standard PCR pipelines. When integrated with our approach,
existing state-of-the-art PCR methods exhibit significantly enhanced
registration performance. For example, combining our framework with
GeoTransformer achieves a new SOTA registration recall of 86.97\% on the
challenging 3DLoMatch benchmark. Our method also demonstrates strong
generalization capabilities on the unseen outdoor ETH dataset.

</details>


### [74] [Hierarchical Cross-modal Prompt Learning for Vision-Language Models](https://arxiv.org/abs/2507.14976)
*Hao Zheng,Shunzhi Yang,Zhuoxin He,Jinfeng Yang,Zhenhua Huang*

Main category: cs.CV

TL;DR: HiCroPL提出了一种分层跨模态提示学习框架，通过双向知识流解决模态隔离和语义衰减问题，显著提升了预训练视觉语言模型的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 预训练视觉语言模型（如CLIP）在下游任务中的适应性和泛化能力仍面临挑战，尤其是模态隔离和分层语义衰减问题。

Method: HiCroPL通过分层知识映射器和轻量级知识代理，实现文本和视觉模态的双向知识流，增强低层视觉语义表示和高层语义对齐。

Result: 在11个基准测试中取得最优性能，显著提升了模型泛化能力。

Conclusion: HiCroPL通过跨模态知识流和分层语义融合，有效解决了现有方法的局限性，为视觉语言模型的适应性和泛化提供了新思路。

Abstract: Pre-trained Vision-Language Models (VLMs) such as CLIP have shown excellent
generalization abilities. However, adapting these large-scale models to
downstream tasks while preserving their generalization capabilities remains
challenging. Although prompt learning methods have shown promise, they suffer
from two fundamental bottlenecks that limit generalization: (a) modality
isolation, and (b) hierarchical semantic decay. To address these limitations,
we propose HiCroPL, a Hierarchical Cross-modal Prompt Learning framework that
establishes bidirectional knowledge flow between text and vision modalities,
enabling them to refine their semantics mutually. HiCroPL routes knowledge
flows by leveraging the complementary strengths of text and vision. In early
layers, text prompts inject relatively clear semantics into visual prompts
through a hierarchical knowledge mapper, enhancing the representation of
low-level visual semantics. In later layers, visual prompts encoding specific
task-relevant objects flow back to refine text prompts, enabling deeper
alignment. Crucially, our hierarchical knowledge mapper allows representations
at multi-scales to be fused, ensuring that deeper representations retain
transferable shallow semantics thereby enhancing generalization. We further
introduce a lightweight layer-specific knowledge proxy to enable efficient
cross-modal interactions. Extensive evaluations across four tasks demonstrate
HiCroPL's superior performance, achieving state-of-the-art results on 11
benchmarks with significant improvements. Code is available at:
https://github.com/zzeoZheng/HiCroPL.

</details>


### [75] [Language Integration in Fine-Tuning Multimodal Large Language Models for Image-Based Regression](https://arxiv.org/abs/2507.14997)
*Roy H. Jennings,Genady Paikin,Roy Shaul,Evgeny Soloveichik*

Main category: cs.CV

TL;DR: 论文提出RvTC方法，通过灵活的基于分箱的分类替代预设词汇分类，在图像回归任务中实现最优性能，并证明语义提示能显著提升多模态大语言模型的表现。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在图像回归任务中表现不佳，预设词汇和通用提示无法利用文本输入的语义信息。

Method: 提出Regression via Transformer-Based Classification (RvTC)，采用基于分箱的灵活分类方法，并引入数据特定的语义提示。

Result: 在四个图像评估数据集上实现最优性能，AVA数据集中语义提示将相关性从0.83提升至0.90。

Conclusion: 语义提示和多模态理解的结合对提升图像回归任务性能至关重要。

Abstract: Multimodal Large Language Models (MLLMs) show promise for image-based
regression tasks, but current approaches face key limitations. Recent methods
fine-tune MLLMs using preset output vocabularies and generic task-level prompts
(e.g., "How would you rate this image?"), assuming this mimics human rating
behavior. Our analysis reveals these approaches provide no benefit over
image-only training. Models using preset vocabularies and generic prompts
perform equivalently to image-only models, failing to leverage semantic
understanding from textual input. We propose Regression via Transformer-Based
Classification (RvTC), which replaces vocabulary-constrained classification
with a flexible bin-based approach. Unlike approaches that address
discretization errors through complex distributional modeling, RvTC eliminates
manual vocabulary crafting through straightforward bin increase, achieving
state-of-the-art performance on four image assessment datasets using only
images. More importantly, we demonstrate that data-specific prompts
dramatically improve performance. Unlike generic task descriptions, prompts
containing semantic information about specific images enable MLLMs to leverage
cross-modal understanding. On the AVA dataset, adding challenge titles to
prompts improves correlations from 0.83 to 0.90, a new state-of-the-art. We
demonstrate through empirical evidence from the AVA and AGIQA-3k datasets that
MLLMs benefit from semantic prompt information surpassing mere statistical
biases. This underscores the importance of incorporating meaningful textual
context in multimodal regression tasks.

</details>


### [76] [Axis-Aligned Document Dewarping](https://arxiv.org/abs/2507.15000)
*Chaoyun Wang,I-Chao Shen,Takeo Igarashi,Nanning Zheng,Caigui Jiang*

Main category: cs.CV

TL;DR: 提出了一种基于轴对齐几何约束的文档去扭曲方法，显著提升了去扭曲效果。


<details>
  <summary>Details</summary>
Motivation: 现有学习方法依赖标注数据，未充分利用物理文档的几何特性。

Method: 在训练阶段引入轴对齐几何约束，推理阶段采用轴对齐预处理策略。

Result: 在多个基准测试中达到SOTA，AAD指标提升18.2%~34.5%。

Conclusion: 该方法通过几何约束和预处理策略，显著提升了文档去扭曲的性能和鲁棒性。

Abstract: Document dewarping is crucial for many applications. However, existing
learning-based methods primarily rely on supervised regression with annotated
data without leveraging the inherent geometric properties in physical documents
to the dewarping process. Our key insight is that a well-dewarped document is
characterized by transforming distorted feature lines into axis-aligned ones.
This property aligns with the inherent axis-aligned nature of the discrete grid
geometry in planar documents. In the training phase, we propose an axis-aligned
geometric constraint to enhance document dewarping. In the inference phase, we
propose an axis alignment preprocessing strategy to reduce the dewarping
difficulty. In the evaluation phase, we introduce a new metric, Axis-Aligned
Distortion (AAD), that not only incorporates geometric meaning and aligns with
human visual perception but also demonstrates greater robustness. As a result,
our method achieves SOTA results on multiple existing benchmarks and achieves
18.2%~34.5% improvements on the AAD metric.

</details>


### [77] [FastSmoothSAM: A Fast Smooth Method For Segment Anything Model](https://arxiv.org/abs/2507.15008)
*Jiasheng Xu,Yewang Chen*

Main category: cs.CV

TL;DR: 本文提出了一种基于B样条曲线拟合的方法，用于改进FastSAM中的锯齿边缘问题，提升分割精度并保持实时处理能力。


<details>
  <summary>Details</summary>
Motivation: FastSAM在实时图像分割中表现优异，但生成的边缘存在锯齿问题，影响分割质量和实际应用效果。

Method: 采用B样条曲线拟合技术，通过四阶段精炼过程（包括两轮曲线拟合）平滑锯齿边缘。

Result: 显著提升了边缘的视觉质量和分析准确性，同时保持了实时处理能力。

Conclusion: 该方法增强了FastSAM的实用性，适用于工业自动化、医疗成像等需要高精度边缘识别的场景。

Abstract: Accurately identifying and representing object edges is a challenging task in
computer vision and image processing. The Segment Anything Model (SAM) has
significantly influenced the field of image segmentation, but suffers from high
memory consumption and long inference times, limiting its efficiency in
real-time applications. To address these limitations, Fast Segment Anything
(FastSAM) was proposed, achieving real-time segmentation. However, FastSAM
often generates jagged edges that deviate from the true object shapes.
Therefore, this paper introduces a novel refinement approach using B-Spline
curve fitting techniques to enhance the edge quality in FastSAM. Leveraging the
robust shape control and flexible geometric construction of B-Splines, a
four-stage refining process involving two rounds of curve fitting is employed
to effectively smooth jagged edges. This approach significantly improves the
visual quality and analytical accuracy of object edges without compromising
critical geometric information. The proposed method improves the practical
utility of FastSAM by improving segmentation accuracy while maintaining
real-time processing capabilities. This advancement unlocks greater potential
for FastSAM technology in various real-world scenarios, such as industrial
automation, medical imaging, and autonomous systems, where precise and
efficient edge recognition is crucial.

</details>


### [78] [Towards Video Thinking Test: A Holistic Benchmark for Advanced Video Reasoning and Understanding](https://arxiv.org/abs/2507.15028)
*Yuanhan Zhang,Yunice Chew,Yuhao Dong,Aria Leo,Bo Hu,Ziwei Liu*

Main category: cs.CV

TL;DR: 论文提出了Video Thinking Test（Video-TT），用于评估视频大语言模型在理解和解释真实世界视频时的正确性和鲁棒性，发现其与人类表现存在显著差距。


<details>
  <summary>Details</summary>
Motivation: 现有视频大语言模型在视频理解的正确性和鲁棒性方面与人类智能存在差距，缺乏合适的评估基准。

Method: 设计了Video-TT，包含1000个YouTube Shorts视频，每个视频配有一个开放性问题及四个对抗性问题，以测试视觉和叙事复杂性。

Result: 评估结果显示，视频大语言模型在正确性和鲁棒性方面与人类表现存在显著差距。

Conclusion: Video-TT揭示了视频大语言模型在复杂视觉叙事理解中的不足，为未来研究提供了评估工具。

Abstract: Human intelligence requires correctness and robustness, with the former being
foundational for the latter. In video understanding, correctness ensures the
accurate interpretation of visual content, and robustness maintains consistent
performance in challenging conditions. Despite advances in video large language
models (video LLMs), existing benchmarks inadequately reflect the gap between
these models and human intelligence in maintaining correctness and robustness
in video interpretation. We introduce the Video Thinking Test (Video-TT), to
assess if video LLMs can interpret real-world videos as effectively as humans.
Video-TT reflects genuine gaps in understanding complex visual narratives, and
evaluates robustness against natural adversarial questions. Video-TT comprises
1,000 YouTube Shorts videos, each with one open-ended question and four
adversarial questions that probe visual and narrative complexity. Our
evaluation shows a significant gap between video LLMs and human performance.

</details>


### [79] [OpenBreastUS: Benchmarking Neural Operators for Wave Imaging Using Breast Ultrasound Computed Tomography](https://arxiv.org/abs/2507.15035)
*Zhijun Zeng,Youjia Zheng,Hao Hu,Zeyuan Dong,Yihang Zheng,Xinliang Liu,Jinzhuo Wang,Zuoqiang Shi,Linfeng Zhang,Yubing Li,He Sun*

Main category: cs.CV

TL;DR: OpenBreastUS是一个大规模波方程数据集，旨在弥合理论方程与实际成像应用之间的差距，为神经PDE求解器提供现实基准。


<details>
  <summary>Details</summary>
Motivation: 传统波方程数值求解器计算量大且不稳定，神经算子虽加速求解但现有数据集过于简化，限制了实际成像效果。

Method: 提出OpenBreastUS数据集，包含8,000个解剖学真实的人体乳腺模型和1,600万频域波模拟，用于神经算子的全面测试。

Result: 首次展示神经算子求解器在人体乳腺活体成像中的高效应用。

Conclusion: OpenBreastUS为神经PDE求解器的开发和实际医学成像应用提供了重要平台。

Abstract: Accurate and efficient simulation of wave equations is crucial in
computational wave imaging applications, such as ultrasound computed tomography
(USCT), which reconstructs tissue material properties from observed scattered
waves. Traditional numerical solvers for wave equations are computationally
intensive and often unstable, limiting their practical applications for
quasi-real-time image reconstruction. Neural operators offer an innovative
approach by accelerating PDE solving using neural networks; however, their
effectiveness in realistic imaging is limited because existing datasets
oversimplify real-world complexity. In this paper, we present OpenBreastUS, a
large-scale wave equation dataset designed to bridge the gap between
theoretical equations and practical imaging applications. OpenBreastUS includes
8,000 anatomically realistic human breast phantoms and over 16 million
frequency-domain wave simulations using real USCT configurations. It enables a
comprehensive benchmarking of popular neural operators for both forward
simulation and inverse imaging tasks, allowing analysis of their performance,
scalability, and generalization capabilities. By offering a realistic and
extensive dataset, OpenBreastUS not only serves as a platform for developing
innovative neural PDE solvers but also facilitates their deployment in
real-world medical imaging problems. For the first time, we demonstrate
efficient in vivo imaging of the human breast using neural operator solvers.

</details>


### [80] [OmniVTON: Training-Free Universal Virtual Try-On](https://arxiv.org/abs/2507.15037)
*Zhaotong Yang,Yuhui Li,Shengfeng He,Xinzhe Li,Yangyang Xu,Junyu Dong,Yong Du*

Main category: cs.CV

TL;DR: OmniVTON是一个无需训练的通用虚拟试衣框架，通过分离服装和姿势条件，实现了跨场景的高保真纹理和姿势一致性。


<details>
  <summary>Details</summary>
Motivation: 现有虚拟试衣技术要么依赖监督学习（限制跨域泛化），要么是无监督方法（受数据偏差和通用性限制），亟需一种统一的解决方案。

Method: 通过服装先验生成机制和对齐技术保留细节，结合DDIM反转实现精确姿势对齐，同时消除扩散模型的多条件偏差。

Result: 实验显示OmniVTON在多样化数据集、服装类型和应用场景中表现优异，首次实现多人物虚拟试衣。

Conclusion: OmniVTON为虚拟试衣提供了一种无需训练、通用且高效的解决方案，具有广泛的应用潜力。

Abstract: Image-based Virtual Try-On (VTON) techniques rely on either supervised
in-shop approaches, which ensure high fidelity but struggle with cross-domain
generalization, or unsupervised in-the-wild methods, which improve adaptability
but remain constrained by data biases and limited universality. A unified,
training-free solution that works across both scenarios remains an open
challenge. We propose OmniVTON, the first training-free universal VTON
framework that decouples garment and pose conditioning to achieve both texture
fidelity and pose consistency across diverse settings. To preserve garment
details, we introduce a garment prior generation mechanism that aligns clothing
with the body, followed by continuous boundary stitching technique to achieve
fine-grained texture retention. For precise pose alignment, we utilize DDIM
inversion to capture structural cues while suppressing texture interference,
ensuring accurate body alignment independent of the original image textures. By
disentangling garment and pose constraints, OmniVTON eliminates the bias
inherent in diffusion models when handling multiple conditions simultaneously.
Experimental results demonstrate that OmniVTON achieves superior performance
across diverse datasets, garment types, and application scenarios. Notably, it
is the first framework capable of multi-human VTON, enabling realistic garment
transfer across multiple individuals in a single scene. Code is available at
https://github.com/Jerome-Young/OmniVTON

</details>


### [81] [Rethinking Pan-sharpening: Principled Design, Unified Training, and a Universal Loss Surpass Brute-Force Scaling](https://arxiv.org/abs/2507.15059)
*Ran Zhang,Xuanhua He,Li Xueheng,Ke Cao,Liu Liu,Wenbo Xu,Fang Jiabin,Yang Qize,Jie Zhang*

Main category: cs.CV

TL;DR: 提出PanTiny，一种轻量级单步全色锐化框架，通过多数据集联合训练和复合损失函数，实现高效且泛化性强的性能。


<details>
  <summary>Details</summary>
Motivation: 挑战当前全色锐化领域大模型计算开销高、泛化性差的问题。

Method: 设计轻量级单步框架PanTiny，采用多数据集联合训练和复合损失函数。

Result: PanTiny在性能和效率上优于大型专用模型，泛化性显著提升。

Conclusion: 通过模型设计、训练范式和损失函数的优化，轻量级模型可超越暴力扩展，推动高效、泛化性强的全色锐化模型发展。

Abstract: The field of pan-sharpening has recently seen a trend towards increasingly
large and complex models, often trained on single, specific satellite datasets.
This approach, however, leads to high computational overhead and poor
generalization on full resolution data, a paradigm we challenge in this paper.
In response to this issue, we propose PanTiny, a lightweight, single-step
pan-sharpening framework designed for both efficiency and robust performance.
More critically, we introduce multiple-in-one training paradigm, where a
single, compact model is trained simultaneously on three distinct satellite
datasets (WV2, WV3, and GF2) with different resolution and spectral
information. Our experiments show that this unified training strategy not only
simplifies deployment but also significantly boosts generalization on
full-resolution data. Further, we introduce a universally powerful composite
loss function that elevates the performance of almost all of models for
pan-sharpening, pushing state-of-the-art metrics into a new era. Our PanTiny
model, benefiting from these innovations, achieves a superior
performance-to-efficiency balance, outperforming most larger, specialized
models. Through extensive ablation studies, we validate that principled
engineering in model design, training paradigms, and loss functions can surpass
brute-force scaling. Our work advocates for a community-wide shift towards
creating efficient, generalizable, and data-conscious models for
pan-sharpening. The code is available at
https://github.com/Zirconium233/PanTiny .

</details>


### [82] [StableAnimator++: Overcoming Pose Misalignment and Face Distortion for Human Image Animation](https://arxiv.org/abs/2507.15064)
*Shuyuan Tu,Zhen Xing,Xintong Han,Zhi-Qi Cheng,Qi Dai,Chong Luo,Zuxuan Wu,Yu-Gang Jiang*

Main category: cs.CV

TL;DR: StableAnimator++ 是一种基于视频扩散模型的框架，通过可学习的姿态对齐和身份保持技术，解决了现有方法在人体图像动画中身份一致性的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的人体图像动画扩散模型在参考图像和驱动视频差异较大时难以保持身份一致性。

Method: StableAnimator++ 通过可学习的姿态对齐模块、图像和面部嵌入编码器、分布感知的身份适配器，以及基于 HJB 的面部优化技术，实现了高质量视频生成。

Result: 实验证明，StableAnimator++ 在定性和定量上均表现出色。

Conclusion: StableAnimator++ 是一种高效的身份保持视频生成框架，显著提升了动画质量。

Abstract: Current diffusion models for human image animation often struggle to maintain
identity (ID) consistency, especially when the reference image and driving
video differ significantly in body size or position. We introduce
StableAnimator++, the first ID-preserving video diffusion framework with
learnable pose alignment, capable of generating high-quality videos conditioned
on a reference image and a pose sequence without any post-processing. Building
upon a video diffusion model, StableAnimator++ contains carefully designed
modules for both training and inference, striving for identity consistency. In
particular, StableAnimator++ first uses learnable layers to predict the
similarity transformation matrices between the reference image and the driven
poses via injecting guidance from Singular Value Decomposition (SVD). These
matrices align the driven poses with the reference image, mitigating
misalignment to a great extent. StableAnimator++ then computes image and face
embeddings using off-the-shelf encoders, refining the face embeddings via a
global content-aware Face Encoder. To further maintain ID, we introduce a
distribution-aware ID Adapter that counteracts interference caused by temporal
layers while preserving ID via distribution alignment. During the inference
stage, we propose a novel Hamilton-Jacobi-Bellman (HJB) based face optimization
integrated into the denoising process, guiding the diffusion trajectory for
enhanced facial fidelity. Experiments on benchmarks show the effectiveness of
StableAnimator++ both qualitatively and quantitatively.

</details>


### [83] [Aesthetics is Cheap, Show me the Text: An Empirical Evaluation of State-of-the-Art Generative Models for OCR](https://arxiv.org/abs/2507.15085)
*Peirong Zhang,Haowei Xu,Jiaxin Zhang,Guitao Xu,Xuhan Zheng,Zhenhua Yang,Junle Liu,Yuyi Zhang,Lianwen Jin*

Main category: cs.CV

TL;DR: 论文评估了当前最先进的生成模型在文本图像生成和编辑方面的能力，提出了OCR生成任务的概念，并通过实验揭示了模型的局限性。


<details>
  <summary>Details</summary>
Motivation: 探讨生成模型是否能掌握文本图像生成和编辑的复杂性，并推动其成为通用生成模型的基础能力。

Method: 选择33个代表性任务，分为五类，评估六种模型在OCR任务中的表现。

Result: 揭示了当前生成模型在OCR任务中的弱点，强调了将文本图像生成和编辑作为基础能力的重要性。

Conclusion: 呼吁将文本图像生成和编辑内化为通用生成模型的基础技能，而非依赖专用解决方案。

Abstract: Text image is a unique and crucial information medium that integrates visual
aesthetics and linguistic semantics in modern e-society. Due to their subtlety
and complexity, the generation of text images represents a challenging and
evolving frontier in the image generation field. The recent surge of
specialized image generators (\emph{e.g.}, Flux-series) and unified generative
models (\emph{e.g.}, GPT-4o), which demonstrate exceptional fidelity, raises a
natural question: can they master the intricacies of text image generation and
editing? Motivated by this, we assess current state-of-the-art generative
models' capabilities in terms of text image generation and editing. We
incorporate various typical optical character recognition (OCR) tasks into our
evaluation and broaden the concept of text-based generation tasks into OCR
generative tasks. We select 33 representative tasks and categorize them into
five categories: document, handwritten text, scene text, artistic text, and
complex \& layout-rich text. For comprehensive evaluation, we examine six
models across both closed-source and open-source domains, using tailored,
high-quality image inputs and prompts. Through this evaluation, we draw crucial
observations and identify the weaknesses of current generative models for OCR
tasks. We argue that photorealistic text image generation and editing should be
internalized as foundational skills into general-domain generative models,
rather than being delegated to specialized solutions, and we hope this
empirical analysis can provide valuable insights for the community to achieve
this goal. This evaluation is online and will be continuously updated at our
GitHub repository.

</details>


### [84] [BleedOrigin: Dynamic Bleeding Source Localization in Endoscopic Submucosal Dissection via Dual-Stage Detection and Tracking](https://arxiv.org/abs/2507.15094)
*Mengya Xu,Rulin Zhou,An Wang,Chaoyang Lyu,Zhen Li,Ning Zhong,Hongliang Ren*

Main category: cs.CV

TL;DR: 论文提出了首个ESD出血源数据集BleedOrigin-Bench和双阶段检测-跟踪框架BleedOrigin-Net，用于实时定位和跟踪出血源，显著提升了准确性和效率。


<details>
  <summary>Details</summary>
Motivation: ESD术中出血的实时定位和持续监测需求迫切，但现有AI方法仅关注出血区域分割，缺乏对出血源的精确定位和动态跟踪，且缺乏专用数据集。

Method: 提出BleedOrigin-Bench数据集和BleedOrigin-Net框架，结合检测与跟踪技术，从出血开始检测到持续空间跟踪。

Result: 在出血开始检测、初始源定位和点跟踪方面分别达到96.85%、70.24%和96.11%的准确率。

Conclusion: BleedOrigin-Net在ESD出血源定位中表现出色，填补了现有技术空白，为AI辅助系统提供了新方向。

Abstract: Intraoperative bleeding during Endoscopic Submucosal Dissection (ESD) poses
significant risks, demanding precise, real-time localization and continuous
monitoring of the bleeding source for effective hemostatic intervention. In
particular, endoscopists have to repeatedly flush to clear blood, allowing only
milliseconds to identify bleeding sources, an inefficient process that prolongs
operations and elevates patient risks. However, current Artificial Intelligence
(AI) methods primarily focus on bleeding region segmentation, overlooking the
critical need for accurate bleeding source detection and temporal tracking in
the challenging ESD environment, which is marked by frequent visual
obstructions and dynamic scene changes. This gap is widened by the lack of
specialized datasets, hindering the development of robust AI-assisted guidance
systems. To address these challenges, we introduce BleedOrigin-Bench, the first
comprehensive ESD bleeding source dataset, featuring 1,771 expert-annotated
bleeding sources across 106,222 frames from 44 procedures, supplemented with
39,755 pseudo-labeled frames. This benchmark covers 8 anatomical sites and 6
challenging clinical scenarios. We also present BleedOrigin-Net, a novel
dual-stage detection-tracking framework for the bleeding source localization in
ESD procedures, addressing the complete workflow from bleeding onset detection
to continuous spatial tracking. We compare with widely-used object detection
models (YOLOv11/v12), multimodal large language models, and point tracking
methods. Extensive evaluation demonstrates state-of-the-art performance,
achieving 96.85% frame-level accuracy ($\pm\leq8$ frames) for bleeding onset
detection, 70.24% pixel-level accuracy ($\leq100$ px) for initial source
detection, and 96.11% pixel-level accuracy ($\leq100$ px) for point tracking.

</details>


### [85] [LoopNet: A Multitasking Few-Shot Learning Approach for Loop Closure in Large Scale SLAM](https://arxiv.org/abs/2507.15109)
*Mohammad-Maher Nakshbandi,Ziad Sharawy,Sorin Grigorescu*

Main category: cs.CV

TL;DR: LoopNet方法通过改进的ResNet架构和在线训练，提升了SLAM闭环检测的准确性和实时性，并引入了新的数据集LoopDB。


<details>
  <summary>Details</summary>
Motivation: 解决SLAM系统中闭环检测的准确性和嵌入式硬件实时计算的挑战。

Method: 采用多任务ResNet变体，结合在线训练和DISK描述符，优化嵌入式设备性能。

Result: LoopNet在多变条件下表现优于传统方法和手工特征，并提供了新的数据集LoopDB。

Conclusion: LoopNet为SLAM闭环问题提供了高效解决方案，同时开源了代码和数据集。

Abstract: One of the main challenges in the Simultaneous Localization and Mapping
(SLAM) loop closure problem is the recognition of previously visited places. In
this work, we tackle the two main problems of real-time SLAM systems: 1) loop
closure detection accuracy and 2) real-time computation constraints on the
embedded hardware. Our LoopNet method is based on a multitasking variant of the
classical ResNet architecture, adapted for online retraining on a dynamic
visual dataset and optimized for embedded devices. The online retraining is
designed using a few-shot learning approach. The architecture provides both an
index into the queried visual dataset, and a measurement of the prediction
quality. Moreover, by leveraging DISK (DIStinctive Keypoints) descriptors,
LoopNet surpasses the limitations of handcrafted features and traditional deep
learning methods, offering better performance under varying conditions. Code is
available at https://github.com/RovisLab/LoopNet. Additinally, we introduce a
new loop closure benchmarking dataset, coined LoopDB, which is available at
https://github.com/RovisLab/LoopDB.

</details>


### [86] [Enhancing Visual Planning with Auxiliary Tasks and Multi-token Prediction](https://arxiv.org/abs/2507.15130)
*Ce Zhang,Yale Song,Ruta Desai,Michael Louis Iuzzolino,Joseph Tighe,Gedas Bertasius,Satwik Kottur*

Main category: cs.CV

TL;DR: 论文提出了一种名为VideoPlan的方法，通过辅助任务增强和多令牌预测技术，解决了视觉规划任务中的数据稀缺和结构化动作空间建模问题，并在多个数据集上取得了最优性能。


<details>
  <summary>Details</summary>
Motivation: 视觉规划任务（VPA）需要基于视频预测用户动作序列，但现有方法面临数据稀缺和结构化动作空间建模的挑战。

Method: 采用辅助任务增强（如目标预测）和多令牌预测技术，以增强模型对长时程视频规划的能力。

Result: 在COIN和CrossTask数据集上，VideoPlan的性能分别超越先前方法7.3%和3.4%，并在Ego4D任务中表现优异。

Conclusion: VideoPlan通过创新的训练策略，显著提升了视觉规划任务的性能，展示了其广泛适用性。

Abstract: Visual Planning for Assistance (VPA) aims to predict a sequence of user
actions required to achieve a specified goal based on a video showing the
user's progress. Although recent advances in multimodal large language models
(MLLMs) have shown promising results in video understanding, long-horizon
visual planning remains a challenging problem. We identify two challenges in
training large MLLMs for video-based planning tasks: (1) scarcity of procedural
annotations, limiting the model's ability to learn procedural task dynamics
effectively, and (2) inefficiency of next-token prediction objective to
explicitly capture the structured action space for visual planning when
compared to free-form, natural language. To tackle data scarcity, we introduce
Auxiliary Task Augmentation. We design and train our model on auxiliary tasks
relevant to long-horizon video-based planning (e.g., goal prediction) to
augment the model's planning ability. To more explicitly model the structured
action space unique to visual planning tasks, we leverage Multi-token
Prediction, extending traditional next-token prediction by using multiple heads
to predict multiple future tokens during training. Our approach, VideoPlan,
achieves state-of-the-art VPA performance on the COIN and CrossTask datasets,
surpassing prior methods by 7.3% and 3.4%, respectively, when predicting 3
future actions. We further extend our method to the challenging Ego4D Long-term
Action Anticipation task, and show that it is on par with the state-of-the-art
approaches despite not using specialized egocentric features. Code will be made
available.

</details>


### [87] [Event-based Graph Representation with Spatial and Motion Vectors for Asynchronous Object Detection](https://arxiv.org/abs/2507.15150)
*Aayush Atul Verma,Arpitsinh Vaghela,Bharatesh Chakravarthi,Kaustav Chanda,Yezhou Yang*

Main category: cs.CV

TL;DR: 提出了一种新颖的时空多图表示方法，通过解耦空间和时间图，优化了事件传感器数据的处理，显著提升了检测精度和效率。


<details>
  <summary>Details</summary>
Motivation: 事件传感器数据稀疏且异步，传统方法将其转换为密集张量会丧失优势，而现有图方法对时空动态建模不足。

Method: 构建解耦的空间图（B样条基函数建模全局结构）和时间图（运动向量注意力建模局部动态），使用高效2D核替代3D核。

Result: 在Gen1和eTraM数据集上，检测精度提升6%，速度提升5倍，参数减少且计算成本不变。

Conclusion: 结构化图建模在异步视觉任务中表现优异，验证了方法的有效性。

Abstract: Event-based sensors offer high temporal resolution and low latency by
generating sparse, asynchronous data. However, converting this irregular data
into dense tensors for use in standard neural networks diminishes these
inherent advantages, motivating research into graph representations. While such
methods preserve sparsity and support asynchronous inference, their performance
on downstream tasks remains limited due to suboptimal modeling of
spatiotemporal dynamics. In this work, we propose a novel spatiotemporal
multigraph representation to better capture spatial structure and temporal
changes. Our approach constructs two decoupled graphs: a spatial graph
leveraging B-spline basis functions to model global structure, and a temporal
graph utilizing motion vector-based attention for local dynamic changes. This
design enables the use of efficient 2D kernels in place of computationally
expensive 3D kernels. We evaluate our method on the Gen1 automotive and eTraM
datasets for event-based object detection, achieving over a 6% improvement in
detection accuracy compared to previous graph-based works, with a 5x speedup,
reduced parameter count, and no increase in computational cost. These results
highlight the effectiveness of structured graph modeling for asynchronous
vision. Project page: eventbasedvision.github.io/eGSMV.

</details>


### [88] [MeshMamba: State Space Models for Articulated 3D Mesh Generation and Reconstruction](https://arxiv.org/abs/2507.15212)
*Yusuke Yoshiyasu,Leyuan Sun,Ryusuke Sagawa*

Main category: cs.CV

TL;DR: MeshMamba是一种基于Mamba-SSMs的高效神经网络模型，用于学习和生成3D关节网格模型，支持超过10,000个顶点，并能捕捉衣物和手部几何。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在处理大规模3D网格数据时的效率和扩展性问题，同时提升对衣物和手部细节的建模能力。

Method: 通过将网格顶点序列化并按身体部位或模板网格的3D位置排序，利用Mamba-SSMs处理。设计了MambaDiff3D（生成模型）和Mamba-HMR（重建模型）。

Result: MambaDiff3D在生成带衣物和手部的密集3D人体网格任务中优于现有方法；Mamba-HMR扩展了非参数化人体网格恢复的能力，支持全身建模并实现接近实时的性能。

Conclusion: MeshMamba在3D人体网格生成和重建任务中表现出高效性和扩展性，为复杂几何建模提供了新方法。

Abstract: In this paper, we introduce MeshMamba, a neural network model for learning 3D
articulated mesh models by employing the recently proposed Mamba State Space
Models (Mamba-SSMs). MeshMamba is efficient and scalable in handling a large
number of input tokens, enabling the generation and reconstruction of body mesh
models with more than 10,000 vertices, capturing clothing and hand geometries.
The key to effectively learning MeshMamba is the serialization technique of
mesh vertices into orderings that are easily processed by Mamba. This is
achieved by sorting the vertices based on body part annotations or the 3D
vertex locations of a template mesh, such that the ordering respects the
structure of articulated shapes. Based on MeshMamba, we design 1) MambaDiff3D,
a denoising diffusion model for generating 3D articulated meshes and 2)
Mamba-HMR, a 3D human mesh recovery model that reconstructs a human body shape
and pose from a single image. Experimental results showed that MambaDiff3D can
generate dense 3D human meshes in clothes, with grasping hands, etc., and
outperforms previous approaches in the 3D human shape generation task.
Additionally, Mamba-HMR extends the capabilities of previous non-parametric
human mesh recovery approaches, which were limited to handling body-only poses
using around 500 vertex tokens, to the whole-body setting with face and hands,
while achieving competitive performance in (near) real-time.

</details>


### [89] [Improving Joint Embedding Predictive Architecture with Diffusion Noise](https://arxiv.org/abs/2507.15216)
*Yuping Qiu,Rui Zhu,Ying-cong Chen*

Main category: cs.CV

TL;DR: 论文提出N-JEPA方法，将扩散噪声与自监督学习结合，通过噪声增强特征学习，提升下游分类任务性能。


<details>
  <summary>Details</summary>
Motivation: 自监督学习在特征学习中表现优异，但在生成任务中不如生成模型。结合两者优势，利用扩散噪声增强自监督学习的表示能力。

Method: 提出N-JEPA方法，将扩散噪声引入掩码图像建模（MIM），通过多级噪声调度增强模型鲁棒性。

Result: 实验验证了N-JEPA在下游分类任务中的有效性。

Conclusion: 结合扩散噪声与自监督学习是一种有效的方法，能提升模型表示能力。

Abstract: Self-supervised learning has become an incredibly successful method for
feature learning, widely applied to many downstream tasks. It has proven
especially effective for discriminative tasks, surpassing the trending
generative models. However, generative models perform better in image
generation and detail enhancement. Thus, it is natural for us to find a
connection between SSL and generative models to further enhance the
representation capacity of SSL. As generative models can create new samples by
approximating the data distribution, such modeling should also lead to a
semantic understanding of the raw visual data, which is necessary for
recognition tasks. This enlightens us to combine the core principle of the
diffusion model: diffusion noise, with SSL to learn a competitive recognition
model. Specifically, diffusion noise can be viewed as a particular state of
mask that reveals a close relationship between masked image modeling (MIM) and
diffusion models. In this paper, we propose N-JEPA (Noise-based JEPA) to
incorporate diffusion noise into MIM by the position embedding of masked
tokens. The multi-level noise schedule is a series of feature augmentations to
further enhance the robustness of our model. We perform a comprehensive study
to confirm its effectiveness in the classification of downstream tasks. Codes
will be released soon in public.

</details>


### [90] [Hierarchical Part-based Generative Model for Realistic 3D Blood Vessel](https://arxiv.org/abs/2507.15223)
*Siqi Chen,Guoqing Zhang,Jiahao Lai,Bingzhi Shen,Sihong Zhang,Caixia Dong,Xuejin Chen,Yang Li*

Main category: cs.CV

TL;DR: 提出了一种基于分层的部件框架，用于3D血管生成，分离全局拓扑与局部几何细节，并在真实数据集上验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 由于血管的复杂几何和拓扑结构（如分支模式、曲率和不规则形状），准确建模血管仍具挑战性。

Method: 方法分为三阶段：关键图生成（建模全局分层结构）、血管段生成（基于几何属性）和分层血管组装（整合局部段与全局图）。

Result: 在真实数据集上验证，性能优于现有方法，首次成功应用部件生成方法于3D血管建模。

Conclusion: 该框架为血管数据生成设定了新基准，代码已开源。

Abstract: Advancements in 3D vision have increased the impact of blood vessel modeling
on medical applications. However, accurately representing the complex geometry
and topology of blood vessels remains a challenge due to their intricate
branching patterns, curvatures, and irregular shapes. In this study, we propose
a hierarchical part-based frame work for 3D vessel generation that separates
the global binary tree-like topology from local geometric details. Our approach
proceeds in three stages: (1) key graph generation to model the overall
hierarchical struc ture, (2) vessel segment generation conditioned on geometric
properties, and (3) hierarchical vessel assembly by integrating the local
segments according to the global key graph. We validate our framework on real
world datasets, demonstrating superior performance over existing methods in
modeling complex vascular networks. This work marks the first successful
application of a part-based generative approach for 3D vessel modeling, setting
a new benchmark for vascular data generation. The code is available at:
https://github.com/CybercatChen/PartVessel.git.

</details>


### [91] [Mammo-SAE: Interpreting Breast Cancer Concept Learning with Sparse Autoencoders](https://arxiv.org/abs/2507.15227)
*Krishna Kanth Nakka*

Main category: cs.CV

TL;DR: 论文提出了一种基于稀疏自编码器（SAE）的可解释性方法，用于分析乳腺影像中的基础模型Mammo-CLIP，揭示了模型决策的潜在特征和影响因素。


<details>
  <summary>Details</summary>
Motivation: 在医疗影像等高风险领域，模型决策的可解释性对临床应用至关重要。本文旨在通过SAE方法深入理解乳腺影像基础模型的内部机制。

Method: 训练了一个基于Mammo-CLIP的patch级稀疏自编码器（Mammo-SAE），用于识别和探测与临床相关乳腺概念（如肿块和可疑钙化）相关的潜在特征。

Result: 研究发现，SAE潜在空间中激活的神经元通常与真实区域对齐，并揭示了影响模型决策的混杂因素。此外，还分析了模型在下游任务中依赖的潜在神经元。

Conclusion: 研究表明，可解释的SAE潜在表征为深入理解乳腺影像基础模型的内部机制提供了有效途径。

Abstract: Interpretability is critical in high-stakes domains such as medical imaging,
where understanding model decisions is essential for clinical adoption. In this
work, we introduce Sparse Autoencoder (SAE)-based interpretability to breast
imaging by analyzing {Mammo-CLIP}, a vision--language foundation model
pretrained on large-scale mammogram image--report pairs. We train a patch-level
\texttt{Mammo-SAE} on Mammo-CLIP to identify and probe latent features
associated with clinically relevant breast concepts such as \textit{mass} and
\textit{suspicious calcification}. Our findings reveal that top activated class
level latent neurons in the SAE latent space often tend to align with ground
truth regions, and also uncover several confounding factors influencing the
model's decision-making process. Additionally, we analyze which latent neurons
the model relies on during downstream finetuning for improving the breast
concept prediction. This study highlights the promise of interpretable SAE
latent representations in providing deeper insight into the internal workings
of foundation models at every layer for breast imaging.

</details>


### [92] [Cross-Domain Few-Shot Learning with Coalescent Projections and Latent Space Reservation](https://arxiv.org/abs/2507.15243)
*Naeem Paeedeh,Mahardhika Pratama,Wolfgang Mayer,Jimmy Cao,Ryszard Kowlczyk*

Main category: cs.CV

TL;DR: 论文提出了一种名为Coalescent Projection（CP）的新方法，结合伪类生成和自监督变换（SSTs），在跨域少样本学习（CD-FSL）中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在跨域少样本学习中存在参数更新过多导致过拟合的问题，需要一种更有效的方法来应对样本稀缺和域偏移。

Method: 提出CP作为软提示的有效替代，并结合伪类生成和SSTs，仅依赖基础域数据来适应未见域样本。

Result: 在BSCD-FSL基准测试的极端域偏移场景中表现出色。

Conclusion: CP和SSTs的组合为跨域少样本学习提供了一种高效解决方案。

Abstract: Despite the progress in Cross-Domain Few-Shot Learning (CD-FSL), a model
pre-trained with DINO combined with a prototypical classifier outperforms the
latest SOTA methods. A crucial limitation that needs to be overcome is that
updating too many parameters of the transformers leads to overfitting due to
the scarcity of labeled samples. To address this challenge, we propose a new
concept, Coalescent Projection (CP), as an effective successor to soft prompts.
Additionally, we propose a novel pseudo-class generation method combined with
Self-Supervised Transformations (SSTs) that relies solely on the base domain to
prepare the network for encountering unseen samples from different domains. The
proposed method exhibits its effectiveness in comprehensive experiments on the
extreme domain shift scenario of the BSCD-FSL benchmark. Our code is published
at https://github.com/Naeem-Paeedeh/CPLSR.

</details>


### [93] [FreeCus: Free Lunch Subject-driven Customization in Diffusion Transformers](https://arxiv.org/abs/2507.15249)
*Yanbing Zhang,Zhe Wang,Qin Zhou,Mengping Yang*

Main category: cs.CV

TL;DR: FreeCus是一个无需训练的框架，通过创新机制激活扩散变压器（DiT）的零样本能力，实现高质量的主题驱动合成。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖训练过程，限制了实际应用，且未能充分利用DiT的零样本潜力。

Method: 提出三种创新：注意力共享机制、改进的DiT变体和多模态大语言模型集成。

Result: 实验表明，FreeCus在多样场景中实现一致的主题合成，性能优于或媲美需训练的方法。

Conclusion: FreeCus展示了与现有工具的兼容性，为设计工作流和娱乐提供了新可能。

Abstract: In light of recent breakthroughs in text-to-image (T2I) generation,
particularly with diffusion transformers (DiT), subject-driven technologies are
increasingly being employed for high-fidelity customized production that
preserves subject identity from reference inputs, enabling thrilling design
workflows and engaging entertainment. Existing alternatives typically require
either per-subject optimization via trainable text embeddings or training
specialized encoders for subject feature extraction on large-scale datasets.
Such dependencies on training procedures fundamentally constrain their
practical applications. More importantly, current methodologies fail to fully
leverage the inherent zero-shot potential of modern diffusion transformers
(e.g., the Flux series) for authentic subject-driven synthesis. To bridge this
gap, we propose FreeCus, a genuinely training-free framework that activates
DiT's capabilities through three key innovations: 1) We introduce a pivotal
attention sharing mechanism that captures the subject's layout integrity while
preserving crucial editing flexibility. 2) Through a straightforward analysis
of DiT's dynamic shifting, we propose an upgraded variant that significantly
improves fine-grained feature extraction. 3) We further integrate advanced
Multimodal Large Language Models (MLLMs) to enrich cross-modal semantic
representations. Extensive experiments reflect that our method successfully
unlocks DiT's zero-shot ability for consistent subject synthesis across diverse
contexts, achieving state-of-the-art or comparable results compared to
approaches that require additional training. Notably, our framework
demonstrates seamless compatibility with existing inpainting pipelines and
control modules, facilitating more compelling experiences. Our code is
available at: https://github.com/Monalissaa/FreeCus.

</details>


### [94] [MinCD-PnP: Learning 2D-3D Correspondences with Approximate Blind PnP](https://arxiv.org/abs/2507.15257)
*Pei An,Jiaqi Yang,Muyao Peng,You Yang,Qiong Liu,Xiaolin Wu,Liangliang Nan*

Main category: cs.CV

TL;DR: 提出了一种基于近似盲PnP的对应学习方法MinCD-PnP，通过最小化学习到的2D和3D关键点之间的Chamfer距离，解决了传统微分PnP对噪声和异常值敏感的问题。


<details>
  <summary>Details</summary>
Motivation: 传统微分PnP在图像到点云（I2P）注册中对噪声和异常值敏感，影响了对应学习的有效性。

Method: 提出MinCD-PnP方法，简化盲PnP为最小化Chamfer距离的任务，并设计轻量级多任务学习模块MinCD-Net。

Result: 在多个数据集上实验表明，MinCD-Net在跨场景和跨数据集设置中均优于现有方法，提高了内点比率（IR）和注册召回率（RR）。

Conclusion: MinCD-PnP和MinCD-Net有效提升了I2P注册的鲁棒性和性能。

Abstract: Image-to-point-cloud (I2P) registration is a fundamental problem in computer
vision, focusing on establishing 2D-3D correspondences between an image and a
point cloud. The differential perspective-n-point (PnP) has been widely used to
supervise I2P registration networks by enforcing the projective constraints on
2D-3D correspondences. However, differential PnP is highly sensitive to noise
and outliers in the predicted correspondences. This issue hinders the
effectiveness of correspondence learning. Inspired by the robustness of blind
PnP against noise and outliers in correspondences, we propose an approximated
blind PnP based correspondence learning approach. To mitigate the high
computational cost of blind PnP, we simplify blind PnP to an amenable task of
minimizing Chamfer distance between learned 2D and 3D keypoints, called
MinCD-PnP. To effectively solve MinCD-PnP, we design a lightweight multi-task
learning module, named as MinCD-Net, which can be easily integrated into the
existing I2P registration architectures. Extensive experiments on 7-Scenes,
RGBD-V2, ScanNet, and self-collected datasets demonstrate that MinCD-Net
outperforms state-of-the-art methods and achieves a higher inlier ratio (IR)
and registration recall (RR) in both cross-scene and cross-dataset settings.

</details>


### [95] [Conditional Video Generation for High-Efficiency Video Compression](https://arxiv.org/abs/2507.15269)
*Fangqiu Yi,Jingyu Xu,Jiawei Shao,Chi Zhang,Xuelong Li*

Main category: cs.CV

TL;DR: 提出了一种基于条件扩散模型的视频压缩框架，通过生成模型从稀疏信号中重建视频，显著提升了感知质量。


<details>
  <summary>Details</summary>
Motivation: 利用条件扩散模型在人类视觉感知对齐重建中的优势，优化视频压缩的感知质量。

Method: 1. 多粒度条件模块捕捉静态场景结构和动态时空线索；2. 设计高效传输的紧凑表示；3. 多条件训练增强鲁棒性。

Result: 在FVD和LPIPS等感知质量指标上显著优于传统和神经编解码器，尤其在高压缩比下表现突出。

Conclusion: 条件扩散模型为视频压缩提供了感知优化的有效解决方案。

Abstract: Perceptual studies demonstrate that conditional diffusion models excel at
reconstructing video content aligned with human visual perception. Building on
this insight, we propose a video compression framework that leverages
conditional diffusion models for perceptually optimized reconstruction.
Specifically, we reframe video compression as a conditional generation task,
where a generative model synthesizes video from sparse, yet informative
signals. Our approach introduces three key modules: (1) Multi-granular
conditioning that captures both static scene structure and dynamic
spatio-temporal cues; (2) Compact representations designed for efficient
transmission without sacrificing semantic richness; (3) Multi-condition
training with modality dropout and role-aware embeddings, which prevent
over-reliance on any single modality and enhance robustness. Extensive
experiments show that our method significantly outperforms both traditional and
neural codecs on perceptual quality metrics such as Fr\'echet Video Distance
(FVD) and LPIPS, especially under high compression ratios.

</details>


### [96] [In-context Learning of Vision Language Models for Detection of Physical and Digital Attacks against Face Recognition Systems](https://arxiv.org/abs/2507.15285)
*Lazaro Janier Gonzalez-Soler,Maciej Salwowski,Christoph Busch*

Main category: cs.CV

TL;DR: 论文探讨了视觉语言模型（VLM）在生物识别系统中检测物理和数字攻击的应用，提出了一种上下文学习框架，性能优于传统CNN，且无需大量训练数据。


<details>
  <summary>Details</summary>
Motivation: 随着生物识别系统的发展，攻击技术也日益复杂，传统深度学习模型难以适应多样化的攻击和环境条件，且数据收集面临隐私和多样性挑战。

Method: 提出了一种基于VLM的上下文学习框架，用于检测物理呈现攻击和数字变形攻击，并建立了首个系统性评估框架。

Result: 实验表明，该框架在公开数据库上表现优异，性能超越部分传统CNN，且无需资源密集型训练。

Conclusion: 该框架为提升攻击检测的泛化能力提供了有前景的工具。

Abstract: Recent advances in biometric systems have significantly improved the
detection and prevention of fraudulent activities. However, as detection
methods improve, attack techniques become increasingly sophisticated. Attacks
on face recognition systems can be broadly divided into physical and digital
approaches. Traditionally, deep learning models have been the primary defence
against such attacks. While these models perform exceptionally well in
scenarios for which they have been trained, they often struggle to adapt to
different types of attacks or varying environmental conditions. These
subsystems require substantial amounts of training data to achieve reliable
performance, yet biometric data collection faces significant challenges,
including privacy concerns and the logistical difficulties of capturing diverse
attack scenarios under controlled conditions. This work investigates the
application of Vision Language Models (VLM) and proposes an in-context learning
framework for detecting physical presentation attacks and digital morphing
attacks in biometric systems. Focusing on open-source models, the first
systematic framework for the quantitative evaluation of VLMs in
security-critical scenarios through in-context learning techniques is
established. The experimental evaluation conducted on freely available
databases demonstrates that the proposed subsystem achieves competitive
performance for physical and digital attack detection, outperforming some of
the traditional CNNs without resource-intensive training. The experimental
results validate the proposed framework as a promising tool for improving
generalisation in attack detection.

</details>


### [97] [Minutiae-Anchored Local Dense Representation for Fingerprint Matching](https://arxiv.org/abs/2507.15297)
*Zhiyu Pan,Xiongjun Guan,Yongjie Duan,Jianjiang Feng,Jie Zhou*

Main category: cs.CV

TL;DR: 提出了一种名为DMD的指纹匹配方法，通过局部密集表示结合细粒度纹理和细节特征，提升了不同采集条件下的匹配性能。


<details>
  <summary>Details</summary>
Motivation: 指纹匹配在多样化采集条件下仍面临挑战，需要一种鲁棒且准确的方法。

Method: DMD方法基于细节锚定的局部密集表示，提取三维张量描述符，结合空间结构和语义特征。

Result: 在多种指纹数据集上验证，DMD实现了最先进的准确性和计算效率。

Conclusion: DMD方法具有大规模指纹识别的潜力，代码已开源。

Abstract: Fingerprint matching under diverse capture conditions remains a fundamental
challenge in biometric recognition. To achieve robust and accurate performance
in such scenarios, we propose DMD, a minutiae-anchored local dense
representation which captures both fine-grained ridge textures and
discriminative minutiae features in a spatially structured manner.
Specifically, descriptors are extracted from local patches centered and
oriented on each detected minutia, forming a three-dimensional tensor, where
two dimensions represent spatial locations on the fingerprint plane and the
third encodes semantic features. This representation explicitly captures
abstract features of local image patches, enabling a multi-level, fine-grained
description that aggregates information from multiple minutiae and their
surrounding ridge structures. Furthermore, thanks to its strong spatial
correspondence with the patch image, DMD allows for the use of foreground
segmentation masks to identify valid descriptor regions. During matching,
comparisons are then restricted to overlapping foreground areas, improving
efficiency and robustness. Extensive experiments on rolled, plain, parital,
contactless, and latent fingerprint datasets demonstrate the effectiveness and
generalizability of the proposed method. It achieves state-of-the-art accuracy
across multiple benchmarks while maintaining high computational efficiency,
showing strong potential for large-scale fingerprint recognition. Corresponding
code is available at https://github.com/Yu-Yy/DMD.

</details>


### [98] [Few-Shot Object Detection via Spatial-Channel State Space Model](https://arxiv.org/abs/2507.15308)
*Zhimeng Xin,Tianxu Wu,Yixiong Zou,Shiming Chen,Dingjie Fu,Xinge You*

Main category: cs.CV

TL;DR: 论文提出了一种基于通道间相关性的空间-通道状态建模（SCSM）模块，用于改进少样本目标检测（FSOD）中的特征提取问题。


<details>
  <summary>Details</summary>
Motivation: 当前少样本目标检测方法在有限训练样本下难以准确提取有效通道特征，表现为高权重通道未必有效，低权重通道可能仍有价值。

Method: 提出SCSM模块，包含空间特征建模（SFM）和基于Mamba的通道状态建模（CSM），以平衡空间与通道关系学习并建模通道相关性。

Result: 在VOC和COCO数据集上的实验表明，SCSM模块提升了特征表示质量并达到最优性能。

Conclusion: SCSM模块通过建模通道相关性，有效改善了少样本目标检测中的特征提取问题。

Abstract: Due to the limited training samples in few-shot object detection (FSOD), we
observe that current methods may struggle to accurately extract effective
features from each channel. Specifically, this issue manifests in two aspects:
i) channels with high weights may not necessarily be effective, and ii)
channels with low weights may still hold significant value. To handle this
problem, we consider utilizing the inter-channel correlation to facilitate the
novel model's adaptation process to novel conditions, ensuring the model can
correctly highlight effective channels and rectify those incorrect ones. Since
the channel sequence is also 1-dimensional, its similarity with the temporal
sequence inspires us to take Mamba for modeling the correlation in the channel
sequence. Based on this concept, we propose a Spatial-Channel State Space
Modeling (SCSM) module for spatial-channel state modeling, which highlights the
effective patterns and rectifies those ineffective ones in feature channels. In
SCSM, we design the Spatial Feature Modeling (SFM) module to balance the
learning of spatial relationships and channel relationships, and then introduce
the Channel State Modeling (CSM) module based on Mamba to learn correlation in
channels. Extensive experiments on the VOC and COCO datasets show that the SCSM
module enables the novel detector to improve the quality of focused feature
representation in channels and achieve state-of-the-art performance.

</details>


### [99] [BenchDepth: Are We on the Right Way to Evaluate Depth Foundation Models?](https://arxiv.org/abs/2507.15321)
*Zhenyu Li,Haotong Lin,Jiashi Feng,Peter Wonka,Bingyi Kang*

Main category: cs.CV

TL;DR: 论文提出了BenchDepth，一种新的深度基础模型（DFMs）评估基准，通过五个下游代理任务评估DFMs的实用性，避免了传统对齐指标的偏差。


<details>
  <summary>Details</summary>
Motivation: 现有深度评估协议存在不一致性，传统基准依赖对齐指标，导致偏差和不公平比较，需要更实用的评估方法。

Method: 提出BenchDepth基准，通过深度补全、立体匹配、单目3D场景重建、SLAM和视觉语言空间理解五个下游任务评估DFMs。

Result: 对八种先进DFMs进行了基准测试，并提供了关键发现和观察的深入分析。

Conclusion: BenchDepth为深度模型评估提供了新标准，有望推动深度估计领域的进一步研究和讨论。

Abstract: Depth estimation is a fundamental task in computer vision with diverse
applications. Recent advancements in deep learning have led to powerful depth
foundation models (DFMs), yet their evaluation remains challenging due to
inconsistencies in existing protocols. Traditional benchmarks rely on
alignment-based metrics that introduce biases, favor certain depth
representations, and complicate fair comparisons. In this work, we propose
BenchDepth, a new benchmark that evaluates DFMs through five carefully selected
downstream proxy tasks: depth completion, stereo matching, monocular
feed-forward 3D scene reconstruction, SLAM, and vision-language spatial
understanding. Unlike conventional evaluation protocols, our approach assesses
DFMs based on their practical utility in real-world applications, bypassing
problematic alignment procedures. We benchmark eight state-of-the-art DFMs and
provide an in-depth analysis of key findings and observations. We hope our work
sparks further discussion in the community on best practices for depth model
evaluation and paves the way for future research and advancements in depth
estimation.

</details>


### [100] [ExDD: Explicit Dual Distribution Learning for Surface Defect Detection via Diffusion Synthesis](https://arxiv.org/abs/2507.15335)
*Muhammad Aqeel,Federico Leonardi,Francesco Setti*

Main category: cs.CV

TL;DR: ExDD框架通过显式建模双重特征分布，解决了工业缺陷检测中单类异常检测的局限性，结合潜在扩散模型生成合成缺陷数据，提升了检测性能。


<details>
  <summary>Details</summary>
Motivation: 工业缺陷检测系统在单类异常检测范式下存在局限，假设异常分布均匀且数据稀缺，难以适应实际制造环境。

Method: 提出ExDD框架，显式建模正常与异常特征的双重分布，利用潜在扩散模型生成合成缺陷数据，并设计邻域感知评分机制。

Result: 在KSDD2数据集上表现优异（94.2% I-AUROC, 97.7% P-AUROC），100个合成样本时效果最佳。

Conclusion: ExDD通过双重分布建模和合成数据生成，显著提升了工业缺陷检测的性能和适应性。

Abstract: Industrial defect detection systems face critical limitations when confined
to one-class anomaly detection paradigms, which assume uniform outlier
distributions and struggle with data scarcity in realworld manufacturing
environments. We present ExDD (Explicit Dual Distribution), a novel framework
that transcends these limitations by explicitly modeling dual feature
distributions. Our approach leverages parallel memory banks that capture the
distinct statistical properties of both normality and anomalous patterns,
addressing the fundamental flaw of uniform outlier assumptions. To overcome
data scarcity, we employ latent diffusion models with domain-specific textual
conditioning, generating in-distribution synthetic defects that preserve
industrial context. Our neighborhood-aware ratio scoring mechanism elegantly
fuses complementary distance metrics, amplifying signals in regions exhibiting
both deviation from normality and similarity to known defect patterns.
Experimental validation on KSDD2 demonstrates superior performance (94.2%
I-AUROC, 97.7% P-AUROC), with optimal augmentation at 100 synthetic samples.

</details>


### [101] [RoadFusion: Latent Diffusion Model for Pavement Defect Detection](https://arxiv.org/abs/2507.15346)
*Muhammad Aqeel,Kidus Dagnaw Bellete,Francesco Setti*

Main category: cs.CV

TL;DR: RoadFusion通过合成异常生成和双路径特征适应解决路面缺陷检测中的数据稀缺、领域偏移和缺陷多样性问题。


<details>
  <summary>Details</summary>
Motivation: 路面缺陷检测面临标注数据稀缺、训练与部署环境间的领域偏移以及缺陷外观的高变异性等挑战。

Method: 使用潜在扩散模型合成多样化的真实缺陷，通过双路径特征适应器分别处理正常和异常输入，轻量级判别器学习细粒度缺陷模式。

Result: 在六个基准数据集上，RoadFusion在分类和定位任务中表现优异，多项指标达到新SOTA。

Conclusion: RoadFusion为路面缺陷检测提供了一种高效解决方案，显著提升了实际道路检查的性能。

Abstract: Pavement defect detection faces critical challenges including limited
annotated data, domain shift between training and deployment environments, and
high variability in defect appearances across different road conditions. We
propose RoadFusion, a framework that addresses these limitations through
synthetic anomaly generation with dual-path feature adaptation. A latent
diffusion model synthesizes diverse, realistic defects using text prompts and
spatial masks, enabling effective training under data scarcity. Two separate
feature adaptors specialize representations for normal and anomalous inputs,
improving robustness to domain shift and defect variability. A lightweight
discriminator learns to distinguish fine-grained defect patterns at the patch
level. Evaluated on six benchmark datasets, RoadFusion achieves consistently
strong performance across both classification and localization tasks, setting
new state-of-the-art in multiple metrics relevant to real-world road
inspection.

</details>


### [102] [DAViD: Data-efficient and Accurate Vision Models from Synthetic Data](https://arxiv.org/abs/2507.15365)
*Fatemeh Saleh,Sadegh Aliakbarian,Charlie Hewitt,Lohit Petikam,Xiao-Xian,Antonio Criminisi,Thomas J. Cashman,Tadas Baltrušaitis*

Main category: cs.CV

TL;DR: 论文提出使用高保真合成数据集训练模型，实现高精度且高效，无需大规模真实数据。


<details>
  <summary>Details</summary>
Motivation: 解决传统方法需要大规模数据和昂贵计算资源的问题，同时提升数据多样性和公平性。

Method: 利用合成数据集训练模型，提供完美标签和数据多样性控制。

Result: 在深度估计、表面法线估计和前景分割任务中实现高精度，且成本大幅降低。

Conclusion: 合成数据集是高效且公平的替代方案，适用于多种密集预测任务。

Abstract: The state of the art in human-centric computer vision achieves high accuracy
and robustness across a diverse range of tasks. The most effective models in
this domain have billions of parameters, thus requiring extremely large
datasets, expensive training regimes, and compute-intensive inference. In this
paper, we demonstrate that it is possible to train models on much smaller but
high-fidelity synthetic datasets, with no loss in accuracy and higher
efficiency. Using synthetic training data provides us with excellent levels of
detail and perfect labels, while providing strong guarantees for data
provenance, usage rights, and user consent. Procedural data synthesis also
provides us with explicit control on data diversity, that we can use to address
unfairness in the models we train. Extensive quantitative assessment on real
input images demonstrates accuracy of our models on three dense prediction
tasks: depth estimation, surface normal estimation, and soft foreground
segmentation. Our models require only a fraction of the cost of training and
inference when compared with foundational models of similar accuracy. Our
human-centric synthetic dataset and trained models are available at
https://aka.ms/DAViD.

</details>


### [103] [Rethinking Occlusion in FER: A Semantic-Aware Perspective and Go Beyond](https://arxiv.org/abs/2507.15401)
*Huiyu Zhai,Xingxing Yang,Yalan Ye,Chenyang Li,Bin Fan,Changze Li*

Main category: cs.CV

TL;DR: ORSANet通过多模态语义引导、多尺度交互模块和动态对抗排斥损失，提升了遮挡条件下的面部表情识别性能。


<details>
  <summary>Details</summary>
Motivation: 现有FER模型在面部部分遮挡时难以提取有效特征，导致分类不准确。

Method: 1) 引入语义分割图和面部标志作为多模态先验；2) 设计多尺度交互模块融合特征；3) 提出动态对抗排斥损失优化分类。

Result: 在公共基准和自建Occlu-FER数据集上达到SOTA性能。

Conclusion: ORSANet有效解决了遮挡条件下的FER问题，并开源了代码。

Abstract: Facial expression recognition (FER) is a challenging task due to pervasive
occlusion and dataset biases. Especially when facial information is partially
occluded, existing FER models struggle to extract effective facial features,
leading to inaccurate classifications. In response, we present ORSANet, which
introduces the following three key contributions: First, we introduce auxiliary
multi-modal semantic guidance to disambiguate facial occlusion and learn
high-level semantic knowledge, which is two-fold: 1) we introduce semantic
segmentation maps as dense semantics prior to generate semantics-enhanced
facial representations; 2) we introduce facial landmarks as sparse geometric
prior to mitigate intrinsic noises in FER, such as identity and gender biases.
Second, to facilitate the effective incorporation of these two multi-modal
priors, we customize a Multi-scale Cross-interaction Module (MCM) to adaptively
fuse the landmark feature and semantics-enhanced representations within
different scales. Third, we design a Dynamic Adversarial Repulsion Enhancement
Loss (DARELoss) that dynamically adjusts the margins of ambiguous classes,
further enhancing the model's ability to distinguish similar expressions. We
further construct the first occlusion-oriented FER dataset to facilitate
specialized robustness analysis on various real-world occlusion conditions,
dubbed Occlu-FER. Extensive experiments on both public benchmarks and Occlu-FER
demonstrate that our proposed ORSANet achieves SOTA recognition performance.
Code is publicly available at https://github.com/Wenyuzhy/ORSANet-master.

</details>


### [104] [SurgX: Neuron-Concept Association for Explainable Surgical Phase Recognition](https://arxiv.org/abs/2507.15418)
*Ka Young Kim,Hyeon Bae Kim,Seong Tae Kim*

Main category: cs.CV

TL;DR: SurgX是一个新颖的概念解释框架，旨在提高手术阶段识别模型的可解释性，通过将神经元与相关概念关联。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在手术阶段识别中取得了进展，但其不透明性阻碍了信任和调试。

Method: 提出SurgX框架，包括选择代表性示例序列、构建概念集、关联神经元与概念，并识别关键神经元。

Result: 在两个手术阶段识别模型上验证了方法的有效性，并分析了预测解释。

Conclusion: SurgX展示了在解释手术阶段识别中的潜力，代码已开源。

Abstract: Surgical phase recognition plays a crucial role in surgical workflow
analysis, enabling various applications such as surgical monitoring, skill
assessment, and workflow optimization. Despite significant advancements in deep
learning-based surgical phase recognition, these models remain inherently
opaque, making it difficult to understand how they make decisions. This lack of
interpretability hinders trust and makes it challenging to debug the model. To
address this challenge, we propose SurgX, a novel concept-based explanation
framework that enhances the interpretability of surgical phase recognition
models by associating neurons with relevant concepts. In this paper, we
introduce the process of selecting representative example sequences for
neurons, constructing a concept set tailored to the surgical video dataset,
associating neurons with concepts and identifying neurons crucial for
predictions. Through extensive experiments on two surgical phase recognition
models, we validate our method and analyze the explanation for prediction. This
highlights the potential of our method in explaining surgical phase
recognition. The code is available at https://github.com/ailab-kyunghee/SurgX

</details>


### [105] [EgoPrune: Efficient Token Pruning for Egomotion Video Reasoning in Embodied Agent](https://arxiv.org/abs/2507.15428)
*Jiaao Li,Kaiyuan Li,Chen Gao,Yong Li,Xinlei Chen*

Main category: cs.CV

TL;DR: EgoPrune是一种无需训练的令牌修剪方法，专门用于提高第一人称视频（egomotion）的推理效率，通过关键帧选择、视角感知冗余过滤和MMR令牌选择器显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 第一人称视频是AI代理的主要视觉输入，但现有令牌修剪方法未充分利用其时空连续性和运动约束，导致计算成本高。

Method: EgoPrune包括关键帧选择器、视角感知冗余过滤（PARF）和基于MMR的令牌选择器，联合优化视觉-文本相关性和帧内多样性。

Result: 在两个基准测试中，EgoPrune优于现有方法，显著减少FLOPs、内存使用和延迟，并在边缘设备上验证了其实用性。

Conclusion: EgoPrune为第一人称视频推理提供了一种高效、实用的解决方案，适用于实际部署。

Abstract: Egomotion videos are first-person recordings where the view changes
continuously due to the agent's movement. As they serve as the primary visual
input for embodied AI agents, making egomotion video reasoning more efficient
is therefore essential for real-world deployment. Recent advances in
vision-language models have enabled strong multimodal reasoning capabilities,
but their computational cost remains prohibitive for long, redundant video
inputs. Existing token pruning methods, typically designed for third-person
videos, fail to leverage the spatiotemporal continuity and motion constraints
inherent in egomotion settings. To address this, we propose EgoPrune, a
training-free token pruning method tailored for egomotion video reasoning.
EgoPrune comprises three components: a keyframe selector adapted from EmbodiedR
for temporally efficient sampling; Perspective-Aware Redundancy Filtering
(PARF), which aligns visual tokens using perspective transformations and
removes redundant tokens; and a Maximal Marginal Relevance (MMR)-based token
selector that jointly considers visual-text relevance and intra-frame
diversity. Experiments on two egomotion video benchmarks show that EgoPrune
consistently outperforms prior training-free methods across various pruning
ratios while significantly reducing FLOPs, memory usage, and latency. Moreover,
we deploy EgoPrune on an embodied agent equipped with a Jetson Orin NX 16GB
edge device, demonstrating its real-world efficiency and suitability for
on-device egomotion video reasoning.

</details>


### [106] [One Last Attention for Your Vision-Language Model](https://arxiv.org/abs/2507.15480)
*Liang Chen,Ghazi Shazan Ahmad,Tianjun Yao,Lingqiao Liu,Zhiqiang Shen*

Main category: cs.CV

TL;DR: RAda是一种简单有效的视觉语言模型微调方法，通过动态校准融合表示来优化跨模态交互。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视了融合表示在决策中的关键作用，RAda旨在填补这一空白。

Method: RAda使用轻量级注意力层生成学习掩码，动态调整融合表示中各元素的贡献。

Result: 实验表明RAda在多种设置下表现优异，优于基线方法并与当前最佳方法相当。

Conclusion: RAda是一种通用且高效的微调技术，适用于不同场景，代码已开源。

Abstract: Pretrained vision-language models (VLMs), such as CLIP, achieve remarkable
zero-shot performance, yet their downstream potential hinges on effective
fine-tuning. Most adaptation methods typically focus on refining representation
from separate modalities (text or vision) but neglect the critical role of
their fused representations in the decision-making process, \emph{\ie} rational
matrix that drives the final prediction. To bridge the gap, we propose a simple
yet effective \textbf{R}ational \textbf{Ada}ptaion ({RAda}) to explicitly
exploit the final fused representation during fine-tuning. RAda employs a
learned mask, obtained from a lightweight attention layer attached at the end
of a VLM, to dynamically calibrate the contribution of each element in the
rational matrix, enabling targeted adjustments to the final cross-modal
interactions without incurring costly modifications to intermediate features.
Experiments in different settings (i.e., updating, or freezing pretrained
encoders in adaptation, and test-time training that can only access the
unlabeled test data) show that RAda serves as a versatile fine-tuning
technique, improving the baseline with minimal code and performing comparably
against current arts in most settings. Code is available at
\href{https://github.com/khufia/RAda/tree/main}{github.com/khufia/RAda}.

</details>


### [107] [An aerial color image anomaly dataset for search missions in complex forested terrain](https://arxiv.org/abs/2507.15492)
*Rakesh John Amala Arokia Nathan,Matthias Gessner,Nurullah Özkan,Marius Bock,Mohamed Youssef,Maximilian Mews,Björn Piltz,Ralf Berger,Oliver Bimber*

Main category: cs.CV

TL;DR: 论文通过一起德国农村家庭谋杀案，利用高分辨率航空影像和众包搜索，构建了一个在复杂森林环境中难以检测的异常数据集，用于改进异常检测方法。


<details>
  <summary>Details</summary>
Motivation: 由于茂密植被遮挡，传统自动化分析失效，需要开发更有效的异常检测方法以支持搜捕和救援行动。

Method: 通过研究飞机获取高分辨率航空影像，并启动众包搜索，构建标注数据集。

Result: 现有方法在初始基准测试中表现不佳，凸显了需要上下文感知方法。

Conclusion: 该数据集可作为复杂森林环境中异常检测的基准，并支持动态增长和在线标注。

Abstract: After a family murder in rural Germany, authorities failed to locate the
suspect in a vast forest despite a massive search. To aid the search, a
research aircraft captured high-resolution aerial imagery. Due to dense
vegetation obscuring small clues, automated analysis was ineffective, prompting
a crowd-search initiative. This effort produced a unique dataset of labeled,
hard-to-detect anomalies under occluded, real-world conditions. It can serve as
a benchmark for improving anomaly detection approaches in complex forest
environments, supporting manhunts and rescue operations. Initial benchmark
tests showed existing methods performed poorly, highlighting the need for
context-aware approaches. The dataset is openly accessible for offline
processing. An additional interactive web interface supports online viewing and
dynamic growth by allowing users to annotate and submit new findings.

</details>


### [108] [Quantifying and Narrowing the Unknown: Interactive Text-to-Video Retrieval via Uncertainty Minimization](https://arxiv.org/abs/2507.15504)
*Bingqing Zhang,Zhuo Cao,Heming Du,Yang Li,Xue Li,Jiajun Liu,Sen Wang*

Main category: cs.CV

TL;DR: UMIVR是一个基于不确定性最小化的交互式文本到视频检索框架，通过量化文本模糊性、映射不确定性和帧不确定性，生成针对性问题以优化检索效果。


<details>
  <summary>Details</summary>
Motivation: 当前交互式文本到视频检索方法依赖启发式策略，未能显式量化不确定性，限制了其效果。

Method: UMIVR通过语义熵（TAS）、Jensen-Shannon散度（MUS）和时序质量采样器（TQFS）量化不确定性，并生成针对性问题。

Result: 在MSR-VTT-1k数据集上，UMIVR在10轮交互后Recall@1达到69.2%。

Conclusion: UMIVR为交互式文本到视频检索建立了不确定性最小化的基础，显著提升了检索效果。

Abstract: Despite recent advances, Text-to-video retrieval (TVR) is still hindered by
multiple inherent uncertainties, such as ambiguous textual queries, indistinct
text-video mappings, and low-quality video frames. Although interactive systems
have emerged to address these challenges by refining user intent through
clarifying questions, current methods typically rely on heuristic or ad-hoc
strategies without explicitly quantifying these uncertainties, limiting their
effectiveness. Motivated by this gap, we propose UMIVR, an
Uncertainty-Minimizing Interactive Text-to-Video Retrieval framework that
explicitly quantifies three critical uncertainties-text ambiguity, mapping
uncertainty, and frame uncertainty-via principled, training-free metrics:
semantic entropy-based Text Ambiguity Score (TAS), Jensen-Shannon
divergence-based Mapping Uncertainty Score (MUS), and a Temporal Quality-based
Frame Sampler (TQFS). By adaptively generating targeted clarifying questions
guided by these uncertainty measures, UMIVR iteratively refines user queries,
significantly reducing retrieval ambiguity. Extensive experiments on multiple
benchmarks validate UMIVR's effectiveness, achieving notable gains in Recall@1
(69.2\% after 10 interactive rounds) on the MSR-VTT-1k dataset, thereby
establishing an uncertainty-minimizing foundation for interactive TVR.

</details>


### [109] [SAIGFormer: A Spatially-Adaptive Illumination-Guided Network for Low-Light Image Enhancement](https://arxiv.org/abs/2507.15520)
*Hanting Li,Fei Zhou,Xin Sun,Yang Hua,Jungong Han,Liang-Jie Zhang*

Main category: cs.CV

TL;DR: SAIGFormer是一种基于Transformer的低光照增强方法，通过动态积分图像表示和光照引导的多头自注意力机制，有效解决了非均匀光照场景下的亮度恢复问题。


<details>
  <summary>Details</summary>
Motivation: 现有Transformer方法在非均匀光照场景（如背光和阴影）中表现不佳，容易出现过曝或亮度恢复不足的问题。

Method: 提出动态积分图像表示建模空间变化的光照，构建SAI²E估计器，并引入光照引导的多头自注意力机制（IG-MSA）。

Result: 在五个标准低光照数据集和跨域基准（LOL-Blur）上，SAIGFormer在定量和定性指标上均显著优于现有方法。

Conclusion: SAIGFormer在非均匀光照增强中表现优异，并展现出强大的跨数据集泛化能力。

Abstract: Recent Transformer-based low-light enhancement methods have made promising
progress in recovering global illumination. However, they still struggle with
non-uniform lighting scenarios, such as backlit and shadow, appearing as
over-exposure or inadequate brightness restoration. To address this challenge,
we present a Spatially-Adaptive Illumination-Guided Transformer (SAIGFormer)
framework that enables accurate illumination restoration. Specifically, we
propose a dynamic integral image representation to model the spatially-varying
illumination, and further construct a novel Spatially-Adaptive Integral
Illumination Estimator ($\text{SAI}^2\text{E}$). Moreover, we introduce an
Illumination-Guided Multi-head Self-Attention (IG-MSA) mechanism, which
leverages the illumination to calibrate the lightness-relevant features toward
visual-pleased illumination enhancement. Extensive experiments on five standard
low-light datasets and a cross-domain benchmark (LOL-Blur) demonstrate that our
SAIGFormer significantly outperforms state-of-the-art methods in both
quantitative and qualitative metrics. In particular, our method achieves
superior performance in non-uniform illumination enhancement while exhibiting
strong generalization capabilities across multiple datasets. Code is available
at https://github.com/LHTcode/SAIGFormer.git.

</details>


### [110] [Procedure Learning via Regularized Gromov-Wasserstein Optimal Transport](https://arxiv.org/abs/2507.15540)
*Syed Ahmed Mahmood,Ali Shah Ali,Umer Ahmed,Fawad Javed Fateh,M. Zeeshan Zia,Quoc-Huy Tran*

Main category: cs.CV

TL;DR: 提出了一种自监督程序学习框架，通过融合Gromov-Wasserstein最优传输和对比正则化，解决了视频中关键步骤发现和顺序确定的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理顺序变化、背景冗余帧和重复动作时表现不佳，需要改进。

Method: 结合Gromov-Wasserstein最优传输和对比正则化，避免嵌入空间退化。

Result: 在多个基准测试中表现优于现有方法，如OPEL。

Conclusion: 该方法有效解决了自监督程序学习中的关键问题，性能显著提升。

Abstract: We study the problem of self-supervised procedure learning, which discovers
key steps and establishes their order from a set of unlabeled procedural
videos. Previous procedure learning methods typically learn frame-to-frame
correspondences between videos before determining key steps and their order.
However, their performance often suffers from order variations,
background/redundant frames, and repeated actions. To overcome these
challenges, we propose a self-supervised procedure learning framework, which
utilizes a fused Gromov-Wasserstein optimal transport formulation with a
structural prior for computing frame-to-frame mapping between videos. However,
optimizing exclusively for the above temporal alignment term may lead to
degenerate solutions, where all frames are mapped to a small cluster in the
embedding space and hence every video is associated with only one key step. To
address that limitation, we further integrate a contrastive regularization
term, which maps different frames to different points in the embedding space,
avoiding the collapse to trivial solutions. Finally, we conduct extensive
experiments on large-scale egocentric (i.e., EgoProceL) and third-person (i.e.,
ProceL and CrossTask) benchmarks to demonstrate superior performance by our
approach against previous methods, including OPEL which relies on a traditional
Kantorovich optimal transport formulation with an optimality prior.

</details>


### [111] [Towards Holistic Surgical Scene Graph](https://arxiv.org/abs/2507.15541)
*Jongmin Shin,Enki Cho,Ka Yong Kim,Jung Yong Kim,Seong Tae Kim,Namkee Oh*

Main category: cs.CV

TL;DR: 论文提出了一种新的数据集和方法，用于改进手术场景的图表示，重点关注工具-动作-目标组合和操作手身份。


<details>
  <summary>Details</summary>
Motivation: 手术场景理解需要更全面的图表示方法，现有研究未充分探索工具-动作-目标组合和操作手身份的重要性。

Method: 提出了Endoscapes-SG201数据集和SSG-Com方法，用于标注和学习手术场景中的关键元素。

Result: 实验证明，这些关键元素对手术场景理解任务（如安全评估和动作识别）有显著贡献。

Conclusion: 通过整合工具-动作-目标组合和操作手身份，图表示方法能更有效地支持手术场景理解。

Abstract: Surgical scene understanding is crucial for computer-assisted intervention
systems, requiring visual comprehension of surgical scenes that involves
diverse elements such as surgical tools, anatomical structures, and their
interactions. To effectively represent the complex information in surgical
scenes, graph-based approaches have been explored to structurally model
surgical entities and their relationships. Previous surgical scene graph
studies have demonstrated the feasibility of representing surgical scenes using
graphs. However, certain aspects of surgical scenes-such as diverse
combinations of tool-action-target and the identity of the hand operating the
tool-remain underexplored in graph-based representations, despite their
importance. To incorporate these aspects into graph representations, we propose
Endoscapes-SG201 dataset, which includes annotations for tool-action-target
combinations and hand identity. We also introduce SSG-Com, a graph-based method
designed to learn and represent these critical elements. Through experiments on
downstream tasks such as critical view of safety assessment and action triplet
recognition, we demonstrated the importance of integrating these essential
scene graph components, highlighting their significant contribution to surgical
scene understanding. The code and dataset are available at
https://github.com/ailab-kyunghee/SSG-Com

</details>


### [112] [HOLa: Zero-Shot HOI Detection with Low-Rank Decomposed VLM Feature Adaptation](https://arxiv.org/abs/2507.15542)
*Qinqian Lei,Bo Wang,Robby T. Tan*

Main category: cs.CV

TL;DR: HOLa提出了一种零样本人-物交互检测方法，通过低秩分解VLM特征增强对未见类别的泛化能力，并改进动作区分。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在区分相同对象的不同动作或泛化到未见类别时的局限性。

Method: 使用低秩分解VLM文本特征，生成类共享基础特征和可调权重，结合LLM动作正则化优化权重。

Result: 在HICO-DET上实现了未见动词设置的27.91 mAP，达到新SOTA。

Conclusion: HOLa通过特征分解和权重优化，显著提升了零样本HOI检测的性能。

Abstract: Zero-shot human-object interaction (HOI) detection remains a challenging
task, particularly in generalizing to unseen actions. Existing methods address
this challenge by tapping Vision-Language Models (VLMs) to access knowledge
beyond the training data. However, they either struggle to distinguish actions
involving the same object or demonstrate limited generalization to unseen
classes. In this paper, we introduce HOLa (Zero-Shot HOI Detection with
Low-Rank Decomposed VLM Feature Adaptation), a novel approach that both
enhances generalization to unseen classes and improves action distinction. In
training, HOLa decomposes VLM text features for given HOI classes via low-rank
factorization, producing class-shared basis features and adaptable weights.
These features and weights form a compact HOI representation that preserves
shared information across classes, enhancing generalization to unseen classes.
Subsequently, we refine action distinction by adapting weights for each HOI
class and introducing human-object tokens to enrich visual interaction
representations. To further distinguish unseen actions, we guide the weight
adaptation with LLM-derived action regularization. Experimental results show
that our method sets a new state-of-the-art across zero-shot HOI settings on
HICO-DET, achieving an unseen-class mAP of 27.91 in the unseen-verb setting.
Our code is available at https://github.com/ChelsieLei/HOLa.

</details>


### [113] [DynImg: Key Frames with Visual Prompts are Good Representation for Multi-Modal Video Understanding](https://arxiv.org/abs/2507.15569)
*Xiaoyi Bao,Chenwei Xie,Hao Tang,Tingyu Weng,Xiaofeng Wang,Yun Zheng,Xingang Wang*

Main category: cs.CV

TL;DR: 提出了一种名为Dynamic-Image (DynImg)的视频表示方法，通过引入非关键帧作为时间提示，增强对快速移动物体空间特征的关注，并结合4D视频旋转位置嵌入保持时空顺序，显著提升了视频理解性能。


<details>
  <summary>Details</summary>
Motivation: 传统方法将时空信息分离处理，导致快速移动物体的空间信息难以准确表示，影响时空交互和视频理解。

Method: 提出DynImg方法，利用非关键帧作为时间提示，结合4D视频旋转位置嵌入，增强对快速移动物体空间特征的关注。

Result: 在多个视频理解基准测试中，DynImg性能优于现有方法约2%。

Conclusion: DynImg通过时间提示和时空顺序保持，有效提升了视频理解的准确性。

Abstract: In recent years, the introduction of Multi-modal Large Language Models
(MLLMs) into video understanding tasks has become increasingly prevalent.
However, how to effectively integrate temporal information remains a critical
research focus. Traditional approaches treat spatial and temporal information
separately. Due to issues like motion blur, it is challenging to accurately
represent the spatial information of rapidly moving objects. This can lead to
temporally important regions being underemphasized during spatial feature
extraction, which in turn hinders accurate spatio-temporal interaction and
video understanding. To address this limitation, we propose an innovative video
representation method called Dynamic-Image (DynImg). Specifically, we introduce
a set of non-key frames as temporal prompts to highlight the spatial areas
containing fast-moving objects. During the process of visual feature
extraction, these prompts guide the model to pay additional attention to the
fine-grained spatial features corresponding to these regions. Moreover, to
maintain the correct sequence for DynImg, we employ a corresponding 4D video
Rotary Position Embedding. This retains both the temporal and spatial adjacency
of DynImg, helping MLLM understand the spatio-temporal order within this
combined format. Experimental evaluations reveal that DynImg surpasses the
state-of-the-art methods by approximately 2% across multiple video
understanding benchmarks, proving the effectiveness of our temporal prompts in
enhancing video comprehension.

</details>


### [114] [GeMix: Conditional GAN-Based Mixup for Improved Medical Image Augmentation](https://arxiv.org/abs/2507.15577)
*Hugo Carlesso,Maria Eliza Patulea,Moncef Garouani,Radu Tudor Ionescu,Josiane Mothe*

Main category: cs.CV

TL;DR: GeMix是一种基于类条件GAN的两阶段图像增强框架，用于生成更真实的混合图像，提升医学图像分类性能。


<details>
  <summary>Details</summary>
Motivation: 传统Mixup的像素级插值生成的图像不真实，可能影响学习效果，尤其是在高风险的医学应用中。

Method: 使用StyleGAN2-ADA生成器，通过Dirichlet和Beta分布采样标签向量，生成连续类别流形上的视觉一致图像。

Result: 在COVIDx-CT-3数据集上，GeMix结合真实数据提升了所有骨干网络的macro-F1，降低了COVID-19检测的假阴性率。

Conclusion: GeMix是传统Mixup的直接替代方案，提供更强的正则化和语义保真度，且不破坏现有训练流程。

Abstract: Mixup has become a popular augmentation strategy for image classification,
yet its naive pixel-wise interpolation often produces unrealistic images that
can hinder learning, particularly in high-stakes medical applications. We
propose GeMix, a two-stage framework that replaces heuristic blending with a
learned, label-aware interpolation powered by class-conditional GANs. First, a
StyleGAN2-ADA generator is trained on the target dataset. During augmentation,
we sample two label vectors from Dirichlet priors biased toward different
classes and blend them via a Beta-distributed coefficient. Then, we condition
the generator on this soft label to synthesize visually coherent images that
lie along a continuous class manifold. We benchmark GeMix on the large-scale
COVIDx-CT-3 dataset using three backbones (ResNet-50, ResNet-101,
EfficientNet-B0). When combined with real data, our method increases macro-F1
over traditional mixup for all backbones, reducing the false negative rate for
COVID-19 detection. GeMix is thus a drop-in replacement for pixel-space mixup,
delivering stronger regularization and greater semantic fidelity, without
disrupting existing training pipelines. We publicly release our code at
https://github.com/hugocarlesso/GeMix to foster reproducibility and further
research.

</details>


### [115] [Compress-Align-Detect: onboard change detection from unregistered images](https://arxiv.org/abs/2507.15578)
*Gabriele Inzerillo,Diego Valsesia,Aniello Fiengo,Enrico Magli*

Main category: cs.CV

TL;DR: 提出一种卫星上实时变化检测框架，解决数据存储、图像配准和变化检测的挑战，通过端到端深度神经网络实现高效处理。


<details>
  <summary>Details</summary>
Motivation: 卫星图像变化检测通常因地面站处理延迟而无法实时应用，需将整个工作流程移至卫星上。

Method: 采用端到端深度神经网络，包含图像压缩、轻量级配准和高效变化检测三个子模块。

Result: 在低功耗硬件上实现0.7 Mpixel/s的吞吐量，F1分数表现优异。

Conclusion: 框架在卫星上实时处理中表现高效，为实时变化检测提供了可行方案。

Abstract: Change detection from satellite images typically incurs a delay ranging from
several hours up to days because of latency in downlinking the acquired images
and generating orthorectified image products at the ground stations; this may
preclude real- or near real-time applications. To overcome this limitation, we
propose shifting the entire change detection workflow onboard satellites. This
requires to simultaneously solve challenges in data storage, image registration
and change detection with a strict complexity constraint. In this paper, we
present a novel and efficient framework for onboard change detection that
addresses the aforementioned challenges in an end-to-end fashion with a deep
neural network composed of three interlinked submodules: (1) image compression,
tailored to minimize onboard data storage resources; (2) lightweight
co-registration of non-orthorectified multi-temporal image pairs; and (3) a
novel temporally-invariant and computationally efficient change detection
model. This is the first approach in the literature combining all these tasks
in a single end-to-end framework with the constraints dictated by onboard
processing. Experimental results compare each submodule with the current
state-of-the-art, and evaluate the performance of the overall integrated system
in realistic setting on low-power hardware. Compelling change detection results
are obtained in terms of F1 score as a function of compression rate, sustaining
a throughput of 0.7 Mpixel/s on a 15W accelerator.

</details>


### [116] [SegDT: A Diffusion Transformer-Based Segmentation Model for Medical Imaging](https://arxiv.org/abs/2507.15595)
*Salah Eddine Bekhouche,Gaby Maroun,Fadi Dornaika,Abdenour Hadid*

Main category: cs.CV

TL;DR: SegDT是一种基于扩散变换器（DiT）的新型皮肤病变分割模型，适用于低成本硬件，通过Rectified Flow提升生成质量并保持快速推理速度，在多个基准数据集上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 皮肤病变分割对皮肤癌诊断和患者监测至关重要，现有方法在性能和效率上仍有提升空间。

Method: 提出SegDT模型，结合扩散变换器和Rectified Flow技术，优化生成质量并减少推理步骤。

Result: 在三个基准数据集上取得最先进结果，同时保持快速推理速度。

Conclusion: SegDT为医疗图像分析提供了高效、准确的工具，适用于实际医疗应用，代码已开源。

Abstract: Medical image segmentation is crucial for many healthcare tasks, including
disease diagnosis and treatment planning. One key area is the segmentation of
skin lesions, which is vital for diagnosing skin cancer and monitoring
patients. In this context, this paper introduces SegDT, a new segmentation
model based on diffusion transformer (DiT). SegDT is designed to work on
low-cost hardware and incorporates Rectified Flow, which improves the
generation quality at reduced inference steps and maintains the flexibility of
standard diffusion models. Our method is evaluated on three benchmarking
datasets and compared against several existing works, achieving
state-of-the-art results while maintaining fast inference speeds. This makes
the proposed model appealing for real-world medical applications. This work
advances the performance and capabilities of deep learning models in medical
image analysis, enabling faster, more accurate diagnostic tools for healthcare
professionals. The code is made publicly available at
\href{https://github.com/Bekhouche/SegDT}{GitHub}.

</details>


### [117] [SurfaceSplat: Connecting Surface Reconstruction and Gaussian Splatting](https://arxiv.org/abs/2507.15602)
*Zihui Gao,Jia-Wang Bian,Guosheng Lin,Hao Chen,Chunhua Shen*

Main category: cs.CV

TL;DR: 提出了一种结合SDF和3DGS的混合方法，用于稀疏视图图像中的表面重建和新视角渲染，优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 稀疏视图图像中的表面重建和新视角渲染具有挑战性，现有方法（如SDF和3DGS）各有不足。

Method: 结合SDF和3DGS的优势：SDF捕捉粗粒度几何，3DGS渲染细化细节。

Result: 在DTU和MobileBrick数据集上，表面重建和新视角合成效果优于现有方法。

Conclusion: 混合方法有效解决了稀疏视图重建问题，代码将开源。

Abstract: Surface reconstruction and novel view rendering from sparse-view images are
challenging. Signed Distance Function (SDF)-based methods struggle with fine
details, while 3D Gaussian Splatting (3DGS)-based approaches lack global
geometry coherence. We propose a novel hybrid method that combines the
strengths of both approaches: SDF captures coarse geometry to enhance
3DGS-based rendering, while newly rendered images from 3DGS refine the details
of SDF for accurate surface reconstruction. As a result, our method surpasses
state-of-the-art approaches in surface reconstruction and novel view synthesis
on the DTU and MobileBrick datasets. Code will be released at
https://github.com/Gaozihui/SurfaceSplat.

</details>


### [118] [CylinderPlane: Nested Cylinder Representation for 3D-aware Image Generation](https://arxiv.org/abs/2507.15606)
*Ru Jia,Xiaozhuang Ma,Jianji Wang,Nanning Zheng*

Main category: cs.CV

TL;DR: 提出CylinderPlane，一种基于圆柱坐标系的新型隐式表示，解决了Tri-plane表示中的多视角一致性问题，实现了高质量无伪影的360°图像合成。


<details>
  <summary>Details</summary>
Motivation: Tri-plane表示在对称区域共享特征导致多面伪影，限制了360°视图图像的生成能力。

Method: 采用圆柱坐标系明确分离不同角度的特征，引入嵌套圆柱表示以处理复杂几何和多分辨率需求。

Result: 在合成数据集和真实图像上表现出优于现有方法的性能。

Conclusion: CylinderPlane解决了Tri-plane的局限性，为360°图像合成提供了更优的解决方案。

Abstract: While the proposal of the Tri-plane representation has advanced the
development of the 3D-aware image generative models, problems rooted in its
inherent structure, such as multi-face artifacts caused by sharing the same
features in symmetric regions, limit its ability to generate 360$^\circ$ view
images. In this paper, we propose CylinderPlane, a novel implicit
representation based on Cylindrical Coordinate System, to eliminate the feature
ambiguity issue and ensure multi-view consistency in 360$^\circ$. Different
from the inevitable feature entanglement in Cartesian coordinate-based
Tri-plane representation, the cylindrical coordinate system explicitly
separates features at different angles, allowing our cylindrical representation
possible to achieve high-quality, artifacts-free 360$^\circ$ image synthesis.
We further introduce the nested cylinder representation that composites
multiple cylinders at different scales, thereby enabling the model more
adaptable to complex geometry and varying resolutions. The combination of
cylinders with different resolutions can effectively capture more critical
locations and multi-scale features, greatly facilitates fine detail learning
and robustness to different resolutions. Moreover, our representation is
agnostic to implicit rendering methods and can be easily integrated into any
neural rendering pipeline. Extensive experiments on both synthetic dataset and
unstructured in-the-wild images demonstrate that our proposed representation
achieves superior performance over previous methods.

</details>


### [119] [A Survey on Efficiency Optimization Techniques for DNN-based Video Analytics: Process Systems, Algorithms, and Applications](https://arxiv.org/abs/2507.15628)
*Shanjiang Tang,Rui Huang,Hsinyu Luo,Chunjiang Wang,Ce Yu,Yusen Li,Hao Fu,Chao Sun,and Jian Xiao*

Main category: cs.CV

TL;DR: 本文综述了深度学习在视频分析中的效率优化技术，从硬件支持、数据处理和部署等多角度进行了全面回顾。


<details>
  <summary>Details</summary>
Motivation: 视频数据的爆炸式增长对视频分析的准确性和效率提出了更高要求，而现有研究多关注准确性优化，本文则聚焦于效率提升。

Method: 采用自底向上的方式组织现有方法，涵盖硬件支持、数据处理和操作部署等多个视角。

Result: 提出了优化框架，并基于现有工作分析了深度学习在视频分析中的性能优化问题和挑战。

Conclusion: 本文为深度学习在视频分析中的效率优化提供了系统综述，并指出了未来的研究方向和挑战。

Abstract: The explosive growth of video data in recent years has brought higher demands
for video analytics, where accuracy and efficiency remain the two primary
concerns. Deep neural networks (DNNs) have been widely adopted to ensure
accuracy; however, improving their efficiency in video analytics remains an
open challenge. Different from existing surveys that make summaries of
DNN-based video mainly from the accuracy optimization aspect, in this survey,
we aim to provide a thorough review of optimization techniques focusing on the
improvement of the efficiency of DNNs in video analytics. We organize existing
methods in a bottom-up manner, covering multiple perspectives such as hardware
support, data processing, operational deployment, etc. Finally, based on the
optimization framework and existing works, we analyze and discuss the problems
and challenges in the performance optimization of DNN-based video analytics.

</details>


### [120] [Experimenting active and sequential learning in a medieval music manuscript](https://arxiv.org/abs/2507.15633)
*Sachin Sharma,Federico Simonetta,Michele Flammini*

Main category: cs.CV

TL;DR: 论文探讨了在光学音乐识别（OMR）中应用主动学习（AL）和序列学习（SL）的方法，以减少标注数据的需求并提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决OMR中标注数据稀缺和历史手稿复杂性的问题。

Method: 使用YOLOv8，通过选择预测置信度最低的样本进行迭代标注和重新训练。

Result: 实验表明，仅需少量标注样本即可达到与全监督训练相当的准确率，但AL方法在当前手稿中效果不佳。

Conclusion: 在数据稀缺场景下，需要更有效的方法替代不确定性驱动的AL。

Abstract: Optical Music Recognition (OMR) is a cornerstone of music digitization
initiatives in cultural heritage, yet it remains limited by the scarcity of
annotated data and the complexity of historical manuscripts. In this paper, we
present a preliminary study of Active Learning (AL) and Sequential Learning
(SL) tailored for object detection and layout recognition in an old medieval
music manuscript. Leveraging YOLOv8, our system selects samples with the
highest uncertainty (lowest prediction confidence) for iterative labeling and
retraining. Our approach starts with a single annotated image and successfully
boosts performance while minimizing manual labeling. Experimental results
indicate that comparable accuracy to fully supervised training can be achieved
with significantly fewer labeled examples. We test the methodology as a
preliminary investigation on a novel dataset offered to the community by the
Anonymous project, which studies laude, a poetical-musical genre spread across
Italy during the 12th-16th Century. We show that in the manuscript at-hand,
uncertainty-based AL is not effective and advocates for more usable methods in
data-scarcity scenarios.

</details>


### [121] [Uncovering Critical Features for Deepfake Detection through the Lottery Ticket Hypothesis](https://arxiv.org/abs/2507.15636)
*Lisan Al Amin,Md. Ismail Hossain,Thanh Thi Nguyen,Tasnim Jahan,Mahbubul Islam,Faisal Quader*

Main category: cs.CV

TL;DR: 该研究探讨了彩票假设（LTH）在深度伪造检测中的应用，发现神经网络可以通过修剪保持高准确性，且关键子网络在稀疏条件下仍能维持性能。


<details>
  <summary>Details</summary>
Motivation: 深度伪造技术对信息完整性和社会信任构成挑战，现有检测方法模型庞大且机制不明确，难以在资源有限环境中部署。

Method: 研究采用彩票假设（LTH）和迭代幅度修剪方法，测试了MesoNet、CNN-5和ResNet-18架构在OpenForensic和FaceForensics++数据集上的表现。

Result: 实验显示，MesoNet在80%稀疏度下仍保持56.2%的准确率（基线为62.6%），且LTH方法优于一次性修剪。关键面部区域的注意力通过Grad-CAM可视化验证。

Conclusion: 研究表明，LTH方法能有效识别深度伪造检测中的关键子网络，为高效、可部署的检测系统提供了潜力。

Abstract: Recent advances in deepfake technology have created increasingly convincing
synthetic media that poses significant challenges to information integrity and
social trust. While current detection methods show promise, their underlying
mechanisms remain poorly understood, and the large sizes of their models make
them challenging to deploy in resource-limited environments. This study
investigates the application of the Lottery Ticket Hypothesis (LTH) to deepfake
detection, aiming to identify the key features crucial for recognizing
deepfakes. We examine how neural networks can be efficiently pruned while
maintaining high detection accuracy. Through extensive experiments with
MesoNet, CNN-5, and ResNet-18 architectures on the OpenForensic and
FaceForensics++ datasets, we find that deepfake detection networks contain
winning tickets, i.e., subnetworks, that preserve performance even at
substantial sparsity levels. Our results indicate that MesoNet retains 56.2%
accuracy at 80% sparsity on the OpenForensic dataset, with only 3,000
parameters, which is about 90% of its baseline accuracy (62.6%). The results
also show that our proposed LTH-based iterative magnitude pruning approach
consistently outperforms one-shot pruning methods. Using Grad-CAM
visualization, we analyze how pruned networks maintain their focus on critical
facial regions for deepfake detection. Additionally, we demonstrate the
transferability of winning tickets across datasets, suggesting potential for
efficient, deployable deepfake detection systems.

</details>


### [122] [Extracting Visual Facts from Intermediate Layers for Mitigating Hallucinations in Multimodal Large Language Models](https://arxiv.org/abs/2507.15652)
*Haoran Zhou,Zihan Zhang,Hao Chen*

Main category: cs.CV

TL;DR: 论文提出了一种名为EVA的训练无关方法，通过动态选择中间层提取视觉事实信息，显著减少多模态大语言模型中的幻觉现象。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLMs）在结合视觉和语言理解方面取得进展，但仍存在对象幻觉问题，即模型生成看似合理但实际错误的输出。研究发现先验知识在深层抑制视觉信息，但中间层的机制尚不明确。

Method: 通过观察中间层视觉事实知识与概率分布差异的相似趋势，提出EVA方法，动态选择视觉信息显著的中间层，对比原始输入和纯文本输入的输出分布，提取视觉事实知识并修正最终输出。

Result: EVA在广泛使用的基准测试中显著降低了幻觉率，优于基线方法。

Conclusion: EVA是一种模型无关、无需训练的方法，能有效减少MLLMs中的幻觉现象，适用于多种解码策略和模型。

Abstract: Multimodal Large Language Models (MLLMs) have made significant strides by
combining visual recognition and language understanding to generate content
that is both coherent and contextually accurate. However, MLLMs continue to
struggle with object hallucinations, where models produce seemingly plausible
but factually incorrect outputs, including objects that do not exist in the
image. Recent work has revealed that the prior knowledge in MLLMs significantly
suppresses visual information in deep layers, causing hallucinatory outputs.
However, how these priors suppress visual information at the intermediate layer
stage in MLLMs remains unclear. We observe that visual factual knowledge and
the differences between intermediate-layer prior/original probability
distributions show similar evolutionary trends in intermediate layers.
Motivated by this, we introduce Decoding by Extracting Visual Facts (EVA), a
simple, training-free method that dynamically selects intermediate layers with
the most significant visual factual information. By contrasting the output
distributions of the selected layer derived from the original input and
pure-text input, EVA extracts visual factual knowledge and proportionally
incorporates it into the final layer to correct the output logits. Importantly,
EVA is model-agnostic, seamlessly integrates with various classic decoding
strategies, and is applicable across different MLLMs. We validate EVA on
widely-used benchmarks, and the results show that it significantly reduces
hallucination rates compared to baseline methods, underscoring its
effectiveness in mitigating hallucinations.

</details>


### [123] [HW-MLVQA: Elucidating Multilingual Handwritten Document Understanding with a Comprehensive VQA Benchmark](https://arxiv.org/abs/2507.15655)
*Aniket Pal,Ajoy Mondal,Minesh Mathew,C. V. Jawahar*

Main category: cs.CV

TL;DR: HW-MLVQA是一个新的多语言手写文档视觉问答基准，包含1600页手写文档和2400个问答对，旨在解决现有模型在手写文档理解上的不足。


<details>
  <summary>Details</summary>
Motivation: 当前的多语言视觉问答模型在处理多样化的手写文档时表现不佳，缺乏真实的多语言手写文档理解基准。

Method: HW-MLVQA通过提供1600页手写文档和2400个问答对，并设计了一个涵盖文本、图像及图文结合的评估框架。

Result: 该基准支持对专有和开源OCR模型的严格评估，模拟真实无标注文本的场景。

Conclusion: HW-MLVQA旨在推动多语言手写文档理解领域的研究和创新。

Abstract: The proliferation of MultiLingual Visual Question Answering (MLVQA)
benchmarks augments the capabilities of large language models (LLMs) and
multi-modal LLMs, thereby enabling them to adeptly capture the intricate
linguistic subtleties and visual complexities inherent across diverse
languages. Despite its potential, the current MLVQA model struggles to fully
utilize its capabilities when dealing with the extensive variety of handwritten
documents. This article delineates HW-MLVQA, an avant-garde VQA benchmark
meticulously crafted to mitigate the dearth of authentic Multilingual
Handwritten document comprehension. HW-MLVQA encompasses an extensive
collection of 1,600 handwritten Pages complemented by 2,400 question-answers.
Furthermore, it provides a robust benchmark evaluation framework spanning three
distinct modalities: text, image, and an integrated image & text modality. To
simulate authentic real-world contexts devoid of ground truth textual
transcriptions, we facilitates a rigorous assessment of proprietary and
open-source OCR models. The benchmark aspires to facilitate pivotal
advancements in multilingual handwritten document interpretation, fostering
innovation and scholarly inquiry within this specialized domain.

</details>


### [124] [Visual-Language Model Knowledge Distillation Method for Image Quality Assessment](https://arxiv.org/abs/2507.15680)
*Yongkang Hou,Jiarun Song*

Main category: cs.CV

TL;DR: 提出了一种基于视觉语言模型知识蒸馏的方法，用于改进图像质量评估任务，显著降低了模型复杂度并提升了性能。


<details>
  <summary>Details</summary>
Motivation: 解决CLIP在图像质量评估任务中参数过多和局部失真特征识别不足的问题。

Method: 设计质量分级提示模板，微调CLIP，并提出模态自适应知识蒸馏策略。

Result: 在多个IQA数据集上表现优于现有方法，同时显著降低模型复杂度。

Conclusion: 该方法在图像质量评估任务中具有实际部署的潜力。

Abstract: Image Quality Assessment (IQA) is a core task in computer vision. Multimodal
methods based on vision-language models, such as CLIP, have demonstrated
exceptional generalization capabilities in IQA tasks. To address the issues of
excessive parameter burden and insufficient ability to identify local distorted
features in CLIP for IQA, this study proposes a visual-language model knowledge
distillation method aimed at guiding the training of models with architectural
advantages using CLIP's IQA knowledge. First, quality-graded prompt templates
were designed to guide CLIP to output quality scores. Then, CLIP is fine-tuned
to enhance its capabilities in IQA tasks. Finally, a modality-adaptive
knowledge distillation strategy is proposed to achieve guidance from the CLIP
teacher model to the student model. Our experiments were conducted on multiple
IQA datasets, and the results show that the proposed method significantly
reduces model complexity while outperforming existing IQA methods,
demonstrating strong potential for practical deployment.

</details>


### [125] [Hi^2-GSLoc: Dual-Hierarchical Gaussian-Specific Visual Relocalization for Remote Sensing](https://arxiv.org/abs/2507.15683)
*Boni Hu,Zhenyu Xia,Lin Chen,Pengcheng Han,Shuhui Bu*

Main category: cs.CV

TL;DR: 论文提出了一种基于3D高斯点云的视觉重定位方法Hi²-GSLoc，通过双层次框架解决了现有方法在精度和计算复杂度上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有视觉重定位方法在精度和计算效率之间存在权衡，特别是在大尺度遥感场景中表现不佳。

Method: 采用3D高斯点云表示场景，提出双层次框架（稀疏到密集、粗到精），结合GPU加速和动态内存管理。

Result: 在仿真数据、公开数据集和实际飞行实验中表现出高定位精度、召回率和计算效率。

Conclusion: Hi²-GSLoc方法在遥感应用中具有实际有效性。

Abstract: Visual relocalization, which estimates the 6-degree-of-freedom (6-DoF) camera
pose from query images, is fundamental to remote sensing and UAV applications.
Existing methods face inherent trade-offs: image-based retrieval and pose
regression approaches lack precision, while structure-based methods that
register queries to Structure-from-Motion (SfM) models suffer from
computational complexity and limited scalability. These challenges are
particularly pronounced in remote sensing scenarios due to large-scale scenes,
high altitude variations, and domain gaps of existing visual priors. To
overcome these limitations, we leverage 3D Gaussian Splatting (3DGS) as a novel
scene representation that compactly encodes both 3D geometry and appearance. We
introduce $\mathrm{Hi}^2$-GSLoc, a dual-hierarchical relocalization framework
that follows a sparse-to-dense and coarse-to-fine paradigm, fully exploiting
the rich semantic information and geometric constraints inherent in Gaussian
primitives. To handle large-scale remote sensing scenarios, we incorporate
partitioned Gaussian training, GPU-accelerated parallel matching, and dynamic
memory management strategies. Our approach consists of two stages: (1) a sparse
stage featuring a Gaussian-specific consistent render-aware sampling strategy
and landmark-guided detector for robust and accurate initial pose estimation,
and (2) a dense stage that iteratively refines poses through coarse-to-fine
dense rasterization matching while incorporating reliability verification.
Through comprehensive evaluation on simulation data, public datasets, and real
flight experiments, we demonstrate that our method delivers competitive
localization accuracy, recall rate, and computational efficiency while
effectively filtering unreliable pose estimates. The results confirm the
effectiveness of our approach for practical remote sensing applications.

</details>


### [126] [LINR-PCGC: Lossless Implicit Neural Representations for Point Cloud Geometry Compression](https://arxiv.org/abs/2507.15686)
*Wenjie Huang,Qi Yang,Shuting Xia,He Huang,Zhu Li,Yiling Xu*

Main category: cs.CV

TL;DR: 本文提出了一种基于隐式神经表示（INR）的无损点云几何压缩方法LINR-PCGC，解决了现有方法对训练数据分布的依赖问题，并显著提升了编码速度和压缩效率。


<details>
  <summary>Details</summary>
Motivation: 现有基于AI的点云压缩方法受限于特定训练数据分布，而INR方法虽能解决这一问题，但仅支持有损压缩且编码时间和解码器大小受限。

Method: 设计了点云级编码框架和高效网络初始化策略以减少编码时间；提出基于多尺度SparseConv的轻量级编码网络，实现快速推理和小型解码器。

Result: 实验显示，LINR-PCGC在MVUB数据集上比G-PCC TMC13v23和SparsePCGC分别减少了21.21%和21.95%的比特流。

Conclusion: LINR-PCGC是首个基于INR的无损点云几何压缩方法，显著提升了压缩效率和实用性。

Abstract: Existing AI-based point cloud compression methods struggle with dependence on
specific training data distributions, which limits their real-world deployment.
Implicit Neural Representation (INR) methods solve the above problem by
encoding overfitted network parameters to the bitstream, resulting in more
distribution-agnostic results. However, due to the limitation of encoding time
and decoder size, current INR based methods only consider lossy geometry
compression. In this paper, we propose the first INR based lossless point cloud
geometry compression method called Lossless Implicit Neural Representations for
Point Cloud Geometry Compression (LINR-PCGC). To accelerate encoding speed, we
design a group of point clouds level coding framework with an effective network
initialization strategy, which can reduce around 60% encoding time. A
lightweight coding network based on multiscale SparseConv, consisting of scale
context extraction, child node prediction, and model compression modules, is
proposed to realize fast inference and compact decoder size. Experimental
results show that our method consistently outperforms traditional and AI-based
methods: for example, with the convergence time in the MVUB dataset, our method
reduces the bitstream by approximately 21.21% compared to G-PCC TMC13v23 and
21.95% compared to SparsePCGC. Our project can be seen on
https://huangwenjie2023.github.io/LINR-PCGC/.

</details>


### [127] [DWTGS: Rethinking Frequency Regularization for Sparse-view 3D Gaussian Splatting](https://arxiv.org/abs/2507.15690)
*Hung Nguyen,Runfa Li,An Le,Truong Nguyen*

Main category: cs.CV

TL;DR: DWTGS提出了一种基于小波变换的频率正则化方法，通过监督低频子带并自监督高频子带，改善了稀疏视图3D高斯泼溅的重建质量。


<details>
  <summary>Details</summary>
Motivation: 稀疏视图3D高斯泼溅（3DGS）在重建高质量新视图时容易过拟合训练视图的高频细节，现有基于傅里叶变换的频率正则化方法参数调优困难且偏向有害的高频学习。

Method: DWTGS利用小波空间损失提供额外的空间监督，仅监督低频LL子带，同时以自监督方式对高频HH子带施加稀疏性。

Result: 实验表明，DWTGS在多个基准测试中优于基于傅里叶的方法，低频中心策略提高了泛化能力并减少了高频幻觉。

Conclusion: DWTGS通过小波空间损失改进了稀疏视图3DGS的重建质量，是一种更有效的频率正则化方法。

Abstract: Sparse-view 3D Gaussian Splatting (3DGS) presents significant challenges in
reconstructing high-quality novel views, as it often overfits to the
widely-varying high-frequency (HF) details of the sparse training views. While
frequency regularization can be a promising approach, its typical reliance on
Fourier transforms causes difficult parameter tuning and biases towards
detrimental HF learning. We propose DWTGS, a framework that rethinks frequency
regularization by leveraging wavelet-space losses that provide additional
spatial supervision. Specifically, we supervise only the low-frequency (LF) LL
subbands at multiple DWT levels, while enforcing sparsity on the HF HH subband
in a self-supervised manner. Experiments across benchmarks show that DWTGS
consistently outperforms Fourier-based counterparts, as this LF-centric
strategy improves generalization and reduces HF hallucinations.

</details>


### [128] [Efficient Face Image Quality Assessment via Self-training and Knowledge Distillation](https://arxiv.org/abs/2507.15709)
*Wei Sun,Weixia Zhang,Linhan Cao,Jun Jia,Xiangyang Zhu,Dandan Zhu,Xiongkuo Min,Guangtao Zhai*

Main category: cs.CV

TL;DR: 提出了一种高效的人脸图像质量评估方法，通过教师-学生模型和自训练策略，实现了高性能与低计算开销的平衡。


<details>
  <summary>Details</summary>
Motivation: 解决现有FIQA方法计算复杂度高的问题，以适应实际应用中的可扩展性和部署需求。

Method: 采用两阶段方法：训练强大的教师模型并通过自训练增强其能力，然后蒸馏出轻量级学生模型。

Result: 学生模型性能接近教师模型，计算开销极低，并在ICCV 2025 VQualA FIQA挑战赛中取得第一名。

Conclusion: 该方法在保持高性能的同时显著降低了计算复杂度，适合实际部署。

Abstract: Face image quality assessment (FIQA) is essential for various face-related
applications. Although FIQA has been extensively studied and achieved
significant progress, the computational complexity of FIQA algorithms remains a
key concern for ensuring scalability and practical deployment in real-world
systems. In this paper, we aim to develop a computationally efficient FIQA
method that can be easily deployed in real-world applications. Specifically,
our method consists of two stages: training a powerful teacher model and
distilling a lightweight student model from it. To build a strong teacher
model, we adopt a self-training strategy to improve its capacity. We first
train the teacher model using labeled face images, then use it to generate
pseudo-labels for a set of unlabeled images. These pseudo-labeled samples are
used in two ways: (1) to distill knowledge into the student model, and (2) to
combine with the original labeled images to further enhance the teacher model
through self-training. The enhanced teacher model is used to further
pseudo-label another set of unlabeled images for distilling the student models.
The student model is trained using a combination of labeled images,
pseudo-labeled images from the original teacher model, and pseudo-labeled
images from the enhanced teacher model. Experimental results demonstrate that
our student model achieves comparable performance to the teacher model with an
extremely low computational overhead. Moreover, our method achieved first place
in the ICCV 2025 VQualA FIQA Challenge. The code is available at
https://github.com/sunwei925/Efficient-FIQA.git.

</details>


### [129] [A Practical Investigation of Spatially-Controlled Image Generation with Transformers](https://arxiv.org/abs/2507.15724)
*Guoxuan Xia,Harleen Hanspal,Petru-Daniel Tudosiu,Shifeng Zhang,Sarah Parisot*

Main category: cs.CV

TL;DR: 论文探讨了图像生成模型的空间控制问题，通过实验比较了不同生成范式，提出了改进方法并澄清了文献中的知识空白。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决图像生成模型在空间控制方面的不足，并填补文献中关于不同生成范式比较的知识空白。

Method: 在ImageNet上进行了扩散模型、流模型和自回归模型的对比实验，提出了控制标记预填充方法，并探索了采样时间增强技术。

Result: 控制标记预填充是一种简单且高效的基线方法；分类器自由引导和softmax截断显著提高了控制与生成的一致性；适配器方法在有限数据下保持生成质量，但一致性较差。

Conclusion: 论文为基于Transformer的空间控制生成系统提供了清晰的实践指导，并填补了文献中的知识空白。

Abstract: Enabling image generation models to be spatially controlled is an important
area of research, empowering users to better generate images according to their
own fine-grained specifications via e.g. edge maps, poses. Although this task
has seen impressive improvements in recent times, a focus on rapidly producing
stronger models has come at the cost of detailed and fair scientific
comparison. Differing training data, model architectures and generation
paradigms make it difficult to disentangle the factors contributing to
performance. Meanwhile, the motivations and nuances of certain approaches
become lost in the literature. In this work, we aim to provide clear takeaways
across generation paradigms for practitioners wishing to develop
transformer-based systems for spatially-controlled generation, clarifying the
literature and addressing knowledge gaps. We perform controlled experiments on
ImageNet across diffusion-based/flow-based and autoregressive (AR) models.
First, we establish control token prefilling as a simple, general and
performant baseline approach for transformers. We then investigate previously
underexplored sampling time enhancements, showing that extending
classifier-free guidance to control, as well as softmax truncation, have a
strong impact on control-generation consistency. Finally, we re-clarify the
motivation of adapter-based approaches, demonstrating that they mitigate
"forgetting" and maintain generation quality when trained on limited downstream
data, but underperform full training in terms of generation-control
consistency. Code will be released upon publication.

</details>


### [130] [TokensGen: Harnessing Condensed Tokens for Long Video Generation](https://arxiv.org/abs/2507.15728)
*Wenqi Ouyang,Zeqi Xiao,Danni Yang,Yifan Zhou,Shuai Yang,Lei Yang,Jianlou Si,Xingang Pan*

Main category: cs.CV

TL;DR: TokensGen提出了一种两阶段框架，通过压缩令牌解决长视频生成中的内存瓶颈和长期一致性问题。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在生成短视频时表现优异，但在生成长视频时面临内存和长期一致性问题。

Method: 方法分为两阶段：1) 训练To2V模型生成短视频；2) 使用T2To模型生成全局一致的令牌。推理时采用FIFO-Diffusion策略平滑过渡。

Result: 实验表明，该方法显著提升了长视频的时序和内容一致性，且计算开销可控。

Conclusion: TokensGen为长视频生成提供了可扩展的模块化解决方案，适用于影视制作和沉浸式模拟。

Abstract: Generating consistent long videos is a complex challenge: while
diffusion-based generative models generate visually impressive short clips,
extending them to longer durations often leads to memory bottlenecks and
long-term inconsistency. In this paper, we propose TokensGen, a novel two-stage
framework that leverages condensed tokens to address these issues. Our method
decomposes long video generation into three core tasks: (1) inner-clip semantic
control, (2) long-term consistency control, and (3) inter-clip smooth
transition. First, we train To2V (Token-to-Video), a short video diffusion
model guided by text and video tokens, with a Video Tokenizer that condenses
short clips into semantically rich tokens. Second, we introduce T2To
(Text-to-Token), a video token diffusion transformer that generates all tokens
at once, ensuring global consistency across clips. Finally, during inference,
an adaptive FIFO-Diffusion strategy seamlessly connects adjacent clips,
reducing boundary artifacts and enhancing smooth transitions. Experimental
results demonstrate that our approach significantly enhances long-term temporal
and content coherence without incurring prohibitive computational overhead. By
leveraging condensed tokens and pre-trained short video models, our method
provides a scalable, modular solution for long video generation, opening new
possibilities for storytelling, cinematic production, and immersive
simulations. Please see our project page at
https://vicky0522.github.io/tokensgen-webpage/ .

</details>


### [131] [Appearance Harmonization via Bilateral Grid Prediction with Transformers for 3DGS](https://arxiv.org/abs/2507.15748)
*Jisu Shin,Richard Shaw,Seunghyun Shin,Anton Pelykh,Zhensong Zhang,Hae-Gon Jeon,Eduardo Perez-Pellitero*

Main category: cs.CV

TL;DR: 提出一种基于Transformer的方法，通过预测空间自适应双边网格来校正多视角一致性中的光度变化，无需场景特定训练即可实现跨场景泛化。


<details>
  <summary>Details</summary>
Motivation: 现代相机处理流程导致多视角间光度不一致，影响新视角合成的质量。现有方法通过联合优化场景表示和每张图像的外观嵌入来解决，但计算复杂度高且训练慢。

Method: 使用Transformer预测空间自适应双边网格，校正光度变化，并将其融入3D高斯泼溅流程中。

Result: 实验表明，该方法在重建质量和收敛速度上优于或匹配现有场景特定优化方法。

Conclusion: 该方法在多视角一致性和训练效率上表现优异，具有跨场景泛化能力。

Abstract: Modern camera pipelines apply extensive on-device processing, such as
exposure adjustment, white balance, and color correction, which, while
beneficial individually, often introduce photometric inconsistencies across
views. These appearance variations violate multi-view consistency and degrade
the quality of novel view synthesis. Joint optimization of scene
representations and per-image appearance embeddings has been proposed to
address this issue, but at the cost of increased computational complexity and
slower training. In this work, we propose a transformer-based method that
predicts spatially adaptive bilateral grids to correct photometric variations
in a multi-view consistent manner, enabling robust cross-scene generalization
without the need for scene-specific retraining. By incorporating the learned
grids into the 3D Gaussian Splatting pipeline, we improve reconstruction
quality while maintaining high training efficiency. Extensive experiments show
that our approach outperforms or matches existing scene-specific optimization
methods in reconstruction fidelity and convergence speed.

</details>


### [132] [Learning from Heterogeneity: Generalizing Dynamic Facial Expression Recognition via Distributionally Robust Optimization](https://arxiv.org/abs/2507.15765)
*Feng-Qi Cui,Anyang Tong,Jinyang Huang,Jie Zhang,Dan Guo,Zhi Liu,Meng Wang*

Main category: cs.CV

TL;DR: 论文提出了一种名为HDF的新框架，通过两个模块增强动态面部表情识别的性能，解决了多源数据和个体表达差异带来的样本异质性问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多源数据和个体表达差异导致的样本异质性下性能下降，需要一种新方法提升鲁棒性和准确性。

Method: HDF框架包含两个模块：Time-Frequency Distributional Attention Module（DAM）用于时间-频率建模，Distribution-aware Scaling Module（DSM）用于动态平衡分类和对比损失。

Result: 在DFEW和FERV39k数据集上，HDF显著提高了识别准确性和鲁棒性，取得了更高的WAR和UAR。

Conclusion: HDF框架有效解决了样本异质性问题，提升了动态面部表情识别的性能，具有广泛适用性。

Abstract: Dynamic Facial Expression Recognition (DFER) plays a critical role in
affective computing and human-computer interaction. Although existing methods
achieve comparable performance, they inevitably suffer from performance
degradation under sample heterogeneity caused by multi-source data and
individual expression variability. To address these challenges, we propose a
novel framework, called Heterogeneity-aware Distributional Framework (HDF), and
design two plug-and-play modules to enhance time-frequency modeling and
mitigate optimization imbalance caused by hard samples. Specifically, the
Time-Frequency Distributional Attention Module (DAM) captures both temporal
consistency and frequency robustness through a dual-branch attention design,
improving tolerance to sequence inconsistency and visual style shifts. Then,
based on gradient sensitivity and information bottleneck principles, an
adaptive optimization module Distribution-aware Scaling Module (DSM) is
introduced to dynamically balance classification and contrastive losses,
enabling more stable and discriminative representation learning. Extensive
experiments on two widely used datasets, DFEW and FERV39k, demonstrate that HDF
significantly improves both recognition accuracy and robustness. Our method
achieves superior weighted average recall (WAR) and unweighted average recall
(UAR) while maintaining strong generalization across diverse and imbalanced
scenarios. Codes are released at https://github.com/QIcita/HDF_DFER.

</details>


### [133] [Label tree semantic losses for rich multi-class medical image segmentation](https://arxiv.org/abs/2507.15777)
*Junwen Wang,Oscar MacCormac,William Rochford,Aaron Kujawa,Jonathan Shapey,Tom Vercauteren*

Main category: cs.CV

TL;DR: 提出两种基于树结构的语义损失函数，利用标签层次结构改进医学图像分割性能，在完全监督和稀疏标注任务中均达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有医学图像分割方法对所有错误同等惩罚，未能利用标签间的语义层次关系，尤其在标签类别增多且差异细微时表现不佳。

Method: 提出两种树基语义损失函数，结合稀疏标注训练方法，扩展其适用性。

Result: 在头部MRI全脑分区和神经外科高光谱成像任务中，性能达到SOTA。

Conclusion: 树基语义损失函数能有效利用标签层次结构，显著提升医学图像分割效果。

Abstract: Rich and accurate medical image segmentation is poised to underpin the next
generation of AI-defined clinical practice by delineating critical anatomy for
pre-operative planning, guiding real-time intra-operative navigation, and
supporting precise post-operative assessment. However, commonly used learning
methods for medical and surgical imaging segmentation tasks penalise all errors
equivalently and thus fail to exploit any inter-class semantics in the labels
space. This becomes particularly problematic as the cardinality and richness of
labels increases to include subtly different classes. In this work, we propose
two tree-based semantic loss functions which take advantage of a hierarchical
organisation of the labels. We further incorporate our losses in a recently
proposed approach for training with sparse, background-free annotations to
extend the applicability of our proposed losses. Extensive experiments are
reported on two medical and surgical image segmentation tasks, namely head MRI
for whole brain parcellation (WBP) with full supervision and neurosurgical
hyperspectral imaging (HSI) for scene understanding with sparse annotations.
Results demonstrate that our proposed method reaches state-of-the-art
performance in both cases.

</details>


### [134] [Regularized Low-Rank Adaptation for Few-Shot Organ Segmentation](https://arxiv.org/abs/2507.15793)
*Ghassen Baklouti,Julio Silva-Rodríguez,Jose Dolz,Houda Bahig,Ismail Ben Ayed*

Main category: cs.CV

TL;DR: 论文提出了一种动态调整低秩适应（LoRA）的方法，用于医学图像分割，通过引入稀疏正则化自动确定任务适应的秩。


<details>
  <summary>Details</summary>
Motivation: 传统LoRA方法需要固定秩，难以适应不同医学图像任务的复杂性，因此需要一种动态调整秩的方法。

Method: 通过奇异值分解和l_1稀疏正则化动态调整低秩表示的秩，并使用近端优化器优化。

Result: 实验表明，该方法在少样本微调任务中显著优于标准LoRA和其他PEFT方法。

Conclusion: 该方法能自动适应任务需求，提高性能和鲁棒性，代码已开源。

Abstract: Parameter-efficient fine-tuning (PEFT) of pre-trained foundation models is
increasingly attracting interest in medical imaging due to its effectiveness
and computational efficiency. Among these methods, Low-Rank Adaptation (LoRA)
is a notable approach based on the assumption that the adaptation inherently
occurs in a low-dimensional subspace. While it has shown good performance, its
implementation requires a fixed and unalterable rank, which might be
challenging to select given the unique complexities and requirements of each
medical imaging downstream task. Inspired by advancements in natural image
processing, we introduce a novel approach for medical image segmentation that
dynamically adjusts the intrinsic rank during adaptation. Viewing the low-rank
representation of the trainable weight matrices as a singular value
decomposition, we introduce an l_1 sparsity regularizer to the loss function,
and tackle it with a proximal optimizer. The regularizer could be viewed as a
penalty on the decomposition rank. Hence, its minimization enables to find
task-adapted ranks automatically. Our method is evaluated in a realistic
few-shot fine-tuning setting, where we compare it first to the standard LoRA
and then to several other PEFT methods across two distinguishable tasks: base
organs and novel organs. Our extensive experiments demonstrate the significant
performance improvements driven by our method, highlighting its efficiency and
robustness against suboptimal rank initialization. Our code is publicly
available: https://github.com/ghassenbaklouti/ARENA

</details>


### [135] [Exploring Superposition and Interference in State-of-the-Art Low-Parameter Vision Models](https://arxiv.org/abs/2507.15798)
*Lilian Hollard,Lucas Mohimont,Nathalie Gaveau,Luiz-Angelo Steffenel*

Main category: cs.CV

TL;DR: 论文研究了低参数深度神经网络在计算机视觉中的性能，重点分析了瓶颈架构及其在使用超线性激活函数时的行为。通过减少特征图中的干扰，可以提升小规模网络（参数少于150万）的扩展性和准确性。


<details>
  <summary>Details</summary>
Motivation: 研究低参数深度神经网络在计算机视觉中的性能，特别是瓶颈架构的行为，以解决特征图中的干扰问题，提升小规模网络的效率和准确性。

Method: 通过分析多种瓶颈架构，识别减少干扰的关键设计元素，并提出一个名为NoDepth Bottleneck的概念验证架构。

Result: 提出的NoDepth Bottleneck架构在ImageNet数据集上表现出稳健的扩展性和准确性。

Conclusion: 研究为低参数范围的神经网络提供了更高效和可扩展的设计方案，并深化了对计算机视觉中瓶颈架构的理解。

Abstract: The paper investigates the performance of state-of-the-art low-parameter deep
neural networks for computer vision, focusing on bottleneck architectures and
their behavior using superlinear activation functions. We address interference
in feature maps, a phenomenon associated with superposition, where neurons
simultaneously encode multiple characteristics. Our research suggests that
limiting interference can enhance scaling and accuracy in very low-scaled
networks (under 1.5M parameters). We identify key design elements that reduce
interference by examining various bottleneck architectures, leading to a more
efficient neural network. Consequently, we propose a proof-of-concept
architecture named NoDepth Bottleneck built on mechanistic insights from our
experiments, demonstrating robust scaling accuracy on the ImageNet dataset.
These findings contribute to more efficient and scalable neural networks for
the low-parameter range and advance the understanding of bottlenecks in
computer vision. https://caiac.pubpub.org/pub/3dh6rsel

</details>


### [136] [ConformalSAM: Unlocking the Potential of Foundational Segmentation Models in Semi-Supervised Semantic Segmentation with Conformal Prediction](https://arxiv.org/abs/2507.15803)
*Danhui Chen,Ziquan Liu,Chuxi Yang,Dan Wang,Yan Yan,Yi Xu,Xiangyang Ji*

Main category: cs.CV

TL;DR: ConformalSAM利用预训练的分割模型SEEM生成未标注数据的预测掩码，并通过不确定性校准和自依赖训练策略提升半监督语义分割性能。


<details>
  <summary>Details</summary>
Motivation: 解决像素级视觉任务中标注数据稀缺的问题，探索预训练分割模型作为标注器的潜力。

Method: 提出ConformalSAM框架，结合不确定性校准和自依赖训练策略，利用SEEM生成的掩码作为监督信号。

Result: 在三个标准半监督语义分割基准上，ConformalSAM表现优于现有方法，并可作为插件提升其他方法性能。

Conclusion: ConformalSAM通过有效利用预训练分割模型，显著提升了半监督语义分割的性能和可靠性。

Abstract: Pixel-level vision tasks, such as semantic segmentation, require extensive
and high-quality annotated data, which is costly to obtain. Semi-supervised
semantic segmentation (SSSS) has emerged as a solution to alleviate the
labeling burden by leveraging both labeled and unlabeled data through
self-training techniques. Meanwhile, the advent of foundational segmentation
models pre-trained on massive data, has shown the potential to generalize
across domains effectively. This work explores whether a foundational
segmentation model can address label scarcity in the pixel-level vision task as
an annotator for unlabeled images. Specifically, we investigate the efficacy of
using SEEM, a Segment Anything Model (SAM) variant fine-tuned for textual
input, to generate predictive masks for unlabeled data. To address the
shortcomings of using SEEM-generated masks as supervision, we propose
ConformalSAM, a novel SSSS framework which first calibrates the foundation
model using the target domain's labeled data and then filters out unreliable
pixel labels of unlabeled data so that only high-confidence labels are used as
supervision. By leveraging conformal prediction (CP) to adapt foundation models
to target data through uncertainty calibration, ConformalSAM exploits the
strong capability of the foundational segmentation model reliably which
benefits the early-stage learning, while a subsequent self-reliance training
strategy mitigates overfitting to SEEM-generated masks in the later training
stage. Our experiment demonstrates that, on three standard benchmarks of SSSS,
ConformalSAM achieves superior performance compared to recent SSSS methods and
helps boost the performance of those methods as a plug-in.

</details>


### [137] [True Multimodal In-Context Learning Needs Attention to the Visual Context](https://arxiv.org/abs/2507.15807)
*Shuo Chen,Jianzhe Liu,Zhen Han,Yan Xia,Daniel Cremers,Philip Torr,Volker Tresp,Jindong Gu*

Main category: cs.CV

TL;DR: 论文提出了一种动态注意力重分配（DARA）策略和TrueMICL数据集，以解决多模态大语言模型（MLLMs）在视觉信息利用上的不足，提升真正的多模态上下文学习能力。


<details>
  <summary>Details</summary>
Motivation: 当前MLLMs在多模态上下文学习中过度依赖文本模式，忽视视觉线索，导致性能受限。如何有效增强和可靠评估多模态上下文学习能力尚未充分探索。

Method: 引入动态注意力重分配（DARA）策略，调整视觉和文本令牌的注意力分配；提出TrueMICL数据集，明确要求整合多模态信息。

Result: 实验证明该方法显著提升了多模态上下文学习的真实能力。

Conclusion: DARA和TrueMICL为多模态上下文学习提供了有效的解决方案，推动了该领域的进一步发展。

Abstract: Multimodal Large Language Models (MLLMs), built on powerful language
backbones, have enabled Multimodal In-Context Learning (MICL)-adapting to new
tasks from a few multimodal demonstrations consisting of images, questions, and
answers. Despite showing noticeable improvement on standard vision-language
datasets, current MLLMs struggle to leverage visual information in the
demonstrations. Specifically, they tend to neglect visual cues and over-rely on
textual patterns, leading to mere text imitation rather than genuine multimodal
adaptation. This behavior makes MICL still unimodal and largely restricts its
practical utility. More importantly, this limitation is often concealed by the
improved performance on tasks that do not require understanding the visual
context. As a result, how to effectively enhance MICL ability and reliably
evaluate the MICL performance remains underexplored. To address these issues,
we first introduce Dynamic Attention Reallocation (DARA), an efficient
fine-tuning strategy that encourages models to attend to the visual context by
rebalancing attention across visual and textual tokens. In addition, we present
TrueMICL, an MICL-dedicated dataset with both support and test sets that
explicitly requires the integration of multimodal information-particularly
visual content-for correct task completion. Extensive experiments demonstrate
the effectiveness of our holistic solution, showcasing substantial improvements
in the true multimodal in-context learning capabilities. Code and datasets are
available at https://chenxshuo.github.io/true-micl-colm .

</details>


### [138] [Diffusion models for multivariate subsurface generation and efficient probabilistic inversion](https://arxiv.org/abs/2507.15809)
*Roberto Miele,Niklas Linde*

Main category: cs.CV

TL;DR: 扩散模型在多元地下建模和概率反演中表现出色，优于变分自编码器和生成对抗网络。通过改进扩散后验采样方法，提出噪声污染似然近似，显著提升统计稳健性和计算效率。


<details>
  <summary>Details</summary>
Motivation: 研究扩散模型在多元地下建模和概率反演中的应用，以解决现有方法（如变分自编码器和生成对抗网络）的局限性。

Method: 改进扩散后验采样方法，引入噪声污染似然近似，并利用局部硬数据和非线性地球物理数据进行条件建模。

Result: 在多元地质场景中，统计稳健性显著提升，后验概率密度函数采样更高效，计算成本降低。

Conclusion: 扩散模型结合改进方法在多元地下建模和概率反演中表现优越，适用于硬数据和间接条件数据，且计算效率高。

Abstract: Diffusion models offer stable training and state-of-the-art performance for
deep generative modeling tasks. Here, we consider their use in the context of
multivariate subsurface modeling and probabilistic inversion. We first
demonstrate that diffusion models enhance multivariate modeling capabilities
compared to variational autoencoders and generative adversarial networks. In
diffusion modeling, the generative process involves a comparatively large
number of time steps with update rules that can be modified to account for
conditioning data. We propose different corrections to the popular Diffusion
Posterior Sampling approach by Chung et al. (2023). In particular, we introduce
a likelihood approximation accounting for the noise-contamination that is
inherent in diffusion modeling. We assess performance in a multivariate
geological scenario involving facies and correlated acoustic impedance.
Conditional modeling is demonstrated using both local hard data (well logs) and
nonlinear geophysics (fullstack seismic data). Our tests show significantly
improved statistical robustness, enhanced sampling of the posterior probability
density function and reduced computational costs, compared to the original
approach. The method can be used with both hard and indirect conditioning data,
individually or simultaneously. As the inversion is included within the
diffusion process, it is faster than other methods requiring an outer-loop
around the generative model, such as Markov chain Monte Carlo.

</details>


### [139] [Can Your Model Separate Yolks with a Water Bottle? Benchmarking Physical Commonsense Understanding in Video Generation Models](https://arxiv.org/abs/2507.15824)
*Enes Sanli,Baris Sarper Tezcan,Aykut Erdem,Erkut Erdem*

Main category: cs.CV

TL;DR: PhysVidBench是一个评估文本到视频生成模型物理常识能力的基准，包含383个提示，通过三阶段评估流程间接测试模型的物理合理性。


<details>
  <summary>Details</summary>
Motivation: 现有文本到视频生成模型在物理常识方面表现不足，需要一种评估方法来衡量其物理合理性。

Method: 设计PhysVidBench基准，包含工具使用、材料属性等提示，采用三阶段评估（问题生成、视频描述、语言模型回答）。

Result: 通过间接评估策略，避免了直接视频评估中的幻觉问题，提供了结构化评估框架。

Conclusion: PhysVidBench为生成视频模型的物理常识评估提供了有效且可解释的方法。

Abstract: Recent progress in text-to-video (T2V) generation has enabled the synthesis
of visually compelling and temporally coherent videos from natural language.
However, these models often fall short in basic physical commonsense, producing
outputs that violate intuitive expectations around causality, object behavior,
and tool use. Addressing this gap, we present PhysVidBench, a benchmark
designed to evaluate the physical reasoning capabilities of T2V systems. The
benchmark includes 383 carefully curated prompts, emphasizing tool use,
material properties, and procedural interactions, and domains where physical
plausibility is crucial. For each prompt, we generate videos using diverse
state-of-the-art models and adopt a three-stage evaluation pipeline: (1)
formulate grounded physics questions from the prompt, (2) caption the generated
video with a vision-language model, and (3) task a language model to answer
several physics-involved questions using only the caption. This indirect
strategy circumvents common hallucination issues in direct video-based
evaluation. By highlighting affordances and tool-mediated actions, areas
overlooked in current T2V evaluations, PhysVidBench provides a structured,
interpretable framework for assessing physical commonsense in generative video
models.

</details>


### [140] [SeC: Advancing Complex Video Object Segmentation via Progressive Concept Construction](https://arxiv.org/abs/2507.15852)
*Zhixiong Zhang,Shuangrui Ding,Xiaoyi Dong,Songxin He,Jianfan Lin,Junsong Tang,Yuhang Zang,Yuhang Cao,Dahua Lin,Jiaqi Wang*

Main category: cs.CV

TL;DR: 论文提出了一种概念驱动的视频对象分割框架（SeC），通过结合视觉语言模型（LVLMs）构建高层次的对象表示，显著提升了在复杂场景下的分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有视频对象分割方法依赖外观匹配，难以应对剧烈视觉变化和复杂场景变化，缺乏人类对对象的概念理解能力。

Method: SeC框架利用LVLMs整合多帧视觉线索，构建对象的概念先验，并在推理时动态平衡语义推理与特征匹配。

Result: 在提出的SeCVOS基准测试中，SeC比SAM 2.1提升了11.8个百分点，达到新最优性能。

Conclusion: SeC通过概念驱动的方法显著提升了视频对象分割的鲁棒性，尤其在复杂场景下表现优异。

Abstract: Video Object Segmentation (VOS) is a core task in computer vision, requiring
models to track and segment target objects across video frames. Despite notable
advances with recent efforts, current techniques still lag behind human
capabilities in handling drastic visual variations, occlusions, and complex
scene changes. This limitation arises from their reliance on appearance
matching, neglecting the human-like conceptual understanding of objects that
enables robust identification across temporal dynamics. Motivated by this gap,
we propose Segment Concept (SeC), a concept-driven segmentation framework that
shifts from conventional feature matching to the progressive construction and
utilization of high-level, object-centric representations. SeC employs Large
Vision-Language Models (LVLMs) to integrate visual cues across diverse frames,
constructing robust conceptual priors. During inference, SeC forms a
comprehensive semantic representation of the target based on processed frames,
realizing robust segmentation of follow-up frames. Furthermore, SeC adaptively
balances LVLM-based semantic reasoning with enhanced feature matching,
dynamically adjusting computational efforts based on scene complexity. To
rigorously assess VOS methods in scenarios demanding high-level conceptual
reasoning and robust semantic understanding, we introduce the Semantic Complex
Scenarios Video Object Segmentation benchmark (SeCVOS). SeCVOS comprises 160
manually annotated multi-scenario videos designed to challenge models with
substantial appearance variations and dynamic scene transformations. In
particular, SeC achieves an 11.8-point improvement over SAM 2.1 on SeCVOS,
establishing a new state-of-the-art in concept-aware video object segmentation.

</details>


### [141] [Latent Denoising Makes Good Visual Tokenizers](https://arxiv.org/abs/2507.15856)
*Jiawei Yang,Tianhong Li,Lijie Fan,Yonglong Tian,Yue Wang*

Main category: cs.CV

TL;DR: 论文提出了一种名为l-DeTok的视觉分词器，通过直接与去噪目标对齐，提升了生成模型的效果。


<details>
  <summary>Details</summary>
Motivation: 现代生成模型共享一个类似的训练目标——从噪声输入中重建干净信号（去噪），因此希望分词器的潜在嵌入更易于重建。

Method: 提出了Latent Denoising Tokenizer (l-DeTok)，通过插值噪声和随机掩码训练分词器重建干净图像。

Result: 在ImageNet 256x256上，l-DeTok在六种代表性生成模型中均优于标准分词器。

Conclusion: 去噪是分词器设计的基本原则，未来分词器设计可基于此视角展开。

Abstract: Despite their fundamental role, it remains unclear what properties could make
visual tokenizers more effective for generative modeling. We observe that
modern generative models share a conceptually similar training objective --
reconstructing clean signals from corrupted inputs such as Gaussian noise or
masking -- a process we term denoising. Motivated by this insight, we propose
aligning tokenizer embeddings directly with the downstream denoising objective,
encouraging latent embeddings to be more easily reconstructed even when heavily
corrupted. To achieve this, we introduce the Latent Denoising Tokenizer
(l-DeTok), a simple yet effective tokenizer trained to reconstruct clean images
from latent embeddings corrupted by interpolative noise and random masking.
Extensive experiments on ImageNet 256x256 demonstrate that our tokenizer
consistently outperforms standard tokenizers across six representative
generative models. Our findings highlight denoising as a fundamental design
principle for tokenizer development, and we hope it could motivate new
perspectives for future tokenizer design.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [142] [DeepWriter: A Fact-Grounded Multimodal Writing Assistant Based On Offline Knowledge Base](https://arxiv.org/abs/2507.14189)
*Song Mao,Lejun Cheng,Pinlong Cai,Guohang Yan,Ding Wang,Botian Shi*

Main category: cs.CL

TL;DR: DeepWriter是一个基于离线知识库的多模态写作助手，通过任务分解、大纲生成和多模态检索等技术，生成高质量、事实准确的文档，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在专业领域（如金融、医学、法律）中缺乏深度知识和易产生幻觉的问题，以及现有检索增强方法的不一致性和在线搜索的不可靠性。

Method: 提出DeepWriter，采用任务分解、大纲生成、多模态检索和分段写作的流程，结合结构化知识库和分层知识表示。

Result: 在金融报告生成实验中，DeepWriter生成的内容在事实准确性和质量上优于现有基线。

Conclusion: DeepWriter通过离线知识库和多模态技术，显著提升了专业领域文档生成的准确性和质量。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in
various applications. However, their use as writing assistants in specialized
domains like finance, medicine, and law is often hampered by a lack of deep
domain-specific knowledge and a tendency to hallucinate. Existing solutions,
such as Retrieval-Augmented Generation (RAG), can suffer from inconsistency
across multiple retrieval steps, while online search-based methods often
degrade quality due to unreliable web content. To address these challenges, we
introduce DeepWriter, a customizable, multimodal, long-form writing assistant
that operates on a curated, offline knowledge base. DeepWriter leverages a
novel pipeline that involves task decomposition, outline generation, multimodal
retrieval, and section-by-section composition with reflection. By deeply mining
information from a structured corpus and incorporating both textual and visual
elements, DeepWriter generates coherent, factually grounded, and
professional-grade documents. We also propose a hierarchical knowledge
representation to enhance retrieval efficiency and accuracy. Our experiments on
financial report generation demonstrate that DeepWriter produces high-quality,
verifiable articles that surpasses existing baselines in factual accuracy and
generated content quality.

</details>


### [143] [Retention analysis of edited knowledge after fine-tuning](https://arxiv.org/abs/2507.14198)
*Fufang Wen,Shichang Zhang*

Main category: cs.CL

TL;DR: 研究发现，微调任务会显著影响大语言模型（LLMs）中通过编辑方法更新的知识，导致其比预训练知识更容易被遗忘。冻结与编辑内容相关的层可以改善知识保留。


<details>
  <summary>Details</summary>
Motivation: 探讨微调任务对模型编辑知识的影响，以解决当前编辑方法在实践中的局限性。

Method: 系统研究不同微调目标与多种模型编辑技术的交互作用。

Result: 编辑的知识在微调过程中比预训练知识更易遗忘；冻结相关层可显著提升知识保留。

Conclusion: 当前编辑方法在微调下的鲁棒性需进一步评估，未来方法可通过冻结层提升知识保留能力。

Abstract: Large language models (LLMs) store vast amounts of knowledge, which often
requires updates to correct factual errors, incorporate newly acquired
information, or adapt model behavior. Model editing methods have emerged as
efficient solutions for such updates, offering localized and precise knowledge
modification at significantly lower computational cost than continual training.
In parallel, LLMs are frequently fine-tuned for a wide range of downstream
tasks. However, the effect of fine-tuning on previously edited knowledge
remains poorly understood. In this work, we systematically investigate how
different fine-tuning objectives interact with various model editing
techniques. Our findings show that edited knowledge is substantially more
susceptible to forgetting during fine-tuning than intrinsic knowledge acquired
through pre-training. This analysis highlights a key limitation of current
editing approaches and suggests that evaluating edit robustness under
downstream fine-tuning is critical for their practical deployment. We further
find that freezing layers associated with edited content can significantly
improve knowledge retention, offering insight into how future editing methods
might be made more robust.

</details>


### [144] [Open-Source LLMs Collaboration Beats Closed-Source LLMs: A Scalable Multi-Agent System](https://arxiv.org/abs/2507.14200)
*Shengji Tang,Jianjian Cao,Weihao Lin,Jiale Hong,Bo Zhang,Shuyue Hu,Lei Bai,Tao Chen,Wanli Ouyang,Peng Ye*

Main category: cs.CL

TL;DR: SMACS框架通过多智能体协作整合开源LLMs，性能超越闭源LLMs。


<details>
  <summary>Details</summary>
Motivation: 探索开源LLMs集体协作是否能超越闭源LLMs。

Method: 提出SMACS框架，包括检索式先验选择（RPS）和探索-利用驱动的后验增强（EPE）。

Result: 在8个主流基准测试中，SMACS超越闭源LLMs（如Claude-3.7-Sonnet、GPT-4.1等），并推动智能上限。

Conclusion: SMACS证明了开源LLMs协作的潜力，性能优于闭源LLMs。

Abstract: This paper aims to demonstrate the potential and strengths of open-source
collectives. It leads to a promising question: Can we harness multiple
open-source LLMs to match or even beat the closed-source LLMs? To answer this,
we propose SMACS, a scalable multi-agent collaboration system (MACS) framework
with high performance. Specifically, for continuous integration of new LLMs and
generalization to diverse questions, we first propose a Retrieval-based Prior
Selection (RPS), which assigns a proxy performance score to each LLM to select
the Top-k LLMs at the instance level for any given question. Then, we propose
an Exploration-Exploitation-Driven Posterior Enhancement (EPE), encouraging the
generation of diverse responses through prior dropping and selecting the
high-quality response via a hybrid posterior score. Experiments on eight
mainstream benchmarks validate the effectiveness of our SMACS: by integrating
fifteen open-source LLMs, SMACS outperforms leading closed-source LLMs in 2025,
e.g., Claude-3.7-Sonnet (+12.73%), GPT-4.1(+5.36%) and GPT-o3-mini(+5.28%)
across multiple tasks. Remarkably, it even exceeds the average of best results
of different datasets from both open-source LLMs (+2.86%) and closed-source
LLMs (+2.04%), pushing the upper bound of intelligence. Code will be released
at https://github.com/magent4aci/SMACS.

</details>


### [145] [Let's Measure the Elephant in the Room: Facilitating Personalized Automated Analysis of Privacy Policies at Scale](https://arxiv.org/abs/2507.14214)
*Rui Zhao,Vladyslav Melnychuk,Jun Zhao,Jesse Wright,Nigel Shadbolt*

Main category: cs.CL

TL;DR: PoliAnalyzer是一个神经符号系统，通过NLP和逻辑推理帮助用户分析隐私政策，减少认知负担，并揭示政策与用户偏见的冲突。


<details>
  <summary>Details</summary>
Motivation: 现代人很少阅读隐私政策，但希望保护个人数据。PoliAnalyzer旨在帮助用户自动化分析隐私政策，减轻认知负担。

Method: 结合NLP提取政策文本的正式表示，并通过逻辑推理比较用户偏好与政策内容，生成合规报告。扩展了现有的数据使用政策语言。

Result: 在评估中，PoliAnalyzer的F1-score达90-100%，能识别95.2%无冲突的政策段落，仅4.8%违反用户偏好。

Conclusion: PoliAnalyzer支持大规模自动化隐私政策分析，帮助用户重新掌控数据，促进社会对平台数据实践的讨论。

Abstract: In modern times, people have numerous online accounts, but they rarely read
the Terms of Service or Privacy Policy of those sites despite claiming
otherwise. This paper introduces PoliAnalyzer, a neuro-symbolic system that
assists users with personalized privacy policy analysis. PoliAnalyzer uses
Natural Language Processing (NLP) to extract formal representations of data
usage practices from policy texts. In favor of deterministic, logical inference
is applied to compare user preferences with the formal privacy policy
representation and produce a compliance report. To achieve this, we extend an
existing formal Data Terms of Use policy language to model privacy policies as
app policies and user preferences as data policies. In our evaluation using our
enriched PolicyIE dataset curated by legal experts, PoliAnalyzer demonstrated
high accuracy in identifying relevant data usage practices, achieving F1-score
of 90-100% across most tasks. Additionally, we demonstrate how PoliAnalyzer can
model diverse user data-sharing preferences, derived from prior research as 23
user profiles, and perform compliance analysis against the top 100 most-visited
websites. This analysis revealed that, on average, 95.2% of a privacy policy's
segments do not conflict with the analyzed user preferences, enabling users to
concentrate on understanding the 4.8% (636 / 13205) that violates preferences,
significantly reducing cognitive burden. Further, we identified common
practices in privacy policies that violate user expectations - such as the
sharing of location data with 3rd parties. This paper demonstrates that
PoliAnalyzer can support automated personalized privacy policy analysis at
scale using off-the-shelf NLP tools. This sheds light on a pathway to help
individuals regain control over their data and encourage societal discussions
on platform data practices to promote a fairer power dynamic.

</details>


### [146] [Beyond Architectures: Evaluating the Role of Contextual Embeddings in Detecting Bipolar Disorder on Social Media](https://arxiv.org/abs/2507.14231)
*Khalid Hasan,Jamil Saquer*

Main category: cs.CL

TL;DR: 论文探讨了利用NLP模型识别社交媒体文本中的双相情感障碍迹象，发现RoBERTa和基于BERT嵌入的LSTM表现最佳，而静态嵌入的LSTM效果不佳。


<details>
  <summary>Details</summary>
Motivation: 双相情感障碍常因早期症状不明显和社会污名被漏诊，研究旨在通过NLP技术提高早期筛查能力。

Method: 评估了多种基于Transformer和LSTM的模型（如BERT、RoBERTa、LSTM等），使用Reddit帖子数据集进行实验。

Result: RoBERTa表现最佳（F1分数~98%），基于BERT嵌入的LSTM效果相近，而静态嵌入的LSTM几乎无效。DistilBERT在效率和准确性间取得平衡。

Conclusion: 上下文语言模型在双相情感障碍检测中至关重要，研究为心理健康NLP应用提供了模型选择依据。

Abstract: Bipolar disorder is a chronic mental illness frequently underdiagnosed due to
subtle early symptoms and social stigma. This paper explores the advanced
natural language processing (NLP) models for recognizing signs of bipolar
disorder based on user-generated social media text. We conduct a comprehensive
evaluation of transformer-based models (BERT, RoBERTa, ALBERT, ELECTRA,
DistilBERT) and Long Short Term Memory (LSTM) models based on contextualized
(BERT) and static (GloVe, Word2Vec) word embeddings. Experiments were performed
on a large, annotated dataset of Reddit posts after confirming their validity
through sentiment variance and judgmental analysis. Our results demonstrate
that RoBERTa achieves the highest performance among transformer models with an
F1 score of ~98% while LSTM models using BERT embeddings yield nearly identical
results. In contrast, LSTMs trained on static embeddings fail to capture
meaningful patterns, scoring near-zero F1. These findings underscore the
critical role of contextual language modeling in detecting bipolar disorder. In
addition, we report model training times and highlight that DistilBERT offers
an optimal balance between efficiency and accuracy. In general, our study
offers actionable insights for model selection in mental health NLP
applications and validates the potential of contextualized language models to
support early bipolar disorder screening.

</details>


### [147] [Language Models Change Facts Based on the Way You Talk](https://arxiv.org/abs/2507.14238)
*Matthew Kearney,Reuben Binns,Yarin Gal*

Main category: cs.CL

TL;DR: 研究发现大型语言模型（LLMs）在用户输入中能识别身份标记，并在医疗、法律、政治等领域中产生偏见性回应，可能导致有害后果。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs如何利用用户文本中的身份信息进行决策，及其在高风险应用中的潜在偏见影响。

Method: 对五个高风险领域的LLM应用进行综合分析，测试其对种族、性别、年龄等身份标记的敏感性。

Result: LLMs对身份标记极为敏感，导致医疗建议、薪资推荐和政治观点等方面存在系统性偏见。

Conclusion: 建议在部署LLMs前进行更全面的评估，以避免偏见带来的有害影响。

Abstract: Large language models (LLMs) are increasingly being used in user-facing
applications, from providing medical consultations to job interview advice.
Recent research suggests that these models are becoming increasingly proficient
at inferring identity information about the author of a piece of text from
linguistic patterns as subtle as the choice of a few words. However, little is
known about how LLMs use this information in their decision-making in
real-world applications. We perform the first comprehensive analysis of how
identity markers present in a user's writing bias LLM responses across five
different high-stakes LLM applications in the domains of medicine, law,
politics, government benefits, and job salaries. We find that LLMs are
extremely sensitive to markers of identity in user queries and that race,
gender, and age consistently influence LLM responses in these applications. For
instance, when providing medical advice, we find that models apply different
standards of care to individuals of different ethnicities for the same
symptoms; we find that LLMs are more likely to alter answers to align with a
conservative (liberal) political worldview when asked factual questions by
older (younger) individuals; and that LLMs recommend lower salaries for
non-White job applicants and higher salaries for women compared to men. Taken
together, these biases mean that the use of off-the-shelf LLMs for these
applications may cause harmful differences in medical care, foster wage gaps,
and create different political factual realities for people of different
identities. Beyond providing an analysis, we also provide new tools for
evaluating how subtle encoding of identity in users' language choices impacts
model decisions. Given the serious implications of these findings, we recommend
that similar thorough assessments of LLM use in user-facing applications are
conducted before future deployment.

</details>


### [148] [CCL-XCoT: An Efficient Cross-Lingual Knowledge Transfer Method for Mitigating Hallucination Generation](https://arxiv.org/abs/2507.14239)
*Weihua Zheng,Roy Ka-Wei Lee,Zhengyuan Liu,Kui Wu,AiTi Aw,Bowei Zou*

Main category: cs.CL

TL;DR: 论文提出CCL-XCoT框架，通过两阶段微调减少多语言大模型在低资源语言中的幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 多语言大模型在低资源语言中易产生幻觉，影响生成任务的准确性。

Method: 采用基于课程学习的对比学习和跨语言思维链提示策略。

Result: 实验显示CCL-XCoT将幻觉率降低62%，并提升跨语言知识迁移。

Conclusion: CCL-XCoT有效减少幻觉，无需依赖外部检索或多模型集成。

Abstract: Multilingual Large Language Models(MLLMs) demonstrate strong generalization
across languages, yet they remain prone to hallucinations, especially in
low-resource languages, due to training data imbalances. These hallucinations,
which include inaccurate or fabricated outputs, are particularly problematic in
domain-specific generation tasks (Chataigner et al., 2024). To address this
challenge, we propose CCL-XCoT(Curriculum-based Contrastive Learning-based
Cross-lingual Chain-of-Thought), a two-stage fine-tuning framework for
mitigating hallucination in MLLMs. Our approach first enhances cross-lingual
semantic alignment through curriculum-based contrastive learning combined with
next-token prediction during continued pre-training. Building on this
foundation, we then introduce a cross-lingual Chain-of-Thought (XCoT) prompting
strategy during instruction fine-tuning, which guides the model to reason in a
high-resource language before generating answers in the target low-resource
language. Experimental results show that CCL-XCoT reduces hallucination rates
by up to 62% and substantially improves factual knowledge transfer across
language pairs, without relying on external retrieval or multi-model ensembles.

</details>


### [149] [HuggingGraph: Understanding the Supply Chain of LLM Ecosystem](https://arxiv.org/abs/2507.14240)
*Mohammad Shahedur Rahman,Peng Gao,Yuede Ji*

Main category: cs.CL

TL;DR: 论文研究了大型语言模型（LLM）供应链中模型与数据集的关系，构建了一个异构图进行分析，揭示了供应链的结构特点和动态性。


<details>
  <summary>Details</summary>
Motivation: 由于LLM的开发依赖预训练模型和外部数据集，可能继承漏洞或偏见，因此理解其供应链关系对风险检测和公平性改进至关重要。

Method: 设计方法系统收集LLM供应链数据，构建有向异构图（397,376节点和453,469边），并进行多种分析。

Result: 发现供应链图规模大、稀疏、符合幂律分布，数据集在训练中起关键作用，模型与数据集间存在强依赖关系，且图动态更新。

Conclusion: 研究为理解LLM供应链提供了结构化视角，有助于风险管理和生态系统优化。

Abstract: Large language models (LLMs) leverage deep learning to process and predict
sequences of words from context, enabling them to perform various NLP tasks,
such as translation, summarization, question answering, and content generation.
However, the growing size and complexity of developing, training, and deploying
advanced LLMs require extensive computational resources and large datasets.
This creates a barrier for users. As a result, platforms that host models and
datasets are widely used. For example, Hugging Face, one of the most popular
platforms, hosted 1.8 million models and 450K datasets by June 2025, with no
sign of slowing down. Since many LLMs are built from base models, pre-trained
models, and external datasets, they can inherit vulnerabilities, biases, or
malicious components from earlier models or datasets. Therefore, it is critical
to understand the origin and development of these components to better detect
potential risks, improve model fairness, and ensure compliance. Motivated by
this, our project aims to study the relationships between models and datasets,
which are core components of the LLM supply chain. First, we design a method to
systematically collect LLM supply chain data. Using this data, we build a
directed heterogeneous graph to model the relationships between models and
datasets, resulting in a structure with 397,376 nodes and 453,469 edges. We
then perform various analyses and uncover several findings, such as: (i) the
LLM supply chain graph is large, sparse, and follows a power-law degree
distribution; (ii) it features a densely connected core and a fragmented
periphery; (iii) datasets play pivotal roles in training; (iv) strong
interdependence exists between models and datasets; and (v) the graph is
dynamic, with daily updates reflecting the ecosystem's ongoing evolution.

</details>


### [150] [Promptomatix: An Automatic Prompt Optimization Framework for Large Language Models](https://arxiv.org/abs/2507.14241)
*Rithesh Murthy,Ming Zhu,Liangwei Yang,Jielin Qiu,Juntao Tan,Shelby Heinecke,Huan Wang,Caiming Xiong,Silvio Savarese*

Main category: cs.CL

TL;DR: Promptomatix是一个自动提示优化框架，能将自然语言任务描述转化为高质量提示，无需手动调整或领域专业知识。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）需要精心设计的提示才能发挥最佳性能，但提示工程目前依赖手动且不一致，对非专家不友好。

Method: Promptomatix结合了轻量级元提示优化器和DSPy编译器，通过分析用户意图、生成合成训练数据、选择提示策略和基于成本目标的提示优化。

Result: 在5个任务类别中，Promptomatix表现优于或与现有库相当，同时减少提示长度和计算开销。

Conclusion: Promptomatix实现了高效、可扩展的提示优化，为非专家提供了便捷的工具。

Abstract: Large Language Models (LLMs) perform best with well-crafted prompts, yet
prompt engineering remains manual, inconsistent, and inaccessible to
non-experts. We introduce Promptomatix, an automatic prompt optimization
framework that transforms natural language task descriptions into high-quality
prompts without requiring manual tuning or domain expertise. Promptomatix
supports both a lightweight meta-prompt-based optimizer and a DSPy-powered
compiler, with modular design enabling future extension to more advanced
frameworks. The system analyzes user intent, generates synthetic training data,
selects prompting strategies, and refines prompts using cost-aware objectives.
Evaluated across 5 task categories, Promptomatix achieves competitive or
superior performance compared to existing libraries, while reducing prompt
length and computational overhead making prompt optimization scalable and
efficient.

</details>


### [151] [In-Depth and In-Breadth: Pre-training Multimodal Language Models Customized for Comprehensive Chart Understanding](https://arxiv.org/abs/2507.14298)
*Wan-Cyuan Fan,Yen-Chun Chen,Mengchen Liu,Alexander Jacobson,Lu Yuan,Leonid Sigal*

Main category: cs.CL

TL;DR: ChartScope是一个针对多样化图表类型优化的LVLM，通过高效数据生成和双路径训练策略提升图表理解能力，并建立了新的评估基准ChartDQA。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖有限图表类型的配对数据且缺乏针对性预训练，限制了模型的泛化能力和数据理解。

Method: 提出高效数据生成管道和双路径训练策略，结合底层数据推理。

Result: 实验表明ChartScope显著提升了对多种图表类型的理解能力。

Conclusion: ChartScope通过创新方法和数据生成策略解决了现有局限性，为图表理解提供了更强大的工具。

Abstract: Recent methods for customizing Large Vision Language Models (LVLMs) for
domain-specific tasks have shown promising results in scientific chart
comprehension. However, existing approaches face two major limitations: First,
they rely on paired data from only a few chart types, limiting generalization
to wide range of chart types. Secondly, they lack targeted pre-training for
chart-data alignment, which hampers the model's understanding of underlying
data. In this paper, we introduce ChartScope, an LVLM optimized for in-depth
chart comprehension across diverse chart types. We propose an efficient data
generation pipeline that synthesizes paired data for a wide range of chart
types, along with a novel Dual-Path training strategy that enabling the model
to succinctly capture essential data details while preserving robust reasoning
capabilities by incorporating reasoning over the underlying data. Lastly, we
establish ChartDQA, a new benchmark for evaluating not only question-answering
at different levels but also underlying data understanding. Experimental
results demonstrate that ChartScope significantly enhances comprehension on a
wide range of chart types. The code and data are available at
https://davidhalladay.github.io/chartscope_demo.

</details>


### [152] [Aligning Large Language Models to Low-Resource Languages through LLM-Based Selective Translation: A Systematic Study](https://arxiv.org/abs/2507.14304)
*Rakesh Paul,Anusha Kamath,Kanishk Singla,Raviraj Joshi,Utkarsh Vaidya,Sanjay Singh Chauhan,Niranjan Wartikar*

Main category: cs.CL

TL;DR: 研究探讨了基于LLM的选择性翻译方法，用于解决多语言大语言模型在低资源语言（如印地语）中对齐时的数据稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 多语言大语言模型在低资源语言中表现不佳，而高质量对齐数据稀缺且翻译成本高。

Method: 提出选择性翻译技术，仅翻译可翻译部分，保留代码、数学表达式等非翻译内容。对比了GCP和Llama-3.1-405B的翻译效果。

Result: 选择性翻译在印地语对齐中表现优于传统翻译方法，且混合翻译样本与原始英语数据效果更佳。

Conclusion: 选择性翻译是提升多语言模型对齐的实用有效方法。

Abstract: Multilingual large language models (LLMs) often demonstrate a performance gap
between English and non-English languages, particularly in low-resource
settings. Aligning these models to low-resource languages is essential yet
challenging due to limited high-quality data. While English alignment datasets
are readily available, curating equivalent data in other languages is expensive
and time-consuming. A common workaround is to translate existing English
alignment data; however, standard translation techniques often fail to preserve
critical elements such as code, mathematical expressions, and structured
formats like JSON. In this work, we investigate LLM-based selective
translation, a technique that selectively translates only the translatable
parts of a text while preserving non-translatable content and sentence
structure. We conduct a systematic study to explore key questions around this
approach, including its effectiveness compared to vanilla translation, the
importance of filtering noisy outputs, and the benefits of mixing translated
samples with original English data during alignment. Our experiments focus on
the low-resource Indic language Hindi and compare translations generated by
Google Cloud Translation (GCP) and Llama-3.1-405B. The results highlight the
promise of selective translation as a practical and effective method for
improving multilingual alignment in LLMs.

</details>


### [153] [How LLMs Comprehend Temporal Meaning in Narratives: A Case Study in Cognitive Evaluation of LLMs](https://arxiv.org/abs/2507.14307)
*Karin de Langis,Jong Inn Park,Andreas Schramm,Bin Hu,Khanh Chi Le,Michael Mensink,Ahn Thu Tong,Dongyeop Kang*

Main category: cs.CL

TL;DR: 研究发现，大型语言模型（LLMs）在处理语言时依赖典型性，判断不一致，且因果推理能力有限，与人类认知方式不同。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs是否以人类方式处理语言中的时间意义，尤其是叙事中的语义和语用推理。

Method: 采用专家参与的探测流程，通过针对性实验评估LLMs的语义和语用处理能力。

Result: LLMs依赖典型性，判断不一致，因果推理能力不足，叙事理解能力有限。

Conclusion: LLMs处理语言的方式与人类不同，缺乏稳健的叙事理解能力，并提出了标准化评估框架。

Abstract: Large language models (LLMs) exhibit increasingly sophisticated linguistic
capabilities, yet the extent to which these behaviors reflect human-like
cognition versus advanced pattern recognition remains an open question. In this
study, we investigate how LLMs process the temporal meaning of linguistic
aspect in narratives that were previously used in human studies. Using an
Expert-in-the-Loop probing pipeline, we conduct a series of targeted
experiments to assess whether LLMs construct semantic representations and
pragmatic inferences in a human-like manner. Our findings show that LLMs
over-rely on prototypicality, produce inconsistent aspectual judgments, and
struggle with causal reasoning derived from aspect, raising concerns about
their ability to fully comprehend narratives. These results suggest that LLMs
process aspect fundamentally differently from humans and lack robust narrative
understanding. Beyond these empirical findings, we develop a standardized
experimental framework for the reliable assessment of LLMs' cognitive and
linguistic capabilities.

</details>


### [154] [What Makes You CLIC: Detection of Croatian Clickbait Headlines](https://arxiv.org/abs/2507.14314)
*Marija Anđedelić,Dominik Šipek,Laura Majer,Jan Šnajder*

Main category: cs.CL

TL;DR: 论文研究了克罗地亚新闻标题中的点击诱饵现象，比较了微调模型和上下文学习方法的效果，发现微调模型表现更优。


<details>
  <summary>Details</summary>
Motivation: 在线新闻依赖广告收入，导致标题多为点击诱饵，影响信息质量和读者信任。研究旨在探索克罗地亚语中点击诱饵检测的最佳方法。

Method: 构建了克罗地亚新闻标题数据集CLIC，比较了微调BERTi\'c模型和基于LLM的上下文学习方法。

Result: 近半数标题含点击诱饵，微调模型表现优于通用LLM。

Conclusion: 微调模型在克罗地亚语点击诱饵检测中效果更佳，为低资源语言提供了实用解决方案。

Abstract: Online news outlets operate predominantly on an advertising-based revenue
model, compelling journalists to create headlines that are often scandalous,
intriguing, and provocative -- commonly referred to as clickbait. Automatic
detection of clickbait headlines is essential for preserving information
quality and reader trust in digital media and requires both contextual
understanding and world knowledge. For this task, particularly in
less-resourced languages, it remains unclear whether fine-tuned methods or
in-context learning (ICL) yield better results. In this paper, we compile CLIC,
a novel dataset for clickbait detection of Croatian news headlines spanning a
20-year period and encompassing mainstream and fringe outlets. We fine-tune the
BERTi\'c model on this task and compare its performance to LLM-based ICL
methods with prompts both in Croatian and English. Finally, we analyze the
linguistic properties of clickbait. We find that nearly half of the analyzed
headlines contain clickbait, and that finetuned models deliver better results
than general LLMs.

</details>


### [155] [Can LLMs Infer Personality from Real World Conversations?](https://arxiv.org/abs/2507.14355)
*Jianfeng Zhu,Ruoming Jin,Karin G. Coifman*

Main category: cs.CL

TL;DR: 论文研究了利用大型语言模型（LLMs）进行人格评估的可行性，发现虽然模型具有高重测信度，但构念效度有限，与真实人格评分的相关性较弱。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在人格评估中的潜力，解决以往研究中依赖合成数据或缺乏心理测量效度的问题。

Method: 使用555份半结构化访谈和BFI-10自评分数作为基准，测试了三种LLM（GPT-4.1 Mini、Meta-LLaMA和DeepSeek）在零样本提示和思维链提示下的表现。

Result: 模型表现出高重测信度，但与真实分数的相关性较弱（最大Pearson's r = 0.27），预测偏向中等或高特质水平。思维链提示和更长输入上下文仅略微改善分布对齐。

Conclusion: 当前LLM在人格推断中存在局限性，需基于证据的开发以提升心理学应用效果。

Abstract: Large Language Models (LLMs) such as OpenAI's GPT-4 and Meta's LLaMA offer a
promising approach for scalable personality assessment from open-ended
language. However, inferring personality traits remains challenging, and
earlier work often relied on synthetic data or social media text lacking
psychometric validity. We introduce a real-world benchmark of 555
semi-structured interviews with BFI-10 self-report scores for evaluating
LLM-based personality inference. Three state-of-the-art LLMs (GPT-4.1 Mini,
Meta-LLaMA, and DeepSeek) were tested using zero-shot prompting for BFI-10 item
prediction and both zero-shot and chain-of-thought prompting for Big Five trait
inference. All models showed high test-retest reliability, but construct
validity was limited: correlations with ground-truth scores were weak (max
Pearson's $r = 0.27$), interrater agreement was low (Cohen's $\kappa < 0.10$),
and predictions were biased toward moderate or high trait levels.
Chain-of-thought prompting and longer input context modestly improved
distributional alignment, but not trait-level accuracy. These results
underscore limitations in current LLM-based personality inference and highlight
the need for evidence-based development for psychological applications.

</details>


### [156] [Text-to-SQL for Enterprise Data Analytics](https://arxiv.org/abs/2507.14372)
*Albert Chen,Manas Bundele,Gaurav Ahlawat,Patrick Stetz,Zhitao Wang,Qiang Fei,Donghoon Jung,Audrey Chu,Bharadwaj Jayaraman,Ayushi Panth,Yatin Arora,Sourav Jain,Renjith Varma,Alexey Ilin,Iuliia Melnychuk,Chelsea Chueh,Joyan Sil,Xiaofeng Wang*

Main category: cs.CL

TL;DR: 本文介绍了LinkedIn开发的一款内部聊天机器人，用于帮助产品经理、工程师和运营团队从动态数据湖中自助获取数据洞察。方法包括构建知识图谱、开发Text-to-SQL代理和交互式聊天机器人。结果显示53%的响应正确或接近正确，并提供了开发企业级Text-to-SQL解决方案的实用路径。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在Text-to-SQL基准测试中取得进展，但构建企业级解决方案仍具挑战性。本文旨在通过实际案例展示如何解决这一问题。

Method: 1. 构建知识图谱，索引数据库元数据、查询日志、Wiki和代码；2. 开发Text-to-SQL代理，检索和排序上下文，生成查询并自动纠错；3. 构建交互式聊天机器人，支持多种用户意图并展示丰富UI。

Result: 聊天机器人每周有300多名用户，53%的响应在内部基准测试中正确或接近正确。消融研究确定了关键组件。

Conclusion: 本文提供了一种实用的企业级Text-to-SQL解决方案开发路径，强调了知识图谱和建模组件的重要性。

Abstract: The introduction of large language models has brought rapid progress on
Text-to-SQL benchmarks, but it is not yet easy to build a working enterprise
solution. In this paper, we present insights from building an internal chatbot
that enables LinkedIn's product managers, engineers, and operations teams to
self-serve data insights from a large, dynamic data lake. Our approach features
three components. First, we construct a knowledge graph that captures
up-to-date semantics by indexing database metadata, historical query logs,
wikis, and code. We apply clustering to identify relevant tables for each team
or product area. Second, we build a Text-to-SQL agent that retrieves and ranks
context from the knowledge graph, writes a query, and automatically corrects
hallucinations and syntax errors. Third, we build an interactive chatbot that
supports various user intents, from data discovery to query writing to
debugging, and displays responses in rich UI elements to encourage follow-up
chats. Our chatbot has over 300 weekly users. Expert review shows that 53% of
its responses are correct or close to correct on an internal benchmark set.
Through ablation studies, we identify the most important knowledge graph and
modeling components, offering a practical path for developing enterprise
Text-to-SQL solutions.

</details>


### [157] [Error-Aware Curriculum Learning for Biomedical Relation Classification](https://arxiv.org/abs/2507.14374)
*Sinchani Chakraborty,Sudeshna Sarkar,Pawan Goyal*

Main category: cs.CL

TL;DR: 提出了一种基于错误感知的师生框架，通过GPT-4o的指导改进生物医学文本中的关系分类（RC），并通过课程学习和知识图谱增强实现最佳性能。


<details>
  <summary>Details</summary>
Motivation: 生物医学文本中的关系分类对构建知识图谱和药物再利用等应用至关重要，但现有方法存在不足。

Method: 使用师生框架，教师分析学生模型的错误并生成补救措施，通过指令调优和课程学习训练两个学生模型，并构建知识图谱支持上下文感知RC。

Result: 在5个PPI数据集中的4个和DDI数据集上达到最新最优性能，ChemProt上保持竞争力。

Conclusion: 提出的框架通过结构化指导和知识图谱增强显著提升了关系分类性能。

Abstract: Relation Classification (RC) in biomedical texts is essential for
constructing knowledge graphs and enabling applications such as drug
repurposing and clinical decision-making. We propose an error-aware
teacher--student framework that improves RC through structured guidance from a
large language model (GPT-4o). Prediction failures from a baseline student
model are analyzed by the teacher to classify error types, assign difficulty
scores, and generate targeted remediations, including sentence rewrites and
suggestions for KG-based enrichment. These enriched annotations are used to
train a first student model via instruction tuning. This model then annotates a
broader dataset with difficulty scores and remediation-enhanced inputs. A
second student is subsequently trained via curriculum learning on this dataset,
ordered by difficulty, to promote robust and progressive learning. We also
construct a heterogeneous biomedical knowledge graph from PubMed abstracts to
support context-aware RC. Our approach achieves new state-of-the-art
performance on 4 of 5 PPI datasets and the DDI dataset, while remaining
competitive on ChemProt.

</details>


### [158] [X-Intelligence 3.0: Training and Evaluating Reasoning LLM for Semiconductor Display](https://arxiv.org/abs/2507.14430)
*Xiaolin Yan,Yangxing Liu,Jiazhang Zheng,Chi Liu,Mingyu Du,Caisheng Chen,Haoyang Liu,Ming Ding,Yuan Li,Qiuping Liao,Linfeng Li,Zhili Mei,Siyu Wan,Li Li,Ruyi Zhong,Jiangling Yu,Xule Liu,Huihui Hu,Jiameng Yue,Ruohui Cheng,Qi Yang,Liangqing Wu,Ke Zhu,Chi Zhang,Chufei Jing,Yifan Zhou,Yan Liang,Dongdong Li,Zhaohui Wang,Bin Zhao,Mingzhou Wu,Mingzhong Zhou,Peng Du,Zuomin Liao,Chao Dai,Pengfei Liang,Xiaoguang Zhu,Yu Zhang,Yu Gu,Kun Pan,Yuan Wu,Yanqing Guan,Shaojing Wu,Zikang Feng,Xianze Ma,Peishan Cheng,Wenjuan Jiang,Jing Ba,Huihao Yu,Zeping Hu,Yuan Xu,Zhiwei Liu,He Wang,Zhenguo Lin,Ming Liu,Yanhong Meng*

Main category: cs.CL

TL;DR: X-Intelligence 3.0是首个专为半导体显示行业设计的高性能推理模型，填补了LLMs在该领域的空白。


<details>
  <summary>Details</summary>
Motivation: 现有LLMs在半导体显示行业缺乏领域专业知识和训练，限制了其应用效果。

Method: 通过监督微调、强化学习和领域知识库增强模型推理能力，并引入自动化评估框架和RAG机制。

Result: X-Intelligence 3.0在多个评估中超越SOTA模型DeepSeek-R1-671B，展现了高效性能。

Conclusion: 该模型为半导体显示行业的复杂推理问题提供了强大解决方案。

Abstract: Large language models (LLMs) have recently achieved significant advances in
reasoning and demonstrated their advantages in solving challenging problems.
Yet, their effectiveness in the semiconductor display industry remains limited
due to a lack of domain-specific training and expertise. To bridge this gap, we
present X-Intelligence 3.0, the first high-performance reasoning model
specifically developed for the semiconductor display industry. This model is
designed to deliver expert-level understanding and reasoning for the industry's
complex challenges. Leveraging a carefully curated industry knowledge base, the
model undergoes supervised fine-tuning and reinforcement learning to enhance
its reasoning and comprehension capabilities. To further accelerate
development, we implemented an automated evaluation framework that simulates
expert-level assessments. We also integrated a domain-specific
retrieval-augmented generation (RAG) mechanism, resulting in notable
performance gains on benchmark datasets. Despite its relatively compact size of
32 billion parameters, X-Intelligence 3.0 outperforms SOTA DeepSeek-R1-671B
across multiple evaluations. This demonstrates its exceptional efficiency and
establishes it as a powerful solution to the longstanding reasoning challenges
faced by the semiconductor display industry.

</details>


### [159] [XL-DURel: Finetuning Sentence Transformers for Ordinal Word-in-Context Classification](https://arxiv.org/abs/2507.14578)
*Sachin Yadav,Dominik Schlechtweg*

Main category: cs.CL

TL;DR: XL-DURel是一个多语言Sentence Transformer模型，专注于顺序Word-in-Context分类，通过角距离优化在复杂空间中的排名任务，表现优于先前模型。


<details>
  <summary>Details</summary>
Motivation: 解决Word-in-Context（WiC）分类问题，尤其是顺序和二元任务，探索统一处理方法。

Method: 微调多语言Sentence Transformer模型，测试多种回归和排名损失函数，基于复杂空间中的角距离优化。

Result: 在顺序和二元数据上表现优于先前模型，且优化顺序任务可提升二元任务性能。

Conclusion: 为不同WiC任务提供统一建模方法，展示了顺序任务优化对二元任务的积极影响。

Abstract: We propose XL-DURel, a finetuned, multilingual Sentence Transformer model
optimized for ordinal Word-in-Context classification. We test several loss
functions for regression and ranking tasks managing to outperform previous
models on ordinal and binary data with a ranking objective based on angular
distance in complex space. We further show that binary WiC can be treated as a
special case of ordinal WiC and that optimizing models for the general ordinal
task improves performance on the more specific binary task. This paves the way
for a unified treatment of WiC modeling across different task formulations.

</details>


### [160] [Exploring Human-AI Complementarity in CPS Diagnosis Using Unimodal and Multimodal BERT Models](https://arxiv.org/abs/2507.14579)
*Kester Wong,Sahan Bulathwela,Mutlu Cukurova*

Main category: cs.CL

TL;DR: 论文探讨了使用多模态BERT模型（AudiBERT）检测协作问题解决（CPS）指标，发现其在社交认知维度有显著改进，但在情感维度未观察到类似效果。数据量和人类评分一致性对模型性能有显著影响。


<details>
  <summary>Details</summary>
Motivation: 研究旨在通过多模态方法（结合语音和声学特征）提升CPS指标的检测效果，并探索人机互补的潜力。

Method: 采用AudiBERT模型，整合语音和声学特征，与BERT模型对比，分析其在CPS指标分类中的表现。

Result: AudiBERT在社交认知维度的分类表现显著优于BERT，但在情感维度无显著差异。数据量和人类评分一致性显著影响模型性能。

Conclusion: 提出了一种结构化方法以实现人机互补，强调模型可解释性在支持人类参与反思编码过程中的重要性。

Abstract: Detecting collaborative problem solving (CPS) indicators from dialogue using
machine learning techniques is a significant challenge for the field of AI in
Education. Recent studies have explored the use of Bidirectional Encoder
Representations from Transformers (BERT) models on transcription data to
reliably detect meaningful CPS indicators. A notable advancement involved the
multimodal BERT variant, AudiBERT, which integrates speech and
acoustic-prosodic audio features to enhance CPS diagnosis. Although initial
results demonstrated multimodal improvements, the statistical significance of
these enhancements remained unclear, and there was insufficient guidance on
leveraging human-AI complementarity for CPS diagnosis tasks. This workshop
paper extends the previous research by highlighting that the AudiBERT model not
only improved the classification of classes that were sparse in the dataset,
but it also had statistically significant class-wise improvements over the BERT
model for classifications in the social-cognitive dimension. However, similar
significant class-wise improvements over the BERT model were not observed for
classifications in the affective dimension. A correlation analysis highlighted
that larger training data was significantly associated with higher recall
performance for both the AudiBERT and BERT models. Additionally, the precision
of the BERT model was significantly associated with high inter-rater agreement
among human coders. When employing the BERT model to diagnose indicators within
these subskills that were well-detected by the AudiBERT model, the performance
across all indicators was inconsistent. We conclude the paper by outlining a
structured approach towards achieving human-AI complementarity for CPS
diagnosis, highlighting the crucial inclusion of model explainability to
support human agency and engagement in the reflective coding process.

</details>


### [161] [Explainable Collaborative Problem Solving Diagnosis with BERT using SHAP and its Implications for Teacher Adoption](https://arxiv.org/abs/2507.14584)
*Kester Wong,Sahan Bulathwela,Mutlu Cukurova*

Main category: cs.CL

TL;DR: 研究使用SHAP方法分析BERT模型在协作问题解决（CPS）分类中词标记的贡献，发现高性能分类未必有合理解释，并识别出语义无关但对分类有贡献的词标记。


<details>
  <summary>Details</summary>
Motivation: 增强BERT模型在CPS诊断中的可解释性，以提升教师等终端用户的信任和采用率。

Method: 使用SHAP方法分析BERT模型分类决策中词标记的贡献。

Result: 发现分类性能与解释合理性不直接相关，存在语义无关但对分类有贡献的词标记。

Conclusion: 建议进一步研究集成模型架构和人机互补方法，以提升CPS诊断的细粒度区分能力。

Abstract: The use of Bidirectional Encoder Representations from Transformers (BERT)
model and its variants for classifying collaborative problem solving (CPS) has
been extensively explored within the AI in Education community. However,
limited attention has been given to understanding how individual tokenised
words in the dataset contribute to the model's classification decisions.
Enhancing the explainability of BERT-based CPS diagnostics is essential to
better inform end users such as teachers, thereby fostering greater trust and
facilitating wider adoption in education. This study undertook a preliminary
step towards model transparency and explainability by using SHapley Additive
exPlanations (SHAP) to examine how different tokenised words in transcription
data contributed to a BERT model's classification of CPS processes. The
findings suggested that well-performing classifications did not necessarily
equate to a reasonable explanation for the classification decisions. Particular
tokenised words were used frequently to affect classifications. The analysis
also identified a spurious word, which contributed positively to the
classification but was not semantically meaningful to the class. While such
model transparency is unlikely to be useful to an end user to improve their
practice, it can help them not to overrely on LLM diagnostics and ignore their
human expertise. We conclude the workshop paper by noting that the extent to
which the model appropriately uses the tokens for its classification is
associated with the number of classes involved. It calls for an investigation
into the exploration of ensemble model architectures and the involvement of
human-AI complementarity for CPS diagnosis, since considerable human reasoning
is still required for fine-grained discrimination of CPS subskills.

</details>


### [162] [Backtranslation and paraphrasing in the LLM era? Comparing data augmentation methods for emotion classification](https://arxiv.org/abs/2507.14590)
*Łukasz Radliński,Mateusz Guściora,Jan Kocoń*

Main category: cs.CL

TL;DR: 论文探讨了利用GPT等大语言模型的数据增强方法，比较了传统方法（如复述和回译）与纯生成方法在解决数据稀缺和类别不平衡问题上的效果。


<details>
  <summary>Details</summary>
Motivation: 解决NLP任务中数据稀缺和类别不平衡的问题，探索传统数据增强方法在新一代模型中的潜力。

Method: 选择了回译和复述等传统方法，结合ChatGPT进行实验，比较了四种数据增强方法在不同实验设置下的效果。

Result: 回译和复述方法在生成数据质量和分类性能上表现优于或少样本生成方法。

Conclusion: 传统数据增强方法在新一代模型中仍具竞争力，甚至优于纯生成方法。

Abstract: Numerous domain-specific machine learning tasks struggle with data scarcity
and class imbalance. This paper systematically explores data augmentation
methods for NLP, particularly through large language models like GPT. The
purpose of this paper is to examine and evaluate whether traditional methods
such as paraphrasing and backtranslation can leverage a new generation of
models to achieve comparable performance to purely generative methods. Methods
aimed at solving the problem of data scarcity and utilizing ChatGPT were
chosen, as well as an exemplary dataset. We conducted a series of experiments
comparing four different approaches to data augmentation in multiple
experimental setups. We then evaluated the results both in terms of the quality
of generated data and its impact on classification performance. The key
findings indicate that backtranslation and paraphrasing can yield comparable or
even better results than zero and a few-shot generation of examples.

</details>


### [163] [Retrieval-Augmented Clinical Benchmarking for Contextual Model Testing in Kenyan Primary Care: A Methodology Paper](https://arxiv.org/abs/2507.14615)
*Fred Mutisya,Shikoh Gitau,Christine Syovata,Diana Oigara,Ibrahim Matende,Muna Aden,Munira Ali,Ryan Nyotu,Diana Marion,Job Nyangena,Nasubo Ongoma,Keith Mbae,Elizabeth Wamicha,Eric Mibuari,Jean Philbert Nsengemana,Talkmore Chidede*

Main category: cs.CL

TL;DR: 论文提出了一种基于检索增强生成（RAG）的方法，创建了一个针对肯尼亚初级医疗的基准数据集和评估框架，以测试大型语言模型（LLMs）在非洲医疗场景中的表现。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在非洲低资源医疗环境中的有效性，填补现有研究的空白。

Method: 使用RAG技术将临床问题与肯尼亚国家指南对齐，生成多语言（英语和斯瓦希里语）的临床场景、选择题及答案，并通过专家评审确保质量。

Result: 发现LLMs在本地化场景中表现显著不足，尤其是在非洲医疗内容上的准确性低于美国基准。

Conclusion: 提出了一个可复制的指南驱动动态评估模型，以支持非洲医疗系统中AI的安全部署。

Abstract: Large Language Models(LLMs) hold promise for improving healthcare access in
low-resource settings, but their effectiveness in African primary care remains
underexplored. We present a methodology for creating a benchmark dataset and
evaluation framework focused on Kenyan Level 2 and 3 clinical care. Our
approach uses retrieval augmented generation (RAG) to ground clinical questions
in Kenya's national guidelines, ensuring alignment with local standards. These
guidelines were digitized, chunked, and indexed for semantic retrieval. Gemini
Flash 2.0 Lite was then prompted with guideline excerpts to generate realistic
clinical scenarios, multiple-choice questions, and rationale based answers in
English and Swahili. Kenyan physicians co-created and refined the dataset, and
a blinded expert review process ensured clinical accuracy, clarity, and
cultural appropriateness. The resulting Alama Health QA dataset includes
thousands of regulator-aligned question answer pairs across common outpatient
conditions. Beyond accuracy, we introduce evaluation metrics that test clinical
reasoning, safety, and adaptability such as rare case detection (Needle in the
Haystack), stepwise logic (Decision Points), and contextual adaptability.
Initial results reveal significant performance gaps when LLMs are applied to
localized scenarios, consistent with findings that LLM accuracy is lower on
African medical content than on US-based benchmarks. This work offers a
replicable model for guideline-driven, dynamic benchmarking to support safe AI
deployment in African health systems.

</details>


### [164] [Linear Relational Decoding of Morphology in Language Models](https://arxiv.org/abs/2507.14640)
*Eric Xia,Jugal Kalita*

Main category: cs.CL

TL;DR: 论文发现，通过两部分的仿射近似可以很好地近似某些主客体关系的Transformer计算，线性变换Ws能准确重现最终客体状态。


<details>
  <summary>Details</summary>
Motivation: 探索Transformer模型中主客体关系的线性可解释性，尤其是形态学关系。

Method: 使用Bigger Analogy Test Set，通过线性变换Ws（s为主词中间层表示，W为模型导数）重现客体状态。

Result: 在形态学关系上达到90%的忠实度，多语言和跨模型验证结果一致。

Conclusion: 语言模型中的某些概念关系（如形态学）可通过潜在空间的稀疏线性变换解释。

Abstract: A two-part affine approximation has been found to be a good approximation for
transformer computations over certain subject object relations. Adapting the
Bigger Analogy Test Set, we show that the linear transformation Ws, where s is
a middle layer representation of a subject token and W is derived from model
derivatives, is also able to accurately reproduce final object states for many
relations. This linear technique is able to achieve 90% faithfulness on
morphological relations, and we show similar findings multi-lingually and
across models. Our findings indicate that some conceptual relationships in
language models, such as morphology, are readily interpretable from latent
space, and are sparsely encoded by cross-layer linear transformations.

</details>


### [165] [Cleanse: Uncertainty Estimation Approach Using Clustering-based Semantic Consistency in LLMs](https://arxiv.org/abs/2507.14649)
*Minsuh Joo,Hyunsoo Cho*

Main category: cs.CL

TL;DR: 论文提出了一种基于聚类的语义一致性方法（Cleanse），用于估计大型语言模型（LLM）生成内容的不确定性，以检测幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在多种NLP任务中表现优异，但其生成的幻觉（不准确回答）仍是一个关键问题，影响模型的安全性和可靠性。

Method: Cleanse通过聚类量化隐藏嵌入中的语义一致性比例，以估计不确定性。

Result: 在LLaMA-7B、LLaMA-13B、LLaMA2-7B和Mistral-7B模型以及SQuAD和CoQA基准测试中验证了Cleanse的有效性。

Conclusion: Cleanse是一种有效的幻觉检测方法，有助于提升LLM的安全性和可靠性。

Abstract: Despite the outstanding performance of large language models (LLMs) across
various NLP tasks, hallucinations in LLMs--where LLMs generate inaccurate
responses--remains as a critical problem as it can be directly connected to a
crisis of building safe and reliable LLMs. Uncertainty estimation is primarily
used to measure hallucination levels in LLM responses so that correct and
incorrect answers can be distinguished clearly. This study proposes an
effective uncertainty estimation approach, \textbf{Cl}ust\textbf{e}ring-based
sem\textbf{an}tic con\textbf{s}ist\textbf{e}ncy (\textbf{Cleanse}). Cleanse
quantifies the uncertainty with the proportion of the intra-cluster consistency
in the total consistency between LLM hidden embeddings which contain adequate
semantic information of generations, by employing clustering. The effectiveness
of Cleanse for detecting hallucination is validated using four off-the-shelf
models, LLaMA-7B, LLaMA-13B, LLaMA2-7B and Mistral-7B and two
question-answering benchmarks, SQuAD and CoQA.

</details>


### [166] [Mangosteen: An Open Thai Corpus for Language Model Pretraining](https://arxiv.org/abs/2507.14664)
*Wannaphong Phatthiyaphaibun,Can Udomcharoenchaikit,Pakpoom Singkorapoom,Kunat Pipatanakul,Ekapol Chuangsuwanich,Peerat Limkonchotiwat,Sarana Nutanong*

Main category: cs.CL

TL;DR: Mangosteen是一个47B泰语语料库，通过定制化Dolma流程构建，提升了泰语模型性能，并公开了全部资源。


<details>
  <summary>Details</summary>
Motivation: 现有语料库处理泰语时缺乏透明度和针对性，导致低质量和不可复现问题。

Method: 采用泰语适应的Dolma流程，包括自定义语言识别、质量过滤器和内容过滤器，结合非网络来源数据。

Result: 流程将CommonCrawl从202M文档缩减至25M，提升模型性能（SEA-HELM NLG从3到11），8B参数模型在泰语基准上超越其他模型。

Conclusion: Mangosteen为泰语及区域LLM研究提供了透明、高质量的语料库和可复现基础。

Abstract: Pre-training data shapes a language model's quality, but raw web text is
noisy and demands careful cleaning. Existing large-scale corpora rely on
English-centric or language-agnostic pipelines whose heuristics do not capture
Thai script or cultural nuances, leaving risky material such as gambling
content untreated. Prior Thai-specific efforts customize pipelines or build new
ones, yet seldom release their data or document design choices, hindering
reproducibility and raising the question of how to construct a transparent,
high-quality Thai corpus. We introduce Mangosteen: a 47 billion-token Thai
corpus built through a Thai-adapted Dolma pipeline that includes custom
rule-based language ID, revised C4/Gopher quality filters, and Thai-trained
content filters, plus curated non-web sources such as Wikipedia, Royal Gazette
texts, OCR-extracted books, and CC-licensed YouTube subtitles. Systematic
ablations using GPT-2 show the pipeline trims CommonCrawl from 202M to 25M
documents while raising SEA-HELM NLG from 3 to 11; an 8B-parameter SEA-LION
model continually pre-trained on Mangosteen then surpasses SEA-LION-v3 and
Llama-3.1 by about four points on Thai benchmarks. We release the full pipeline
code, cleaning manifests, corpus snapshot, and all checkpoints, providing a
fully reproducible foundation for future Thai and regional LLM research.

</details>


### [167] [Large Language Models as Medical Codes Selectors: a benchmark using the International Classification of Primary Care](https://arxiv.org/abs/2507.14681)
*Vinicius Anjos de Almeida,Vinicius de Camargo,Raquel Gómez-Bravo,Egbert van der Haring,Kees van Boven,Marcelo Finger,Luis Fernandez Lopez*

Main category: cs.CL

TL;DR: LLMs can effectively automate ICPC-2 coding without fine-tuning, with top models achieving high F1-scores. Challenges include input length and formatting for smaller models.


<details>
  <summary>Details</summary>
Motivation: To assess the potential of LLMs in automating medical coding (ICPC-2) using domain-specific search engine outputs, improving efficiency and accuracy in healthcare data structuring.

Method: Used a dataset of 437 clinical expressions with ICPC-2 codes, leveraging a semantic search engine and 33 LLMs to select the best-matching codes. Evaluated performance via F1-score, token usage, cost, and format adherence.

Result: 28 models achieved F1-score >0.8; top performers included GPT-4.5-preview and Gemini-2.5-pro. Retriever optimization improved performance by up to 4 points. Smaller models struggled with formatting.

Conclusion: LLMs demonstrate strong potential for ICPC-2 coding automation, but broader evaluations are needed for clinical validation.

Abstract: Background: Medical coding structures healthcare data for research, quality
monitoring, and policy. This study assesses the potential of large language
models (LLMs) to assign ICPC-2 codes using the output of a domain-specific
search engine.
  Methods: A dataset of 437 Brazilian Portuguese clinical expressions, each
annotated with ICPC-2 codes, was used. A semantic search engine (OpenAI's
text-embedding-3-large) retrieved candidates from 73,563 labeled concepts.
Thirty-three LLMs were prompted with each query and retrieved results to select
the best-matching ICPC-2 code. Performance was evaluated using F1-score, along
with token usage, cost, response time, and format adherence.
  Results: Twenty-eight models achieved F1-score > 0.8; ten exceeded 0.85. Top
performers included gpt-4.5-preview, o3, and gemini-2.5-pro. Retriever
optimization can improve performance by up to 4 points. Most models returned
valid codes in the expected format, with reduced hallucinations. Smaller models
(<3B) struggled with formatting and input length.
  Conclusions: LLMs show strong potential for automating ICPC-2 coding, even
without fine-tuning. This work offers a benchmark and highlights challenges,
but findings are limited by dataset scope and setup. Broader, multilingual,
end-to-end evaluations are needed for clinical validation.

</details>


### [168] [MiroMind-M1: An Open-Source Advancement in Mathematical Reasoning via Context-Aware Multi-Stage Policy Optimization](https://arxiv.org/abs/2507.14683)
*Xingxuan Li,Yao Xiao,Dianwen Ng,Hai Ye,Yue Deng,Xiang Lin,Bin Wang,Zhanfeng Mo,Chong Zhang,Yueyi Zhang,Zonglin Yang,Ruilin Li,Lei Lei,Shihao Xu,Han Zhao,Weiling Chen,Feng Ji,Lidong Bing*

Main category: cs.CL

TL;DR: 论文介绍了MiroMind-M1系列，一种完全开源的推理语言模型，旨在提高透明度和可复现性，并在数学推理任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 封闭源RLMs（如GPT-3）虽然表现出色，但缺乏透明度和可复现性。开源项目通常缺少关键资源（如数据集和训练配置），限制了复现性。

Method: 模型分两阶段训练：SFT（使用719K数学推理问题）和RLVR（使用62K挑战性问题），并引入Context-Aware Multi-Stage Policy Optimization算法。

Result: 模型在AIME24、AIME25和MATH基准测试中表现优异，达到或超过现有开源RLMs的性能。

Conclusion: MiroMind-M1系列为社区提供了完整的资源（模型、数据集、配置），支持进一步研究和社区发展。

Abstract: Large language models have recently evolved from fluent text generation to
advanced reasoning across diverse domains, giving rise to reasoning language
models. Among these domains, mathematical reasoning serves as a representative
benchmark as it requires precise multi-step logic and abstract reasoning, which
can be generalized to other tasks. While closed-source RLMs such as GPT-o3
demonstrate impressive reasoning capabilities, their proprietary nature limits
transparency and reproducibility. Although many open-source projects aim to
close this gap, most of them lack sufficient openness by omitting critical
resources such as datasets and detailed training configurations, which hinders
reproducibility. To contribute toward greater transparency in RLM development,
we introduce the MiroMind-M1 series, a set of fully open-source RLMs built on
the Qwen-2.5 backbone that match or exceed the performance of existing
open-source RLMs. Specifically, our models are trained in two stages: SFT on a
carefully curated corpus of 719K math-reasoning problems with verified CoT
trajectories, followed by RLVR on 62K challenging and verifiable problems. To
enhance the robustness and efficiency of the RLVR process, we introduce
Context-Aware Multi-Stage Policy Optimization, an algorithm that integrates
length-progressive training with an adaptive repetition penalty to encourage
context-aware RL training. Our model achieves state-of-the-art or competitive
performance and superior token efficiency among Qwen-2.5-based open-source 7B
and 32B models on the AIME24, AIME25, and MATH benchmarks. To facilitate
reproducibility, we release the complete stack: models (MiroMind-M1-SFT-7B,
MiroMind-M1-RL-7B, MiroMind-M1-RL-32B); datasets (MiroMind-M1-SFT-719K,
MiroMind-M1-RL-62K); and all training and evaluation configurations. We hope
these resources will support further research and foster community advancement.

</details>


### [169] [Mind the Gap: A Review of Arabic Post-Training Datasets and Their Limitations](https://arxiv.org/abs/2507.14688)
*Mohammed Alkhowaiter,Norah Alshahrani,Saied Alshahrani,Reem I. Masoud,Alaa Alzahrani,Deema Alnuhait,Emad A. Alghamdi,Khalid Almubarak*

Main category: cs.CL

TL;DR: 本文综述了Hugging Face Hub上公开的阿拉伯语后训练数据集，从四个维度（LLM能力、可操控性、对齐性和鲁棒性）评估其质量，揭示了任务多样性不足、文档缺失等关键问题，并提出了改进建议。


<details>
  <summary>Details</summary>
Motivation: 后训练是提升预训练大语言模型（LLM）与人类指令对齐的关键技术，但阿拉伯语后训练数据集的质量和多样性存在不足，亟需系统评估和改进。

Method: 通过四个维度（LLM能力、可操控性、对齐性和鲁棒性）评估Hugging Face Hub上的阿拉伯语后训练数据集，并基于流行度、文档质量等指标进行严格分析。

Result: 发现阿拉伯语后训练数据集存在任务多样性不足、文档不一致或缺失、社区采用率低等问题。

Conclusion: 论文指出了这些问题对阿拉伯语LLM发展的影响，并提出了改进后训练数据集开发的具体建议。

Abstract: Post-training has emerged as a crucial technique for aligning pre-trained
Large Language Models (LLMs) with human instructions, significantly enhancing
their performance across a wide range of tasks. Central to this process is the
quality and diversity of post-training datasets. This paper presents a review
of publicly available Arabic post-training datasets on the Hugging Face Hub,
organized along four key dimensions: (1) LLM Capabilities (e.g., Question
Answering, Translation, Reasoning, Summarization, Dialogue, Code Generation,
and Function Calling); (2) Steerability (e.g., persona and system prompts); (3)
Alignment (e.g., cultural, safety, ethics, and fairness), and (4) Robustness.
Each dataset is rigorously evaluated based on popularity, practical adoption,
recency and maintenance, documentation and annotation quality, licensing
transparency, and scientific contribution. Our review revealed critical gaps in
the development of Arabic post-training datasets, including limited task
diversity, inconsistent or missing documentation and annotation, and low
adoption across the community. Finally, the paper discusses the implications of
these gaps on the progress of Arabic LLMs and applications while providing
concrete recommendations for future efforts in post-training dataset
development.

</details>


### [170] [Rethinking Suicidal Ideation Detection: A Trustworthy Annotation Framework and Cross-Lingual Model Evaluation](https://arxiv.org/abs/2507.14693)
*Amina Dzafic,Merve Kavut,Ulya Bayram*

Main category: cs.CL

TL;DR: 研究构建了一个土耳其语自杀意念语料库，并提出了资源高效的标注框架，同时评估了标签可靠性和模型一致性，强调了心理健康NLP中透明性和可靠性的重要性。


<details>
  <summary>Details</summary>
Motivation: 解决自杀意念检测中语言覆盖不足和标注不可靠的问题，推动全球自杀预防的AI应用。

Method: 构建土耳其语语料库，设计标注框架，使用预训练模型进行标签可靠性和模型一致性评估。

Result: 发现现有模型在零样本迁移学习下表现不佳，强调需要更严格的标注和评估方法。

Conclusion: 呼吁在心理健康NLP中提高数据和模型可靠性，并采用透明的方法。

Abstract: Suicidal ideation detection is critical for real-time suicide prevention, yet
its progress faces two under-explored challenges: limited language coverage and
unreliable annotation practices. Most available datasets are in English, but
even among these, high-quality, human-annotated data remains scarce. As a
result, many studies rely on available pre-labeled datasets without examining
their annotation process or label reliability. The lack of datasets in other
languages further limits the global realization of suicide prevention via
artificial intelligence (AI). In this study, we address one of these gaps by
constructing a novel Turkish suicidal ideation corpus derived from social media
posts and introducing a resource-efficient annotation framework involving three
human annotators and two large language models (LLMs). We then address the
remaining gaps by performing a bidirectional evaluation of label reliability
and model consistency across this dataset and three popular English suicidal
ideation detection datasets, using transfer learning through eight pre-trained
sentiment and emotion classifiers. These transformers help assess annotation
consistency and benchmark model performance against manually labeled data. Our
findings underscore the need for more rigorous, language-inclusive approaches
to annotation and evaluation in mental health natural language processing (NLP)
while demonstrating the questionable performance of popular models with
zero-shot transfer learning. We advocate for transparency in model training and
dataset construction in mental health NLP, prioritizing data and model
reliability.

</details>


### [171] [Disparities in Peer Review Tone and the Role of Reviewer Anonymity](https://arxiv.org/abs/2507.14741)
*Maria Sahakyan,Bedoor AlShebli*

Main category: cs.CL

TL;DR: 该研究通过分析8万份同行评审，揭示了语言中的隐性偏见及其对作者性别、种族和机构背景的影响，同时探讨了匿名评审对公平性的作用。


<details>
  <summary>Details</summary>
Motivation: 同行评审虽被视为科学诚信的守门人，但存在偏见问题。研究旨在揭示语言如何加剧评审中的不平等。

Method: 采用自然语言处理和大规模统计建模，分析匿名和署名评审的语言差异。

Result: 发现评审语言在作者人口统计学特征上存在显著差异，匿名性对公平性的作用被挑战。

Conclusion: 研究为学术出版改革提供了关键见解，强调评审政策对职业发展和科学进步的影响。

Abstract: The peer review process is often regarded as the gatekeeper of scientific
integrity, yet increasing evidence suggests that it is not immune to bias.
Although structural inequities in peer review have been widely debated, much
less attention has been paid to the subtle ways in which language itself may
reinforce disparities. This study undertakes one of the most comprehensive
linguistic analyses of peer review to date, examining more than 80,000 reviews
in two major journals. Using natural language processing and large-scale
statistical modeling, it uncovers how review tone, sentiment, and supportive
language vary across author demographics, including gender, race, and
institutional affiliation. Using a data set that includes both anonymous and
signed reviews, this research also reveals how the disclosure of reviewer
identity shapes the language of evaluation. The findings not only expose hidden
biases in peer feedback, but also challenge conventional assumptions about
anonymity's role in fairness. As academic publishing grapples with reform,
these insights raise critical questions about how review policies shape career
trajectories and scientific progress.

</details>


### [172] [On the robustness of modeling grounded word learning through a child's egocentric input](https://arxiv.org/abs/2507.14749)
*Wai Keen Vong,Brenden M. Lake*

Main category: cs.CL

TL;DR: 研究探讨机器学习如何模拟儿童语言习得，通过多模态神经网络训练验证其在不同儿童数据上的稳健性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型依赖海量数据，与儿童语言习得的有限输入形成对比，研究旨在缩小这一差距。

Method: 使用自动语音转录方法处理SAYCam数据集，生成多模态数据并训练多种神经网络配置。

Result: 网络能从不同儿童的数据中学习并泛化词汇映射，验证了多模态神经网络的稳健性。

Conclusion: 研究证实了多模态神经网络在词汇学习中的有效性，同时揭示了不同儿童数据带来的个体差异。

Abstract: What insights can machine learning bring to understanding human language
acquisition? Large language and multimodal models have achieved remarkable
capabilities, but their reliance on massive training datasets creates a
fundamental mismatch with children, who succeed in acquiring language from
comparatively limited input. To help bridge this gap, researchers have
increasingly trained neural networks using data similar in quantity and quality
to children's input. Taking this approach to the limit, Vong et al. (2024)
showed that a multimodal neural network trained on 61 hours of visual and
linguistic input extracted from just one child's developmental experience could
acquire word-referent mappings. However, whether this approach's success
reflects the idiosyncrasies of a single child's experience, or whether it would
show consistent and robust learning patterns across multiple children's
experiences was not explored. In this article, we applied automated speech
transcription methods to the entirety of the SAYCam dataset, consisting of over
500 hours of video data spread across all three children. Using these automated
transcriptions, we generated multi-modal vision-and-language datasets for both
training and evaluation, and explored a range of neural network configurations
to examine the robustness of simulated word learning. Our findings demonstrate
that networks trained on automatically transcribed data from each child can
acquire and generalize word-referent mappings across multiple network
architectures. These results validate the robustness of multimodal neural
networks for grounded word learning, while highlighting the individual
differences that emerge in how models learn when trained on each child's
developmental experiences.

</details>


### [173] [GRACE: Generative Recommendation via Journey-Aware Sparse Attention on Chain-of-Thought Tokenization](https://arxiv.org/abs/2507.14758)
*Luyi Ma,Wanjia Zhang,Kai Zhao,Abhishek Kulkarni,Lalitesh Morishetti,Anjana Ganesh,Ashish Ranjan,Aashika Padmanabhan,Jianpeng Xu,Jason Cho,Praveen Kanumala,Kaushiki Nag,Sumit Dutta,Kamiya Motwani,Malay Patel,Evren Korpeoglu,Sushant Kumar,Kannan Achan*

Main category: cs.CL

TL;DR: GRACE是一种生成式多行为推荐框架，通过改进的token化和稀疏注意力机制，显著提升了推荐性能并降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有生成模型在多行为推荐中存在token推理信息不足、计算成本高和多尺度建模有限的问题。

Method: GRACE采用混合Chain-of-Thought token化方法，结合产品知识图谱属性，并设计Journey-Aware稀疏注意力机制。

Result: 在真实数据集上，GRACE在HR@10和NDCG@10指标上显著优于基线，计算成本降低48%。

Conclusion: GRACE通过改进token化和注意力机制，为多行为推荐提供了高效且可解释的解决方案。

Abstract: Generative models have recently demonstrated strong potential in
multi-behavior recommendation systems, leveraging the expressive power of
transformers and tokenization to generate personalized item sequences. However,
their adoption is hindered by (1) the lack of explicit information for token
reasoning, (2) high computational costs due to quadratic attention complexity
and dense sequence representations after tokenization, and (3) limited
multi-scale modeling over user history. In this work, we propose GRACE
(Generative Recommendation via journey-aware sparse Attention on
Chain-of-thought tokEnization), a novel generative framework for multi-behavior
sequential recommendation. GRACE introduces a hybrid Chain-of-Thought (CoT)
tokenization method that encodes user-item interactions with explicit
attributes from product knowledge graphs (e.g., category, brand, price) over
semantic tokenization, enabling interpretable and behavior-aligned generation.
To address the inefficiency of standard attention, we design a Journey-Aware
Sparse Attention (JSA) mechanism, which selectively attends to compressed,
intra-, inter-, and current-context segments in the tokenized sequence.
Experiments on two real-world datasets show that GRACE significantly
outperforms state-of-the-art baselines, achieving up to +106.9% HR@10 and
+106.7% NDCG@10 improvement over the state-of-the-art baseline on the Home
domain, and +22.1% HR@10 on the Electronics domain. GRACE also reduces
attention computation by up to 48% with long sequences.

</details>


### [174] [FastLongSpeech: Enhancing Large Speech-Language Models for Efficient Long-Speech Processing](https://arxiv.org/abs/2507.14815)
*Shoutao Guo,Shaolei Zhang,Qingkai Fang,Zhengrui Ma,Min Zhang,Yang Feng*

Main category: cs.CL

TL;DR: FastLongSpeech框架通过迭代融合和动态压缩训练，解决了LSLMs处理长语音的挑战，无需专用长语音训练数据，并在LongSpeech-Eval基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有LSLMs主要关注短语音任务，长语音处理因数据稀缺和计算成本高而未被充分探索。

Method: 引入FastLongSpeech框架，采用迭代融合策略压缩长语音序列，并通过动态压缩训练适应长语音输入。

Result: 实验表明，FastLongSpeech在长语音和短语音任务中均表现优异，同时显著提升推理效率。

Conclusion: FastLongSpeech为LSLMs高效处理长语音提供了可行方案，填补了研究空白。

Abstract: The rapid advancement of Large Language Models (LLMs) has spurred significant
progress in Large Speech-Language Models (LSLMs), enhancing their capabilities
in both speech understanding and generation. While existing LSLMs often
concentrate on augmenting speech generation or tackling a diverse array of
short-speech tasks, the efficient processing of long-form speech remains a
critical yet underexplored challenge. This gap is primarily attributed to the
scarcity of long-speech training datasets and the high computational costs
associated with long sequences. To address these limitations, we introduce
FastLongSpeech, a novel framework designed to extend LSLM capabilities for
efficient long-speech processing without necessitating dedicated long-speech
training data. FastLongSpeech incorporates an iterative fusion strategy that
can compress excessively long-speech sequences into manageable lengths. To
adapt LSLMs for long-speech inputs, it introduces a dynamic compression
training approach, which exposes the model to short-speech sequences at varying
compression ratios, thereby transferring the capabilities of LSLMs to
long-speech tasks. To assess the long-speech capabilities of LSLMs, we develop
a long-speech understanding benchmark called LongSpeech-Eval. Experiments show
that our method exhibits strong performance in both long-speech and
short-speech tasks, while greatly improving inference efficiency.

</details>


### [175] [Doc2Chart: Intent-Driven Zero-Shot Chart Generation from Documents](https://arxiv.org/abs/2507.14819)
*Akriti Jain,Pritika Ramu,Aparna Garimella,Apoorv Saxena*

Main category: cs.CL

TL;DR: 论文提出了一种基于意图从文档生成图表的无监督两阶段框架，通过LLM提取信息并验证，再选择图表类型生成代码，优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 解决从长文档基于用户意图生成图表的现实问题，而非用户手动选择相关内容。

Method: 两阶段框架：1) LLM分解意图并提取验证数据；2) 启发式模块选择图表类型并生成代码。

Result: 在金融和科学领域的数据集上，图表数据准确性和类型选择分别优于基线9和17个百分点。

Conclusion: 提出的方法在零样本设置下有效，且通过结构化文本评估指标提高了数据准确性。

Abstract: Large Language Models (LLMs) have demonstrated strong capabilities in
transforming text descriptions or tables to data visualizations via
instruction-tuning methods. However, it is not straightforward to apply these
methods directly for a more real-world use case of visualizing data from long
documents based on user-given intents, as opposed to the user pre-selecting the
relevant content manually. We introduce the task of intent-based chart
generation from documents: given a user-specified intent and document(s), the
goal is to generate a chart adhering to the intent and grounded on the
document(s) in a zero-shot setting. We propose an unsupervised, two-staged
framework in which an LLM first extracts relevant information from the
document(s) by decomposing the intent and iteratively validates and refines
this data. Next, a heuristic-guided module selects an appropriate chart type
before final code generation. To assess the data accuracy of the generated
charts, we propose an attribution-based metric that uses a structured textual
representation of charts, instead of relying on visual decoding metrics that
often fail to capture the chart data effectively. To validate our approach, we
curate a dataset comprising of 1,242 $<$intent, document, charts$>$ tuples from
two domains, finance and scientific, in contrast to the existing datasets that
are largely limited to parallel text descriptions/ tables and their
corresponding charts. We compare our approach with baselines using single-shot
chart generation using LLMs and query-based retrieval methods; our method
outperforms by upto $9$ points and $17$ points in terms of chart data accuracy
and chart type respectively over the best baselines.

</details>


### [176] [Beyond Isolated Capabilities: Bridging Long CoT Reasoning and Long-Context Understanding](https://arxiv.org/abs/2507.14849)
*Yifei Wang*

Main category: cs.CL

TL;DR: 推理蒸馏能提升小语言模型的推理能力，但对检索与推理能力的影响尚不明确。本文通过实验证明，蒸馏能显著改善长上下文理解，解决“迷失在中部”问题。


<details>
  <summary>Details</summary>
Motivation: 研究大规模推理蒸馏对检索增强生成（RAG）系统中上下文检索与推理能力的影响，填补这一空白。

Method: 使用从Deepseek-R1蒸馏的开源模型，通过多文档问答任务评估长上下文理解能力。

Result: 蒸馏显著提升长上下文理解，促进更详细的推理过程，缓解“迷失在中部”问题。

Conclusion: 推理蒸馏能有效增强长上下文理解能力，为RAG系统提供更可靠的响应生成。

Abstract: Reasoning distillation has emerged as an effective approach to enhance the
reasoning capabilities of smaller language models. However, the impact of
large-scale reasoning distillation on other critical abilities, particularly
in-context retrieval and reasoning, remains unexplored. This gap in
understanding is particularly significant given the increasing importance of
Retrieval-Augmented Generation (RAG) systems, where efficient acquisition and
utilization of contextual information are paramount for generating reliable
responses. Motivated by the need to understand how the extended long-CoT
process influences long-context comprehension, we conduct a comprehensive
investigation using a series of open-source models distilled from Deepseek-R1,
renowned for its exceptional reasoning capabilities. Our study focuses on
evaluating these models' performance in extracting and integrating relevant
information from extended contexts through multi-document question and
answering tasks. Through rigorous experimentation, we demonstrate that
distilled reasoning patterns significantly improve long-context understanding.
Our analysis reveals that distillation fosters greater long-context awareness
by promoting more detailed and explicit reasoning processes during context
analysis and information parsing. This advancement effectively mitigates the
persistent "lost in the middle" issue that has hindered long-context models.

</details>


### [177] [Tiny language models](https://arxiv.org/abs/2507.14871)
*Ronit D. Gross,Yarden Tzach,Tal Halevi,Ella Koresh,Ido Kanter*

Main category: cs.CL

TL;DR: 研究表明，即使是小型语言模型（TLMs）也能通过预训练展现出与大型语言模型（LLMs）相似的关键性能，且预训练效果随数据集规模和任务重叠度增加而提升。


<details>
  <summary>Details</summary>
Motivation: 由于大型语言模型（LLMs）预训练需要巨大计算资源，限制了广泛研究参与，因此探索小型语言模型（TLMs）是否具备类似性能成为关键需求。

Method: 通过预训练BERT-6及其变体（如BERT-1）在Wikipedia子集上，并在FewRel、AGNews和DBPedia分类任务中评估性能。

Result: 预训练的TLMs在分类任务中表现显著优于未预训练模型，且通过多个浅层模型的软组合可实现低延迟而不损失准确性。

Conclusion: TLMs的预训练效果显著，未来研究可能揭示其与人类语言习得机制的关联。

Abstract: A prominent achievement of natural language processing (NLP) is its ability
to understand and generate meaningful human language. This capability relies on
complex feedforward transformer block architectures pre-trained on large
language models (LLMs). However, LLM pre-training is currently feasible only
for a few dominant companies due to the immense computational resources
required, limiting broader research participation. This creates a critical need
for more accessible alternatives. In this study, we explore whether tiny
language models (TLMs) exhibit the same key qualitative features of LLMs. We
demonstrate that TLMs exhibit a clear performance gap between pre-trained and
non-pre-trained models across classification tasks, indicating the
effectiveness of pre-training, even at a tiny scale. The performance gap
increases with the size of the pre-training dataset and with greater overlap
between tokens in the pre-training and classification datasets. Furthermore,
the classification accuracy achieved by a pre-trained deep TLM architecture can
be replicated through a soft committee of multiple, independently pre-trained
shallow architectures, enabling low-latency TLMs without affecting
classification accuracy. Our results are based on pre-training BERT-6 and
variants of BERT-1 on subsets of the Wikipedia dataset and evaluating their
performance on FewRel, AGNews, and DBPedia classification tasks. Future
research on TLM is expected to further illuminate the mechanisms underlying
NLP, especially given that its biologically inspired models suggest that TLMs
may be sufficient for children or adolescents to develop language.

</details>


### [178] [MEKiT: Multi-source Heterogeneous Knowledge Injection Method via Instruction Tuning for Emotion-Cause Pair Extraction](https://arxiv.org/abs/2507.14887)
*Shiyi Mu,Yongkang Liu,Shi Feng,Xiaocui Yang,Daling Wang,Yifei Zhang*

Main category: cs.CL

TL;DR: MEKiT方法通过整合内部情感知识和外部因果知识，显著提升了大型语言模型在情感-原因对提取任务（ECPE）中的表现。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在情感-原因对提取任务中表现不佳，主要原因是缺乏辅助知识，限制了其感知情感和推理原因的能力。

Method: 提出MEKiT方法，结合内部情感知识和外部因果知识，通过指令模板和数据混合进行指令调优，以全面识别情感和准确推理原因。

Result: 实验表明，MEKiT在ECPE任务中表现优于基线模型，显著提升了LLMs的性能。

Conclusion: MEKiT为ECPE任务提供了更有效和适应性强的解决方案。

Abstract: Although large language models (LLMs) excel in text comprehension and
generation, their performance on the Emotion-Cause Pair Extraction (ECPE) task,
which requires reasoning ability, is often underperform smaller language model.
The main reason is the lack of auxiliary knowledge, which limits LLMs' ability
to effectively perceive emotions and reason causes. To address this issue, we
propose a novel \textbf{M}ulti-source h\textbf{E}terogeneous \textbf{K}nowledge
\textbf{i}njection me\textbf{T}hod, MEKiT, which integrates heterogeneous
internal emotional knowledge and external causal knowledge. Specifically, for
these two distinct aspects and structures of knowledge, we apply the approaches
of incorporating instruction templates and mixing data for instruction-tuning,
which respectively facilitate LLMs in more comprehensively identifying emotion
and accurately reasoning causes. Experimental results demonstrate that MEKiT
provides a more effective and adaptable solution for the ECPE task, exhibiting
an absolute performance advantage over compared baselines and dramatically
improving the performance of LLMs on the ECPE task.

</details>


### [179] [Sparse Autoencoder-guided Supervised Finetuning to Mitigate Unexpected Code-Switching in LLMs](https://arxiv.org/abs/2507.14894)
*Boyi Deng,Yu Wan,Baosong Yang,Fei Huang,Wenjie Wang,Fuli Feng*

Main category: cs.CL

TL;DR: 论文提出SASFT方法，通过稀疏自编码器分析预激活值，减少大语言模型中的意外代码切换问题，效果显著且不影响多语言能力。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）在多语言任务中表现优异，但存在意外代码切换问题，影响模型输出的可读性和实用性。现有方法缺乏机制分析且效果有限。

Method: 使用稀疏自编码器分析语言特征的预激活值，提出SASFT方法（稀疏自编码器引导的监督微调），通过训练控制特定语言特征的预激活值。

Result: 在五种模型和三种语言上的实验表明，SASFT将意外代码切换减少50%以上，四种情况下完全消除，同时保持或提升多语言基准性能。

Conclusion: SASFT有效解决了代码切换问题，同时保持LLMs的多语言能力，为模型优化提供了新思路。

Abstract: Large Language Models (LLMs) have impressive multilingual capabilities, but
they suffer from unexpected code-switching, also known as language mixing,
which involves switching to unexpected languages in the model response. This
problem leads to poor readability and degrades the usability of model
responses. However, existing work on this issue lacks a mechanistic analysis
and shows limited effectiveness. In this paper, we first provide an in-depth
analysis of unexpected code-switching using sparse autoencoders and find that
when LLMs switch to a language, the features of that language exhibit excessive
pre-activation values. Based on our findings, we propose $\textbf{S}$parse
$\textbf{A}$utoencoder-guided $\textbf{S}$upervised
$\textbf{F}$ine$\textbf{t}$uning (SASFT), which teaches LLMs to maintain
appropriate pre-activation values of specific language features during
training. Experiments on five models across three languages demonstrate that
SASFT consistently reduces unexpected code-switching by more than 50\% compared
to standard supervised fine-tuning, with complete elimination in four cases.
Moreover, SASFT maintains or even improves the models' performance on six
multilingual benchmarks, showing its effectiveness in addressing code-switching
while preserving multilingual capabilities.

</details>


### [180] [From Neurons to Semantics: Evaluating Cross-Linguistic Alignment Capabilities of Large Language Models via Neurons Alignment](https://arxiv.org/abs/2507.14900)
*Chongxuan Huang,Yongshi Ye,Biao Fu,Qifeng Su,Xiaodong Shi*

Main category: cs.CL

TL;DR: 提出了一种基于神经元状态的跨语言对齐评估方法（NeuronXA），用于评估大语言模型的跨语言对齐能力，效果显著。


<details>
  <summary>Details</summary>
Motivation: 现有跨语言对齐评估方法主要关注句子嵌入，但神经网络模型可能产生非平滑表示空间，影响低资源语言的语义对齐评估。

Method: 受神经科学启发，提出NeuronXA方法，通过神经元状态评估跨语言对齐能力。

Result: 在多个多语言大语言模型上测试，仅需100对平行句子，NeuronXA与下游任务性能的Pearson相关系数达0.9556，与可迁移性的相关系数为0.8514。

Conclusion: NeuronXA能有效评估跨语言对齐和可迁移性，即使数据量小，有望推动跨语言对齐研究和多语言大语言模型的语义理解。

Abstract: Large language models (LLMs) have demonstrated remarkable multilingual
capabilities, however, how to evaluate cross-lingual alignment remains
underexplored. Existing alignment benchmarks primarily focus on sentence
embeddings, but prior research has shown that neural models tend to induce a
non-smooth representation space, which impact of semantic alignment evaluation
on low-resource languages. Inspired by neuroscientific findings that similar
information activates overlapping neuronal regions, we propose a novel Neuron
State-Based Cross-Lingual Alignment (NeuronXA) to assess the cross-lingual a
lignment capabilities of LLMs, which offers a more semantically grounded
approach to assess cross-lingual alignment. We evaluate NeuronXA on several
prominent multilingual LLMs (LLaMA, Qwen, Mistral, GLM, and OLMo) across two
transfer tasks and three multilingual benchmarks. The results demonstrate that
with only 100 parallel sentence pairs, NeuronXA achieves a Pearson correlation
of 0.9556 with downstream tasks performance and 0.8514 with transferability.
These findings demonstrate NeuronXA's effectiveness in assessing both
cross-lingual alignment and transferability, even with a small dataset. This
highlights its potential to advance cross-lingual alignment research and to
improve the semantic understanding of multilingual LLMs.

</details>


### [181] [PromptSuite: A Task-Agnostic Framework for Multi-Prompt Generation](https://arxiv.org/abs/2507.14913)
*Eliya Habba,Noam Dahan,Gili Lior,Gabriel Stanovsky*

Main category: cs.CL

TL;DR: PromptSuite是一个自动生成多样化提示的框架，用于更可靠的LLM评估。


<details>
  <summary>Details</summary>
Motivation: 单一提示评估LLM不可靠，需要多提示评估但生成提示变体困难。

Method: 采用模块化提示设计，支持可控扰动和新组件扩展。

Result: PromptSuite能生成有意义的提示变体，支持强健的评估实践。

Conclusion: PromptSuite通过Python API和Web界面提供灵活、可扩展的解决方案。

Abstract: Evaluating LLMs with a single prompt has proven unreliable, with small
changes leading to significant performance differences. However, generating the
prompt variations needed for a more robust multi-prompt evaluation is
challenging, limiting its adoption in practice. To address this, we introduce
PromptSuite, a framework that enables the automatic generation of various
prompts. PromptSuite is flexible - working out of the box on a wide range of
tasks and benchmarks. It follows a modular prompt design, allowing controlled
perturbations to each component, and is extensible, supporting the addition of
new components and perturbation types. Through a series of case studies, we
show that PromptSuite provides meaningful variations to support strong
evaluation practices. It is available through both a Python API:
https://github.com/eliyahabba/PromptSuite, and a user-friendly web interface:
https://promptsuite.streamlit.app/

</details>


### [182] [SYNTHIA: Synthetic Yet Naturally Tailored Human-Inspired PersonAs](https://arxiv.org/abs/2507.14922)
*Vahid Rahimzadeh,Erfan Moosavi Monazzah,Mohammad Taher Pilehvar,Yadollah Yaghoobzadeh*

Main category: cs.CL

TL;DR: SYNTHIA是一个基于真实社交媒体用户活动的数据集，解决了现有方法在成本与真实性之间的极端问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么依赖高成本人工数据，要么生成缺乏一致性和真实性的合成角色，SYNTHIA旨在填补这一空白。

Method: 利用BlueSky开放平台上10,000名真实用户的30,000个背景故事，结合时间维度和社交互动元数据生成合成角色。

Result: SYNTHIA在人口多样性和社会调查对齐方面表现优异，同时在叙事一致性上显著优于现有方法。

Conclusion: SYNTHIA为计算社会科学和角色驱动语言建模提供了新的研究方向。

Abstract: Persona-driven LLMs have emerged as powerful tools in computational social
science, yet existing approaches fall at opposite extremes, either relying on
costly human-curated data or producing synthetic personas that lack consistency
and realism. We introduce SYNTHIA, a dataset of 30,000 backstories derived from
10,000 real social media users from BlueSky open platform across three time
windows, bridging this spectrum by grounding synthetic generation in authentic
user activity. Our evaluation demonstrates that SYNTHIA achieves competitive
performance with state-of-the-art methods in demographic diversity and social
survey alignment while significantly outperforming them in narrative
consistency. Uniquely, SYNTHIA incorporates temporal dimensionality and
provides rich social interaction metadata from the underlying network, enabling
new research directions in computational social science and persona-driven
language modeling.

</details>


### [183] [MUR: Momentum Uncertainty guided Reasoning for Large Language Models](https://arxiv.org/abs/2507.14958)
*Hang Yan,Fangzhi Xu,Rongman Xu,Yifei Li,Jian Zhang,Haoran Luo,Xiaobao Wu,Luu Anh Tuan,Haiteng Zhao,Qika Lin,Jun Liu*

Main category: cs.CL

TL;DR: MUR（Momentum Uncertainty-guided Reasoning）是一种动态分配推理预算的方法，通过跟踪和聚合步骤不确定性，显著减少计算量并提升准确性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在推理任务中表现优异，但推理效率优化仍具挑战性。现有方法如Test-Time Scaling（TTS）可能导致过度计算。

Method: 提出MUR方法，受物理学动量概念启发，动态分配推理预算，并引入gamma-control机制灵活调控预算。

Result: 在四个基准测试中，MUR平均减少50%以上计算量，同时提升准确性0.62-3.37%。

Conclusion: MUR通过动态预算分配，显著优化LLMs推理效率，无需额外训练。

Abstract: Large Language Models (LLMs) have achieved impressive performance on
reasoning-intensive tasks, yet optimizing their reasoning efficiency remains an
open challenge. While Test-Time Scaling (TTS) improves reasoning quality, it
often leads to overthinking, wasting tokens on redundant computations. This
work investigates how to efficiently and adaptively guide LLM test-time scaling
without additional training. Inspired by the concept of momentum in physics, we
propose Momentum Uncertainty-guided Reasoning (MUR), which dynamically
allocates thinking budgets to critical reasoning steps by tracking and
aggregating stepwise uncertainty over time. To support flexible inference-time
control, we introduce gamma-control, a simple mechanism that tunes the
reasoning budget via a single hyperparameter. We provide in-depth theoretical
proof to support the superiority of MUR in terms of stability and biases. MUR
is comprehensively evaluated against various TTS methods across four
challenging benchmarks (MATH-500, AIME24, AIME25, and GPQA-diamond) using
different sizes of recent Qwen3 models (1.7B, 4B, and 8B). Results demonstrate
that MUR reduces computation by over 50% on average while improving accuracy by
0.62-3.37%.

</details>


### [184] [RefCritic: Training Long Chain-of-Thought Critic Models with Refinement Feedback](https://arxiv.org/abs/2507.15024)
*Qiaoyu Tang,Hao Xiang,Le Yu,Bowen Yu,Hongyu Lin,Yaojie Lu,Xianpei Han,Le Sun,Junyang Lin*

Main category: cs.CL

TL;DR: 本文提出RefCritic，一种基于强化学习的批评模块，通过双规则奖励提升模型批评能力，显著优于现有监督微调方法。


<details>
  <summary>Details</summary>
Motivation: 现有监督微调方法无法真正提升模型的批评能力，生成的批评缺乏深度和验证。

Method: 提出RefCritic，采用强化学习框架，结合实例级正确性和策略模型改进精度作为奖励，生成高质量批评。

Result: 在多个基准测试中表现优异，如AIME25上分别提升6.8%和7.2%，且在多数投票下表现更优。

Conclusion: RefCritic在批评和指导模型改进方面具有显著优势，优于传统监督方法。

Abstract: With the rapid advancement of Large Language Models (LLMs), developing
effective critic modules for precise guidance has become crucial yet
challenging. In this paper, we initially demonstrate that supervised
fine-tuning for building critic modules (which is widely adopted in current
solutions) fails to genuinely enhance models' critique abilities, producing
superficial critiques with insufficient reflections and verifications. To
unlock the unprecedented critique capabilities, we propose RefCritic, a
long-chain-of-thought critic module based on reinforcement learning with dual
rule-based rewards: (1) instance-level correctness of solution judgments and
(2) refinement accuracies of the policy model based on critiques, aiming to
generate high-quality evaluations with actionable feedback that effectively
guides model refinement. We evaluate RefCritic on Qwen2.5-14B-Instruct and
DeepSeek-R1-Distill-Qwen-14B across five benchmarks. On critique and refinement
settings, RefCritic demonstrates consistent advantages across all benchmarks,
e.g., 6.8\% and 7.2\% gains on AIME25 for the respective base models. Notably,
under majority voting, policy models filtered by RefCritic show superior
scaling with increased voting numbers. Moreover, despite training on
solution-level supervision, RefCritic outperforms step-level supervised
approaches on ProcessBench, a benchmark to identify erroneous steps in
mathematical reasoning.

</details>


### [185] [WebShaper: Agentically Data Synthesizing via Information-Seeking Formalization](https://arxiv.org/abs/2507.15061)
*Zhengwei Tao,Jialong Wu,Wenbiao Yin,Junkai Zhang,Baixuan Li,Haiyang Shen,Kuan Li,Liwen Zhang,Xinyu Wang,Yong Jiang,Pengjun Xie,Fei Huang,Jingren Zhou*

Main category: cs.CL

TL;DR: 论文提出了一种基于形式化驱动的信息搜索（IS）数据合成框架WebShaper，通过知识投影（KP）控制推理结构，生成高质量数据集，提升了IS代理的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在生成信息搜索数据时存在信息结构与推理结构不一致的问题，限制了IS代理的发展。

Method: 提出WebShaper框架，通过集合论形式化IS任务，利用知识投影（KP）操作组合控制推理结构，并通过多步扩展过程合成数据集。

Result: 实验表明，WebShaper在GAIA和WebWalkerQA基准测试中达到了开源IS代理的最先进性能。

Conclusion: WebShaper通过形式化驱动的方法有效解决了数据质量问题，显著提升了IS代理的性能。

Abstract: The advent of Large Language Model (LLM)-powered agents has revolutionized
artificial intelligence by enabling solutions to complex, open-ended tasks
through web-based information-seeking (IS) capabilities. The scarcity of
high-quality training data has limited the development of IS agents. Existing
approaches typically adopt an information-driven paradigm that first collects
web data and then generates questions based on the retrieval. However, this may
lead to inconsistency between information structure and reasoning structure,
question and answer. To mitigate, we propose a formalization-driven IS data
synthesis framework WebShaper to construct a dataset. WebShaper systematically
formalizes IS tasks through set theory. Central to the formalization is the
concept of Knowledge Projections (KP), which enables precise control over
reasoning structure by KP operation compositions. During synthesis, we begin by
creating seed tasks, then use a multi-step expansion process. At each step, an
agentic Expander expands the current formal question more complex with
retrieval and validation tools based on our formalization. We train our model
on the synthesized dataset. Experiment results demonstrate that WebShaper
achieves state-of-the-art performance among open-sourced IS agents on GAIA and
WebWalkerQA benchmarks.

</details>


### [186] [Evaluation of Coding Schemes for Transformer-based Gene Sequence Modeling](https://arxiv.org/abs/2507.15087)
*Chenlei Gong,Yuanhe Tian,Lei Mao,Yan Song*

Main category: cs.CL

TL;DR: 比较了DNA序列建模中k-mer分割与BPE子词标记化的性能，发现BPE表现更优，同时评估了不同位置编码方法和模型深度的影响。


<details>
  <summary>Details</summary>
Motivation: 缺乏对DNA序列建模中不同标记化和位置编码方法的系统评估，需明确哪种方法更优。

Method: 比较k-mer分割（k=1,3,4,5,6）、BPE子词标记化及三种位置编码方法（sinusoidal、AliBi、RoPE），在不同层数的Transformer编码器上进行训练和评估。

Result: BPE表现更优，RoPE擅长周期性模式，AliBi适合局部依赖任务。模型深度在3到12层时性能显著提升，24层时可能过拟合。

Conclusion: 为DNA Transformer模型的标记化和位置编码设计提供了实用指导。

Abstract: Currently, many studies view DNA sequences as a special type of language and
utilize Transformers to model them. These studies use fixed-length k-mer
segmentation and BPE subword tokenization but lack a systematic evaluation to
determine which is superior. We compare k-mer segmentation with k=1,3,4,5,6, a
4,096-token BPE vocabulary, and three positional encoding methods-sinusoidal,
AliBi, and RoPE. Each configuration is trained from scratch in 3, 6, 12, and
24-layer Transformer encoders and evaluated on GUE benchmark dataset. In
general, BPE delivers higher and more stable performance across tasks by
compressing frequent motifs into variable-length tokens, reducing sequence
length, and improving model generalization. RoPE excels at capturing periodic
motifs and extrapolating to long sequences, while AliBi also performs well on
tasks driven by local dependencies. In terms of depth, we observe significant
gains when increasing layers from 3 to 12, with only marginal improvements or
slight overfitting at 24 layers. This study provides practical guidance for
designing tokenization and positional encoding in DNA Transformer models.

</details>


### [187] [A Penalty Goes a Long Way: Measuring Lexical Diversity in Synthetic Texts Under Prompt-Influenced Length Variations](https://arxiv.org/abs/2507.15092)
*Vijeta Deshpande,Ishita Dasgupta,Uttaran Bhattacharya,Somdeb Sarkhel,Saayan Mitra,Anna Rumshisky*

Main category: cs.CL

TL;DR: 提出了一种新的词汇多样性度量方法PATTR，能够有效减少文本长度对多样性评估的偏差，并在实验中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 研究提示变化对生成文本长度及词汇多样性测量的影响，现有方法未充分解决长度偏差问题。

Method: 提出PATTR度量方法，基于任务目标长度调整多样性评分，生成20M词的合成语料进行验证。

Result: PATTR在过滤高多样性响应时表现优于MATTR和CR，且能更好地保持目标长度。

Conclusion: PATTR是一种鲁棒的多样性度量方法，适用于需要控制文本长度的任务。

Abstract: Synthetic text generated by Large Language Models (LLMs) is increasingly used
for further training and improvement of LLMs. Diversity is crucial for the
effectiveness of synthetic data, and researchers rely on prompt engineering to
improve diversity. However, the impact of prompt variations on response text
length, and, more importantly, the consequential effect on lexical diversity
measurements, remain underexplored. In this work, we propose Penalty-Adjusted
Type-Token Ratio (PATTR), a diversity metric robust to length variations. We
generate a large synthetic corpus of over 20M words using seven models from the
LLaMA, OLMo, and Phi families, focusing on a creative writing task of video
script generation, where diversity is crucial. We evaluate per-response lexical
diversity using PATTR and compare it against existing metrics of Moving-Average
TTR (MATTR) and Compression Ratio (CR). Our analysis highlights how text length
variations introduce biases favoring shorter responses. Unlike existing
metrics, PATTR explicitly considers the task-specific target response length
($L_T$) to effectively mitigate length biases. We further demonstrate the
utility of PATTR in filtering the top-10/100/1,000 most lexically diverse
responses, showing that it consistently outperforms MATTR and CR by yielding on
par or better diversity with high adherence to $L_T$.

</details>


### [188] [Filling the Gap: Is Commonsense Knowledge Generation useful for Natural Language Inference?](https://arxiv.org/abs/2507.15100)
*Chathuri Jayaweera,Brianna Yanqui,Bonnie Dorr*

Main category: cs.CL

TL;DR: 研究探讨了大型语言模型（LLM）作为常识知识生成器在自然语言推理（NLI）任务中的潜力，评估其生成知识的可靠性和对预测准确性的影响。


<details>
  <summary>Details</summary>
Motivation: 现有常识资源对多种前提-假设对的覆盖不足，需探索LLM作为补充。

Method: 调整和修改现有指标，评估LLM生成常识知识的真实性和一致性。

Result: 显式引入常识知识虽未显著提升整体结果，但能有效区分蕴含实例，并适度改善矛盾和中立推理的区分。

Conclusion: LLM在NLI任务中生成常识知识具有一定潜力，但需进一步优化以提高一致性。

Abstract: Natural Language Inference (NLI) is the task of determining the semantic
entailment of a premise for a given hypothesis. The task aims to develop
systems that emulate natural human inferential processes where commonsense
knowledge plays a major role. However, existing commonsense resources lack
sufficient coverage for a variety of premise-hypothesis pairs. This study
explores the potential of Large Language Models as commonsense knowledge
generators for NLI along two key dimensions: their reliability in generating
such knowledge and the impact of that knowledge on prediction accuracy. We
adapt and modify existing metrics to assess LLM factuality and consistency in
generating in this context. While explicitly incorporating commonsense
knowledge does not consistently improve overall results, it effectively helps
distinguish entailing instances and moderately improves distinguishing
contradictory and neutral inferences.

</details>


### [189] [From Disagreement to Understanding: The Case for Ambiguity Detection in NLI](https://arxiv.org/abs/2507.15114)
*Chathuri Jayaweera,Bonnie Dorr*

Main category: cs.CL

TL;DR: 论文主张NLI中的标注分歧并非噪音，而是反映了有意义的解释差异，尤其是由前提或假设的模糊性引发时。提出模糊感知的NLI框架，并呼吁标注模糊性数据集以改进模型。


<details>
  <summary>Details</summary>
Motivation: NLI中的标注分歧常被忽视或视为噪音，但实际反映了人类解释的多样性，尤其是由内容模糊性引发时。

Method: 提出统一框架整合现有分类法，通过具体示例展示模糊性子类型，并呼吁开发模糊性标注数据集和无监督检测方法。

Result: 模糊性显著影响标注者决策，需针对性检测方法以更好对齐模型与人类解释。

Conclusion: 需标注模糊性数据集和改进检测方法，以实现更鲁棒、可解释且与人类对齐的NLI系统。

Abstract: This position paper argues that annotation disagreement in Natural Language
Inference (NLI) is not mere noise but often reflects meaningful interpretive
variation, especially when triggered by ambiguity in the premise or hypothesis.
While underspecified guidelines and annotator behavior can contribute to
variation, content-based ambiguity offers a process-independent signal of
divergent human perspectives. We call for a shift toward ambiguity-aware NLI by
systematically identifying ambiguous input pairs and classifying ambiguity
types. To support this, we present a unified framework that integrates existing
taxonomies and illustrate key ambiguity subtypes through concrete examples.
These examples reveal how ambiguity shapes annotator decisions and motivate the
need for targeted detection methods that better align models with human
interpretation. A key limitation is the lack of datasets annotated for
ambiguity and subtypes. We propose addressing this gap through new annotated
resources and unsupervised approaches to ambiguity detection -- paving the way
for more robust, explainable, and human-aligned NLI systems.

</details>


### [190] [A Case Against Implicit Standards: Homophone Normalization in Machine Translation for Languages that use the Ge'ez Script](https://arxiv.org/abs/2507.15142)
*Hellina Hailu Nigatu,Atnafu Lambebo Tonja,Henok Biadglign Ademtew,Hizkel Mitiku Alemayehu,Negasi Haile Abadi,Tadesse Destaw Belay,Seid Muhie Yimam*

Main category: cs.CL

TL;DR: 研究探讨了阿姆哈拉语NLP中同音字归一化的影响，提出了一种后推断归一化方法，以提升性能同时保留语言特征。


<details>
  <summary>Details</summary>
Motivation: 同音字归一化虽能提升自动指标性能，但可能导致模型无法理解语言多样性，并影响跨语言迁移学习。

Method: 通过单语训练和跨语言迁移实验，研究归一化对Ge'ez脚本语言的影响，并提出后推断归一化方案。

Result: 后推断归一化使BLEU分数提升1.03，同时保留训练中的语言特征。

Conclusion: 研究呼吁更多语言感知的干预措施，为技术驱动的语言变化讨论提供贡献。

Abstract: Homophone normalization, where characters that have the same sound in a
writing script are mapped to one character, is a pre-processing step applied in
Amharic Natural Language Processing (NLP) literature. While this may improve
performance reported by automatic metrics, it also results in models that are
not able to understand different forms of writing in a single language.
Further, there might be impacts in transfer learning, where models trained on
normalized data do not generalize well to other languages. In this paper, we
experiment with monolingual training and cross-lingual transfer to understand
the impacts of normalization on languages that use the Ge'ez script. We then
propose a post-inference intervention in which normalization is applied to
model predictions instead of training data. With our simple scheme of
post-inference normalization, we show that we can achieve an increase in BLEU
score of up to 1.03 while preserving language features in training. Our work
contributes to the broader discussion on technology-facilitated language change
and calls for more language-aware interventions.

</details>


### [191] [What Level of Automation is "Good Enough"? A Benchmark of Large Language Models for Meta-Analysis Data Extraction](https://arxiv.org/abs/2507.15152)
*Lingbo Li,Anuradha Mathrani,Teo Susnjak*

Main category: cs.CL

TL;DR: 评估三种LLM在医学领域数据提取任务中的表现，发现定制提示最有效，并提出三层自动化指南。


<details>
  <summary>Details</summary>
Motivation: 自动化从RCTs中提取数据用于荟萃分析仍具挑战性，需评估LLMs的实际表现。

Method: 测试三种LLM（Gemini-2.0-flash、Grok-3、GPT-4o-mini）在高血压、糖尿病和骨科领域的统计结果、偏倚风险评估和研究特征提取任务，采用四种提示策略。

Result: 模型精度高但召回率低，定制提示可提升召回率15%。

Conclusion: 提出三层自动化指南，平衡LLM效率与专家监督，适用于实际荟萃分析。

Abstract: Automating data extraction from full-text randomised controlled trials (RCTs)
for meta-analysis remains a significant challenge. This study evaluates the
practical performance of three LLMs (Gemini-2.0-flash, Grok-3, GPT-4o-mini)
across tasks involving statistical results, risk-of-bias assessments, and
study-level characteristics in three medical domains: hypertension, diabetes,
and orthopaedics. We tested four distinct prompting strategies (basic
prompting, self-reflective prompting, model ensemble, and customised prompts)
to determine how to improve extraction quality. All models demonstrate high
precision but consistently suffer from poor recall by omitting key information.
We found that customised prompts were the most effective, boosting recall by up
to 15\%. Based on this analysis, we propose a three-tiered set of guidelines
for using LLMs in data extraction, matching data types to appropriate levels of
automation based on task complexity and risk. Our study offers practical advice
for automating data extraction in real-world meta-analyses, balancing LLM
efficiency with expert oversight through targeted, task-specific automation.

</details>


### [192] [Collaborative Distillation Strategies for Parameter-Efficient Language Model Deployment](https://arxiv.org/abs/2507.15198)
*Xiandong Meng,Yan Wu,Yexin Tian,Xin Hu,Tianze Kang,Junliang Du*

Main category: cs.CL

TL;DR: 提出了一种基于多教师模型的知识蒸馏方法，降低大语言模型的部署成本并提升推理速度。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型计算成本高和推理速度慢的问题。

Method: 构建多个教师模型，融合其输出概率分布和中间语义特征，通过加权输出融合、特征对齐损失函数和动态教师权重策略指导学生模型学习。

Result: 学生模型在语言理解和生成能力上表现优异，同时在困惑度、蒸馏损失和生成质量上优于其他蒸馏方法。

Conclusion: 多教师协作机制为大规模语言模型的高效压缩提供了可行技术路径。

Abstract: This paper addresses the challenges of high computational cost and slow
inference in deploying large language models. It proposes a distillation
strategy guided by multiple teacher models. The method constructs several
teacher models and integrates their output probability distributions and
intermediate semantic features. This guides the student model to learn from
multiple sources of knowledge. As a result, the student model gains stronger
language understanding and generation ability while maintaining a small
parameter size. To achieve this, the paper introduces a weighted output fusion
mechanism, a feature alignment loss function, and an entropy-driven dynamic
teacher weighting strategy. These components improve the quality and stability
of knowledge transfer during distillation. Under multi-teacher guidance, the
student model captures semantic information more effectively and demonstrates
strong performance across multiple evaluation metrics. In particular, the
method shows high consistency in expression, generalization ability, and task
adaptability in tasks such as language modeling, text generation, and
multi-task learning. The experiments compare the proposed method with several
widely adopted distillation approaches. The results further confirm its overall
advantages in perplexity, distillation loss, and generation quality. This study
provides a feasible technical path for the efficient compression of large-scale
language models. It also demonstrates the effectiveness of multi-teacher
collaborative mechanisms in complex language modeling tasks.

</details>


### [193] [SOI Matters: Analyzing Multi-Setting Training Dynamics in Pretrained Language Models via Subsets of Interest](https://arxiv.org/abs/2507.15236)
*Shayan Vassef,Amirhossein Dabiriaghdam,Mohammadreza Bakhtiari,Yadollah Yaghoobzadeh*

Main category: cs.CL

TL;DR: 研究多任务、多语言和多源学习对预训练语言模型鲁棒性和性能的影响，引入SOI框架分析学习行为模式，并通过实验验证多源学习显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 探讨多任务、多语言和多源学习对语言模型性能的影响，提出SOI框架以更细致地分析学习行为。

Method: 引入SOI框架，通过热图和数据集可视化分析学习行为变化，进行多任务、多源和多语言的对比实验。

Result: 多源学习提升分布外性能7%，多任务学习在相似任务组合中表现突出，两阶段微调进一步优化性能。

Conclusion: 多源学习效果显著，SOI框架为优化多设置语言模型提供了新思路。

Abstract: This work investigates the impact of multi-task, multi-lingual, and
multi-source learning approaches on the robustness and performance of
pretrained language models. To enhance this analysis, we introduce Subsets of
Interest (SOI), a novel categorization framework that identifies six distinct
learning behavior patterns during training, including forgettable examples,
unlearned examples, and always correct examples. Through SOI transition
heatmaps and dataset cartography visualization, we analyze how examples shift
between these categories when transitioning from single-setting to
multi-setting configurations. We perform comprehensive experiments across three
parallel comparisons: multi-task vs. single-task learning using English tasks
(entailment, paraphrase, sentiment), multi-source vs. single-source learning
using sentiment analysis datasets, and multi-lingual vs. single-lingual
learning using intent classification in French, English, and Persian. Our
results demonstrate that multi-source learning consistently improves
out-of-distribution performance by up to 7%, while multi-task learning shows
mixed results with notable gains in similar task combinations. We further
introduce a two-stage fine-tuning approach where the second stage leverages
SOI-based subset selection to achieve additional performance improvements.
These findings provide new insights into training dynamics and offer practical
approaches for optimizing multi-setting language model performance.

</details>


### [194] [ChiMed 2.0: Advancing Chinese Medical Dataset in Facilitating Large Language Modeling](https://arxiv.org/abs/2507.15275)
*Yuanhe Tian,Junjie Liu,Zhizhou Kou,Yuxiang Li,Yan Song*

Main category: cs.CL

TL;DR: ChiMed 2.0是一个扩展的中文医学数据集，支持预训练、监督微调和RLHF，验证了其在训练中文医学LLM中的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有中文医学数据集规模小、领域覆盖窄，无法满足预训练需求，且大多不支持RLHF。

Method: 提出ChiMed 2.0数据集，包含预训练文档、问答对和偏好数据，并在通用LLM上进行实验验证。

Result: 实验结果显示性能提升，验证了数据集的有效性和适用性。

Conclusion: ChiMed 2.0为中文医学LLM训练提供了高质量数据资源。

Abstract: Building high-quality data resources is crucial for advancing artificial
intelligence research and applications in specific domains, particularly in the
Chinese medical domain. Existing Chinese medical datasets are limited in size
and narrow in domain coverage, falling short of the diverse corpora required
for effective pre-training. Moreover, most datasets are designed solely for LLM
fine-tuning and do not support pre-training and reinforcement learning from
human feedback (RLHF). In this paper, we propose a Chinese medical dataset
named ChiMed 2.0, which extends our previous work ChiMed, and covers data
collected from Chinese medical online platforms and generated by LLMs. ChiMed
2.0 contains 204.4M Chinese characters covering both traditional Chinese
medicine classics and modern general medical data, where there are 164.8K
documents for pre-training, 351.6K question-answering pairs for supervised
fine-tuning (SFT), and 41.7K preference data tuples for RLHF. To validate the
effectiveness of our approach for training a Chinese medical LLM, we conduct
further pre-training, SFT, and RLHF experiments on representative general
domain LLMs and evaluate their performance on medical benchmark datasets. The
results show performance gains across different model scales, validating the
dataset's effectiveness and applicability.

</details>


### [195] [A Novel Self-Evolution Framework for Large Language Models](https://arxiv.org/abs/2507.15281)
*Haoran Sun,Zekun Zhang,Shaoning Zeng*

Main category: cs.CL

TL;DR: 提出了一种名为DPSE的双阶段自进化框架，通过联合优化用户偏好适应和领域特定能力，显著提升了LLM的性能。


<details>
  <summary>Details</summary>
Motivation: 现有后训练策略（如基于记忆的检索或偏好优化）虽能改善用户对齐，但无法提升模型的领域认知能力，因此需要一种新方法填补这一空白。

Method: DPSE框架引入Censor模块提取多维交互信号并估计满意度分数，通过主题感知和偏好驱动策略扩展结构化数据，支持两阶段微调流程：监督领域基础训练和频率感知偏好优化。

Result: 实验表明，DPSE在通用NLP基准和长期对话任务中均优于监督微调、偏好优化和基于记忆的基线方法。

Conclusion: DPSE为LLM的持续自进化提供了一条自主路径，并通过消融研究验证了各模块的贡献。

Abstract: The capabilities of Large Language Models (LLMs) are limited to some extent
by pre-training, so some researchers optimize LLMs through post-training.
Existing post-training strategies, such as memory-based retrieval or preference
optimization, improve user alignment yet fail to enhance the model's domain
cognition. To bridge this gap, we propose a novel Dual-Phase Self-Evolution
(DPSE) framework that jointly optimizes user preference adaptation and
domain-specific competence. DPSE introduces a Censor module to extract
multi-dimensional interaction signals and estimate satisfaction scores, which
guide structured data expansion via topic-aware and preference-driven
strategies. These expanded datasets support a two-stage fine-tuning pipeline:
supervised domain grounding followed by frequency-aware preference
optimization. Experiments across general NLP benchmarks and long-term dialogue
tasks demonstrate that DPSE consistently outperforms Supervised Fine-Tuning,
Preference Optimization, and Memory-Augmented baselines. Ablation studies
validate the contribution of each module. In this way, our framework provides
an autonomous path toward continual self-evolution of LLMs.

</details>


### [196] [Beyond Easy Wins: A Text Hardness-Aware Benchmark for LLM-generated Text Detection](https://arxiv.org/abs/2507.15286)
*Navid Ayoobi,Sadat Shahriar,Arjun Mukherjee*

Main category: cs.CL

TL;DR: 提出了一种新的AI文本检测器评估范式SHIELD，强调实际应用中的可靠性和稳定性，并开发了一种模型无关的人类化框架。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法过于依赖传统指标（如AUROC），忽略了实际部署中的关键问题（如假阳性率和稳定性）。

Method: 设计了SHIELD基准，结合可靠性和稳定性指标，并开发了可调节的人类化框架以挑战现有检测方法。

Result: SHIELD在评估中表现出对现有零样本检测方法的有效挑战，尤其在可靠性和稳定性方面。

Conclusion: SHIELD为AI文本检测器的实际部署提供了更全面的评估标准，并展示了人类化框架的有效性。

Abstract: We present a novel evaluation paradigm for AI text detectors that prioritizes
real-world and equitable assessment. Current approaches predominantly report
conventional metrics like AUROC, overlooking that even modest false positive
rates constitute a critical impediment to practical deployment of detection
systems. Furthermore, real-world deployment necessitates predetermined
threshold configuration, making detector stability (i.e. the maintenance of
consistent performance across diverse domains and adversarial scenarios), a
critical factor. These aspects have been largely ignored in previous research
and benchmarks. Our benchmark, SHIELD, addresses these limitations by
integrating both reliability and stability factors into a unified evaluation
metric designed for practical assessment. Furthermore, we develop a post-hoc,
model-agnostic humanification framework that modifies AI text to more closely
resemble human authorship, incorporating a controllable hardness parameter.
This hardness-aware approach effectively challenges current SOTA zero-shot
detection methods in maintaining both reliability and stability. (Data and
code: https://github.com/navid-aub/SHIELD-Benchmark)

</details>


### [197] [On the Inevitability of Left-Leaning Political Bias in Aligned Language Models](https://arxiv.org/abs/2507.15328)
*Thilo Hagendorff*

Main category: cs.CL

TL;DR: 论文探讨了AI对齐目标（无害、有帮助、诚实）与左翼政治偏见的必然联系，认为对齐原则与进步道德框架一致，而右翼意识形态与之冲突。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于澄清AI对齐目标与政治偏见之间的关系，反驳将左翼倾向视为问题的观点。

Method: 通过分析对齐目标的规范性假设与政治意识形态的契合度，论证左翼偏见的必然性。

Result: 结果表明，对齐目标与左翼原则（如避免伤害、包容性）一致，而与右翼意识形态冲突。

Conclusion: 结论认为，将左翼偏见视为问题实际上违背了AI对齐的核心原则。

Abstract: The guiding principle of AI alignment is to train large language models
(LLMs) to be harmless, helpful, and honest (HHH). At the same time, there are
mounting concerns that LLMs exhibit a left-wing political bias. Yet, the
commitment to AI alignment cannot be harmonized with the latter critique. In
this article, I argue that intelligent systems that are trained to be harmless
and honest must necessarily exhibit left-wing political bias. Normative
assumptions underlying alignment objectives inherently concur with progressive
moral frameworks and left-wing principles, emphasizing harm avoidance,
inclusivity, fairness, and empirical truthfulness. Conversely, right-wing
ideologies often conflict with alignment guidelines. Yet, research on political
bias in LLMs is consistently framing its insights about left-leaning tendencies
as a risk, as problematic, or concerning. This way, researchers are actively
arguing against AI alignment, tacitly fostering the violation of HHH
principles.

</details>


### [198] [Reasoning Models are Test Exploiters: Rethinking Multiple-Choice](https://arxiv.org/abs/2507.15337)
*Narun Raman,Taylor Lundy,Kevin Leyton-Brown*

Main category: cs.CL

TL;DR: 论文研究了多选问答（MCQA）是否仍能有效评估大型语言模型（LLM）的下游性能，发现其有效性取决于推理方式。


<details>
  <summary>Details</summary>
Motivation: 评估MCQA是否仍是评估LLM下游性能的有效方法，尤其是在先进推理模型上。

Method: 系统评估了15个问答基准和25个LLM，测试了5种提问方式，包括是否提供选项、是否允许链式推理等。

Result: MCQA仅在模型在提供选项前进行链式推理时有效；若推理在选项后，模型会利用选项信息，导致性能虚高。

Conclusion: MCQA不再适合评估先进模型的下游性能，需设计更鲁棒、无偏的基准以反映真实推理能力。

Abstract: When evaluating Large Language Models (LLMs) in question-answering domains,
it is common to ask the model to choose among a fixed set of choices (so-called
multiple-choice question-answering, or MCQA). Although downstream tasks of
interest typically do not provide systems with explicit options among which to
choose, this approach is nevertheless widely used because it makes it makes
automatic grading straightforward and has tended to produce challenging
benchmarks that correlate sufficiently well with downstream performance. This
paper investigates the extent to which this trend continues to hold for
state-of-the-art reasoning models, describing a systematic evaluation of $15$
different question-answering benchmarks (e.g., MMLU, HLE) and $25$ different
LLMs (including small models such as Qwen 7B and relatively large models such
as Llama 70B). For each model-benchmark pair, we considered $5$ ways of
presenting the model with questions, including variations on whether multiple
choices were offered to the model at all; whether "none of the above" sometimes
replaced the right answer; and whether the model was permitted to perform
chain-of-thought reasoning before and/or after the choices were presented. MCQA
remained a good proxy for the downstream performance of models as long as they
were allowed to perform chain-of-thought reasoning only before being presented
with the options among which they had to select. On the other hand, large
models that were able to perform reasoning after being given a set of options
tended to significantly outperform their free-text performance due to
exploiting the information in the options. We conclude that MCQA is no longer a
good proxy for assessing downstream performance of state-of-the-art models, and
offer practical guidelines for designing more robust, bias-resistant benchmarks
that better reflect LLMs' genuine reasoning capabilities.

</details>


### [199] [LionGuard 2: Building Lightweight, Data-Efficient & Localised Multilingual Content Moderators](https://arxiv.org/abs/2507.15339)
*Leanne Tan,Gabriel Chua,Ziyu Ge,Roy Ka-Wei Lee*

Main category: cs.CL

TL;DR: LionGuard 2是一个轻量级多语言内容审核分类器，针对新加坡语境优化，支持英语、中文、马来语和部分泰米尔语，性能优于多个商业和开源系统。


<details>
  <summary>Details</summary>
Motivation: 解决多语言和低资源变体在内容审核中的本地化问题，填补现有系统的安全漏洞。

Method: 基于预训练的OpenAI嵌入和多头序数分类器构建，无需微调大型模型。

Result: 在17个基准测试中表现优异，包括新加坡特定和公共英语数据集，已在新加坡政府实际部署。

Conclusion: 高质量本地数据和强大多语言嵌入可实现强内容审核性能，无需依赖大型模型。

Abstract: Modern moderation systems increasingly support multiple languages, but often
fail to address localisation and low-resource variants - creating safety gaps
in real-world deployments. Small models offer a potential alternative to large
LLMs, yet still demand considerable data and compute. We present LionGuard 2, a
lightweight, multilingual moderation classifier tailored to the Singapore
context, supporting English, Chinese, Malay, and partial Tamil. Built on
pre-trained OpenAI embeddings and a multi-head ordinal classifier, LionGuard 2
outperforms several commercial and open-source systems across 17 benchmarks,
including both Singapore-specific and public English datasets. The system is
actively deployed within the Singapore Government, demonstrating practical
efficacy at scale. Our findings show that high-quality local data and robust
multilingual embeddings can achieve strong moderation performance, without
fine-tuning large models. We release our model weights and part of our training
data to support future work on LLM safety.

</details>


### [200] [Probing Information Distribution in Transformer Architectures through Entropy Analysis](https://arxiv.org/abs/2507.15347)
*Amedeo Buonanno,Alessandro Rivetti,Francesco A. N. Palmieri,Giovanni Di Gennaro,Gianmarco Romano*

Main category: cs.CL

TL;DR: 该研究通过熵分析探索Transformer架构中的信息分布，量化标记级不确定性并分析处理阶段的熵模式，以揭示模型行为和内部表示。


<details>
  <summary>Details</summary>
Motivation: 研究动机是理解Transformer模型中信息的处理方式，为模型可解释性和评估框架提供新视角。

Method: 采用熵分析方法，量化标记级不确定性，并在GPT类大语言模型中应用该方法。

Result: 研究揭示了模型内部信息管理和转换的模式，为理解模型行为提供了新工具。

Conclusion: 熵分析是一种有效的工具，可用于研究Transformer模型的信息分布和行为，有助于模型可解释性和评估。

Abstract: This work explores entropy analysis as a tool for probing information
distribution within Transformer-based architectures. By quantifying token-level
uncertainty and examining entropy patterns across different stages of
processing, we aim to investigate how information is managed and transformed
within these models. As a case study, we apply the methodology to a GPT-based
large language model, illustrating its potential to reveal insights into model
behavior and internal representations. This approach may offer insights into
model behavior and contribute to the development of interpretability and
evaluation frameworks for transformer-based models

</details>


### [201] [Metaphor and Large Language Models: When Surface Features Matter More than Deep Understanding](https://arxiv.org/abs/2507.15357)
*Elisa Sanchez-Bayona,Rodrigo Agerri*

Main category: cs.CL

TL;DR: 本文全面评估了大语言模型（LLMs）在多种数据集、任务和提示配置下的隐喻解释能力，发现其表现更多受表面特征（如词汇重叠和句子长度）影响，而非隐喻内容。


<details>
  <summary>Details</summary>
Motivation: 隐喻处理在自然语言处理（NLP）中备受关注，但以往研究局限于单一数据集和特定任务设置，且多使用人工构造数据。本文旨在通过多样化公开数据集弥补这些不足。

Method: 使用多种公开数据集，结合自然语言推理（NLI）和问答（QA）任务，分析LLMs在隐喻解释中的表现。

Result: LLMs的表现更多受表面特征（如词汇重叠和句子长度）影响，而非隐喻内容，表明其隐喻理解能力是表面特征、上下文学习和语言知识的综合结果。

Conclusion: 本文揭示了LLMs在处理比喻语言时的当前能力和局限，强调需要更现实的评估框架。数据和代码已公开。

Abstract: This paper presents a comprehensive evaluation of the capabilities of Large
Language Models (LLMs) in metaphor interpretation across multiple datasets,
tasks, and prompt configurations. Although metaphor processing has gained
significant attention in Natural Language Processing (NLP), previous research
has been limited to single-dataset evaluations and specific task settings,
often using artificially constructed data through lexical replacement. We
address these limitations by conducting extensive experiments using diverse
publicly available datasets with inference and metaphor annotations, focusing
on Natural Language Inference (NLI) and Question Answering (QA) tasks. The
results indicate that LLMs' performance is more influenced by features like
lexical overlap and sentence length than by metaphorical content, demonstrating
that any alleged emergent abilities of LLMs to understand metaphorical language
are the result of a combination of surface-level features, in-context learning,
and linguistic knowledge. This work provides critical insights into the current
capabilities and limitations of LLMs in processing figurative language,
highlighting the need for more realistic evaluation frameworks in metaphor
interpretation tasks. Data and code are publicly available.

</details>


### [202] [STITCH: Simultaneous Thinking and Talking with Chunked Reasoning for Spoken Language Models](https://arxiv.org/abs/2507.15375)
*Cheng-Han Chiang,Xiaofei Wang,Linjie Li,Chung-Ching Lin,Kevin Lin,Shujie Liu,Zhendong Wang,Zhengyuan Yang,Hung-yi Lee,Lijuan Wang*

Main category: cs.CL

TL;DR: 论文提出Stitch方法，通过在生成语音响应时交替生成无声推理块，实现SLM的同时思考和说话，显著降低延迟并提升推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前SLM缺乏无声内部思考能力，而人类通过内部复杂推理清晰表达思想，因此需要为SLM集成无声思考过程。

Method: 提出Stitch方法，交替生成无声推理块和语音响应块，利用语音播放时间生成推理块，实现同时思考和说话。

Result: Stitch在数学推理数据集上比基线模型性能提升15%，在非推理数据集上表现相当，且延迟与基线一致。

Conclusion: Stitch成功实现SLM的同时思考和说话，显著提升推理能力且不增加延迟。

Abstract: Spoken Language Models (SLMs) are designed to take speech inputs and produce
spoken responses. However, current SLMs lack the ability to perform an
internal, unspoken thinking process before responding. In contrast, humans
typically engage in complex mental reasoning internally, enabling them to
communicate ideas clearly and concisely. Thus, integrating an unspoken thought
process into SLMs is highly desirable. While naively generating a complete
chain-of-thought (CoT) reasoning before starting to talk can enable thinking
for SLMs, this induces additional latency for the speech response, as the CoT
reasoning can be arbitrarily long. To solve this issue, we propose Stitch, a
novel generation method that alternates between the generation of unspoken
reasoning chunks and spoken response chunks. Since the audio duration of a
chunk of spoken response is much longer than the time to generate the tokens in
a chunk of spoken response, we use the remaining free time to generate the
unspoken reasoning tokens. When a chunk of audio is played to the user, the
model continues to generate the next unspoken reasoning chunk, achieving
simultaneous thinking and talking. Remarkably, Stitch matches the latency of
baselines that cannot generate unspoken CoT by design while outperforming those
baselines by 15% on math reasoning datasets; Stitch also performs equally well
on non-reasoning datasets as those baseline models. Some animations and
demonstrations are on the project page: https://d223302.github.io/STITCH.

</details>


### [203] [AlgoSimBench: Identifying Algorithmically Similar Problems for Competitive Programming](https://arxiv.org/abs/2507.15378)
*Jierui Li,Raymond Mooney*

Main category: cs.CL

TL;DR: 论文介绍了AlgoSimBench基准测试，评估LLMs识别算法相似问题的能力，发现模型表现不佳，并提出ASM方法提升性能。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在训练数据较少的相关领域中识别算法相似问题的能力。

Method: 提出AlgoSimBench基准测试，包含1317个问题和402个多选题，并引入ASM方法改进相似问题检测。

Result: 最佳模型在MCQ任务中准确率为65.9%，ASM方法提升6.7%至11.7%。代码嵌入模型和检索方法在去除叙事元素后表现改善。

Conclusion: LLMs在识别算法相似问题上仍有挑战，ASM方法显著提升性能，未来可结合其他技术进一步优化。

Abstract: Recent progress in LLMs, such as reasoning models, has demonstrated strong
abilities to solve complex competitive programming problems, often rivaling top
human competitors. However, it remains underexplored whether these abilities
generalize to relevant domains that are less seen during training. To address
this, we introduce AlgoSimBench, a new benchmark designed to assess LLMs'
ability to identify algorithmically similar problems (ASPs)-problems that can
be solved using similar algorithmic approaches. AlgoSimBench consists of 1317
problems, annotated with 231 distinct fine-grained algorithm tags, from which
we curate 402 multiple-choice questions (MCQs), where each question presents
one algorithmically similar problem alongside three textually similar but
algorithmically dissimilar distractors. Our evaluation reveals that LLMs
struggle to identify ASPs, with the best-performing model (o3-mini) achieving
only 65.9% accuracy on the MCQ task. To address this challenge, we propose
attempted solution matching (ASM), a novel method for improving problem
similarity detection. On our MCQ task, ASM yields an absolute accuracy
improvement of 6.7% to 11.7% across different models. We also evaluated code
embedding models and retrieval methods on similar problem identification. While
the adversarial selection of problems degrades the performance to be less than
random, we found that simply summarizing the problem to remove narrative
elements eliminates the effect, and combining ASM with a keyword-prioritized
method, BM25, can yield up to 52.2% accuracy. Code and data are available at
github.com

</details>


### [204] [ASPERA: A Simulated Environment to Evaluate Planning for Complex Action Execution](https://arxiv.org/abs/2507.15501)
*Alexandru Coca,Mark Gaynor,Zhenxing Zhang,Jianpeng Cheng,Bo-Hsiang Tseng,Pete Boothroyd,Héctor Martinez Alonso,Diarmuid Ó Séaghdha,Anders Johannsen*

Main category: cs.CL

TL;DR: 本文评估了大型语言模型（LLMs）驱动复杂动作执行数字助手的潜力，提出了ASPERA框架和Asper-Bench数据集，展示了LLMs在依赖自定义助手库的程序生成中的挑战。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在复杂动作执行中的潜力，解决数据可用性和评估鲁棒性问题。

Method: 开发ASPERA框架，包括助手库模拟和人工辅助的LLM数据生成引擎，生成高质量任务数据。

Result: 发布了Asper-Bench数据集，显示LLMs在依赖自定义库的程序生成中表现较差。

Conclusion: 自定义助手库的程序生成对LLMs是显著挑战，ASPERA框架为未来研究提供了工具。

Abstract: This work evaluates the potential of large language models (LLMs) to power
digital assistants capable of complex action execution. These assistants rely
on pre-trained programming knowledge to execute multi-step goals by composing
objects and functions defined in assistant libraries into action execution
programs. To achieve this, we develop ASPERA, a framework comprising an
assistant library simulation and a human-assisted LLM data generation engine.
Our engine allows developers to guide LLM generation of high-quality tasks
consisting of complex user queries, simulation state and corresponding
validation programs, tackling data availability and evaluation robustness
challenges. Alongside the framework we release Asper-Bench, an evaluation
dataset of 250 challenging tasks generated using ASPERA, which we use to show
that program generation grounded in custom assistant libraries is a significant
challenge to LLMs compared to dependency-free code generation.

</details>


### [205] [Step-level Verifier-guided Hybrid Test-Time Scaling for Large Language Models](https://arxiv.org/abs/2507.15512)
*Kaiyan Chang,Yonghao Shi,Chenglong Wang,Hang Zhou,Chi Hu,Xiaoqian Liu,Yingfeng Luo,Yuan Ge,Tong Xiao,Jingbo Zhu*

Main category: cs.CL

TL;DR: 论文提出了一种无需训练的测试时间缩放（TTS）方法，结合了细粒度顺序缩放和并行缩放，显著提升了大型语言模型的推理性能。


<details>
  <summary>Details</summary>
Motivation: 尽管基于训练的TTS方法（如强化学习）流行，但其计算开销大。论文旨在探索无需训练的TTS方法，以减轻负担并提升推理能力。

Method: 设计了条件步骤级自优化（Conditional Step-level Self-refinement）方法，并结合经典并行缩放方法，提出混合测试时间缩放（Hybrid Test-Time Scaling）范式。

Result: 在多个不同规模和家族的指令调优LLM（3B-14B）上实验表明，混合策略显著扩展了模型的推理性能边界。

Conclusion: 无需训练的混合TTS方法在推理任务中具有巨大潜力，为LLM的性能提升提供了新方向。

Abstract: Test-Time Scaling (TTS) is a promising approach to progressively elicit the
model's intelligence during inference. Recently, training-based TTS methods,
such as continued reinforcement learning (RL), have further surged in
popularity, while training-free TTS methods are gradually fading from
prominence. However, the additional computation overhead of training amplifies
the burden on test-time scaling. In this paper, we focus on training-free TTS
methods for reasoning. We first design Conditional Step-level Self-refinement,
a fine-grained sequential scaling method guided by process verification. On top
of its effectiveness, we further combine it with other classical parallel
scaling methods at the step level, to introduce a novel inference paradigm
called Hybrid Test-Time Scaling. Extensive experiments on five
instruction-tuned LLMs across different scales (3B-14B) and families
demonstrate that hybrid strategy incorporating various training-free TTS
methods at a fine granularity has considerable potential for expanding the
reasoning performance boundaries of LLMs.

</details>


### [206] [Evaluating Text Style Transfer: A Nine-Language Benchmark for Text Detoxification](https://arxiv.org/abs/2507.15557)
*Vitaly Protasov,Nikolay Babakov,Daryna Dementieva,Alexander Panchenko*

Main category: cs.CL

TL;DR: 本文研究了多语言文本去毒系统的评估方法，比较了基于神经网络的评估模型和基于提示的LLM评估方法，提出了更可靠的多语言评估流程。


<details>
  <summary>Details</summary>
Motivation: 现有文本风格转换（TST）评估方法在自动指标与人类判断之间存在显著差距，且多语言评估研究不足。

Method: 对九种语言的文本去毒系统进行评估，结合神经网络模型和LLM提示方法。

Result: 研究结果为设计更可靠的多语言TST评估流程提供了实用方案。

Conclusion: 本文填补了多语言文本去毒评估的空白，为未来研究提供了实用指导。

Abstract: Despite recent progress in large language models (LLMs), evaluation of text
generation tasks such as text style transfer (TST) remains a significant
challenge. Recent studies (Dementieva et al., 2024; Pauli et al., 2025)
revealed a substantial gap between automatic metrics and human judgments.
Moreover, most prior work focuses exclusively on English, leaving multilingual
TST evaluation largely unexplored. In this paper, we perform the first
comprehensive multilingual study on evaluation of text detoxification system
across nine languages: English, Spanish, German, Chinese, Arabic, Hindi,
Ukrainian, Russian, Amharic. Drawing inspiration from the machine translation,
we assess the effectiveness of modern neural-based evaluation models alongside
prompting-based LLM-as-a-judge approaches. Our findings provide a practical
recipe for designing more reliable multilingual TST evaluation pipeline in the
text detoxification case.

</details>


### [207] [Smart Eyes for Silent Threats: VLMs and In-Context Learning for THz Imaging](https://arxiv.org/abs/2507.15576)
*Nicolas Poggi,Shashank Agnihotri,Margret Keuper*

Main category: cs.CL

TL;DR: 论文提出了一种基于上下文学习（ICL）和视觉语言模型（VLM）的太赫兹（THz）图像分类方法，无需微调即可在低数据量下提升分类性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 太赫兹成像在安全筛查和材料分类等应用中具有潜力，但受限于标注数据少、分辨率低和视觉模糊，传统分类方法效果不佳。

Method: 采用模态对齐的提示框架，将两种开放权重的VLM适配到THz领域，并在零样本和单样本设置下评估。

Result: 实验表明，ICL在低数据量下显著提升了分类性能和可解释性。

Conclusion: 这是ICL增强的VLM首次应用于THz成像，为资源受限的科学领域提供了新方向。

Abstract: Terahertz (THz) imaging enables non-invasive analysis for applications such
as security screening and material classification, but effective image
classification remains challenging due to limited annotations, low resolution,
and visual ambiguity. We introduce In-Context Learning (ICL) with
Vision-Language Models (VLMs) as a flexible, interpretable alternative that
requires no fine-tuning. Using a modality-aligned prompting framework, we adapt
two open-weight VLMs to the THz domain and evaluate them under zero-shot and
one-shot settings. Our results show that ICL improves classification and
interpretability in low-data regimes. This is the first application of
ICL-enhanced VLMs to THz imaging, offering a promising direction for
resource-constrained scientific domains. Code:
\href{https://github.com/Nicolas-Poggi/Project_THz_Classification/tree/main}{GitHub
repository}.

</details>


### [208] [Learning to Extract Rational Evidence via Reinforcement Learning for Retrieval-Augmented Generation](https://arxiv.org/abs/2507.15586)
*Xinping Zhao,Shouzheng Huang,Yan Zhong,Xinshuo Hu,Baotian Hu,Min Zhang*

Main category: cs.CL

TL;DR: LEAR是一种通过学习提取理性证据的方法，通过显式推理和提取关键线索来减少检索噪声对LLM生成质量的影响。


<details>
  <summary>Details</summary>
Motivation: 检索噪声显著影响LLM生成质量，现有方法缺乏显式推理，可能遗漏关键线索且泛化能力不足。

Method: LEAR通过显式推理识别潜在线索，统一证据推理与提取进行端到端训练，并使用知识令牌掩码和奖励函数优化模型。

Result: 在三个基准数据集上的实验表明，LEAR能提供紧凑高质量的证据，提升下游任务准确性，适用于在线RAG系统。

Conclusion: LEAR通过显式推理和提取机制有效减少检索噪声，提升LLM生成质量和应用效果。

Abstract: Retrieval-Augmented Generation (RAG) effectively improves the accuracy of
Large Language Models (LLMs). However, retrieval noises significantly impact
the quality of LLMs' generation, necessitating the development of denoising
mechanisms. Previous methods extract evidence straightforwardly without
explicit thinking, which risks filtering out key clues and struggles with
generalization. To this end, we propose LEAR, which learns to extract rational
evidence by (1) explicitly reasoning to identify potential cues within
retrieval contents first, and then (2) consciously extracting to avoid omitting
any key cues helpful for answering questions. Specifically, we frame evidence
reasoning and evidence extraction into one unified response for end-to-end
training; apply knowledge token masks for disentanglement to derive
reasoning-based and extraction-based answers; and devise three types of
verifiable reward functions, including answer, length, and format, to update
the model via the policy optimization algorithm. Extensive experiments on three
benchmark datasets show the effectiveness of LEAR, providing compact and
high-quality evidence, improving the accuracy of downstream tasks, and
promoting effective application in online RAG systems.

</details>


### [209] [Conflicting narratives and polarization on social media](https://arxiv.org/abs/2507.15600)
*Armin Pournaki*

Main category: cs.CL

TL;DR: 论文通过分析德国Twitter上对立观点群体的推文，研究了政治叙事如何揭示极化现象和议题对齐的机制。


<details>
  <summary>Details</summary>
Motivation: 探索政治叙事作为理解政治现实的解释工具，以及其在公共领域极化现象中的作用。

Method: 基于2021-2023年德国Twitter数据，提取对立观点群体的叙事信号，分析乌克兰战争、新冠疫情和气候变化等议题。

Result: 发现叙事冲突的两个维度：角色分配差异和事件情节差异，并初步揭示叙事对齐的策略。

Conclusion: 叙事分析为研究极化现象的机制提供了有效视角。

Abstract: Narratives are key interpretative devices by which humans make sense of
political reality. In this work, we show how the analysis of conflicting
narratives, i.e. conflicting interpretive lenses through which political
reality is experienced and told, provides insight into the discursive
mechanisms of polarization and issue alignment in the public sphere. Building
upon previous work that has identified ideologically polarized issues in the
German Twittersphere between 2021 and 2023, we analyze the discursive dimension
of polarization by extracting textual signals of conflicting narratives from
tweets of opposing opinion groups. Focusing on a selection of salient issues
and events (the war in Ukraine, Covid, climate change), we show evidence for
conflicting narratives along two dimensions: (i) different attributions of
actantial roles to the same set of actants (e.g. diverging interpretations of
the role of NATO in the war in Ukraine), and (ii) emplotment of different
actants for the same event (e.g. Bill Gates in the right-leaning Covid
narrative). Furthermore, we provide first evidence for patterns of narrative
alignment, a discursive strategy that political actors employ to align opinions
across issues. These findings demonstrate the use of narratives as an
analytical lens into the discursive mechanisms of polarization.

</details>


### [210] [Leveraging Context for Multimodal Fallacy Classification in Political Debates](https://arxiv.org/abs/2507.15641)
*Alessio Pittiglio*

Main category: cs.CL

TL;DR: 本文介绍了参加MM-ArgFallacy2025共享任务的提交，旨在推进多模态论点挖掘研究，特别是政治辩论中的逻辑谬误。


<details>
  <summary>Details</summary>
Motivation: 研究旨在通过多模态方法改进政治辩论中逻辑谬误的识别。

Method: 使用预训练的Transformer模型，并提出多种利用上下文的方法。

Result: 在谬误分类子任务中，文本、音频和多模态模型的宏F1分数分别为0.4444、0.3559和0.4403。

Conclusion: 多模态模型表现接近纯文本模型，表明有改进潜力。

Abstract: In this paper, we present our submission to the MM-ArgFallacy2025 shared
task, which aims to advance research in multimodal argument mining, focusing on
logical fallacies in political debates. Our approach uses pretrained
Transformer-based models and proposes several ways to leverage context. In the
fallacy classification subtask, our models achieved macro F1-scores of 0.4444
(text), 0.3559 (audio), and 0.4403 (multimodal). Our multimodal model showed
performance comparable to the text-only model, suggesting potential for
improvements.

</details>


### [211] [P3: Prompts Promote Prompting](https://arxiv.org/abs/2507.15675)
*Xinyu Zhang,Yuanquan Hu,Fangchao Liu,Zhicheng Dou*

Main category: cs.CL

TL;DR: P3框架通过同时优化系统和用户提示，提升大语言模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅优化系统或用户提示，效果不佳，需同时优化两者。

Method: P3框架通过迭代过程同时优化系统和用户提示，并支持在线优化。

Result: 在通用任务和推理任务中，P3表现优于现有方法。

Conclusion: 整体优化策略能显著提升大语言模型性能。

Abstract: Current large language model (LLM) applications often employ multi-component
prompts, comprising both system and user prompts, to guide model behaviors.
While recent advancements have demonstrated the efficacy of automatically
optimizing either the system or user prompt to boost performance, such
unilateral approaches often yield suboptimal outcomes due to the interdependent
nature of these components. In this work, we introduce P3, a novel
self-improvement framework that concurrently optimizes both system and user
prompts through an iterative process. The offline optimized prompts are further
leveraged to promote online prompting by performing query-dependent prompt
optimization. Extensive experiments on general tasks (e.g., Arena-hard and
Alpaca-eval) and reasoning tasks (e.g., GSM8K and GPQA) demonstrate that P3
achieves superior performance in the realm of automatic prompt optimization.
Our results highlight the effectiveness of a holistic optimization strategy in
enhancing LLM performance across diverse domains.

</details>


### [212] [CoLD: Counterfactually-Guided Length Debiasing for Process Reward Models](https://arxiv.org/abs/2507.15698)
*Congmin Zheng,Jiachen Zhu,Jianghao Lin,Xinyi Dai,Yong Yu,Weinan Zhang,Mengyue Yang*

Main category: cs.CL

TL;DR: 论文提出CoLD框架，通过长度惩罚、学习偏差估计和联合训练策略，解决PRMs中存在的长度偏见问题，提升推理的准确性和简洁性。


<details>
  <summary>Details</summary>
Motivation: 现有PRMs存在长度偏见，倾向于给更长的推理步骤更高评分，影响奖励预测的可靠性和推理输出的简洁性。

Method: 提出CoLD框架，包含显式长度惩罚调整、学习偏差估计器和联合训练策略，基于反事实推理和因果图分析。

Result: 在MATH500和GSM-Plus数据集上，CoLD显著降低了奖励与长度的相关性，提升了步骤选择的准确性和推理的简洁性。

Conclusion: CoLD有效提升了PRMs的可靠性和鲁棒性，证明了其在改进推理过程中的实用价值。

Abstract: Process Reward Models (PRMs) play a central role in evaluating and guiding
multi-step reasoning in large language models (LLMs), especially for
mathematical problem solving. However, we identify a pervasive length bias in
existing PRMs: they tend to assign higher scores to longer reasoning steps,
even when the semantic content and logical validity are unchanged. This bias
undermines the reliability of reward predictions and leads to overly verbose
outputs during inference. To address this issue, we propose
CoLD(Counterfactually-Guided Length Debiasing), a unified framework that
mitigates length bias through three components: an explicit length-penalty
adjustment, a learned bias estimator trained to capture spurious length-related
signals, and a joint training strategy that enforces length-invariance in
reward predictions. Our approach is grounded in counterfactual reasoning and
informed by causal graph analysis. Extensive experiments on MATH500 and
GSM-Plus show that CoLD consistently reduces reward-length correlation,
improves accuracy in step selection, and encourages more concise, logically
valid reasoning. These results demonstrate the effectiveness and practicality
of CoLD in improving the fidelity and robustness of PRMs.

</details>


### [213] [Compositional Understanding in Signaling Games](https://arxiv.org/abs/2507.15706)
*David Peter Wallis Freeborn*

Main category: cs.CL

TL;DR: 论文通过构建两种新的信号博弈模型（简约型接收者和通用型接收者），解决了标准模型中接收者难以学习组合信息的问题。


<details>
  <summary>Details</summary>
Motivation: 标准信号博弈模型中，接收者无法有效理解组合信息，导致信息丢失或遗忘时整体信息受损。

Method: 提出两种新模型：简约型接收者（仅从信号的原子消息中学习）和通用型接收者（从所有可用信息中学习）。

Result: 新模型比现有方案更简单，且能让接收者从消息的原子组件中学习。

Conclusion: 新模型成功实现了接收者对组合信息的真正理解。

Abstract: Receivers in standard signaling game models struggle with learning
compositional information. Even when the signalers send compositional messages,
the receivers do not interpret them compositionally. When information from one
message component is lost or forgotten, the information from other components
is also erased. In this paper I construct signaling game models in which
genuine compositional understanding evolves. I present two new models: a
minimalist receiver who only learns from the atomic messages of a signal, and a
generalist receiver who learns from all of the available information. These
models are in many ways simpler than previous alternatives, and allow the
receivers to learn from the atomic components of messages.

</details>


### [214] [Is Large Language Model Performance on Reasoning Tasks Impacted by Different Ways Questions Are Asked?](https://arxiv.org/abs/2507.15707)
*Seok Hwan Song,Mohna Chakraborty,Qi Li,Wallapak Tavanapong*

Main category: cs.CL

TL;DR: 研究探讨了不同问题类型对大型语言模型（LLMs）在推理任务中准确性的影响，发现性能差异显著且推理准确性与最终答案选择准确性不一定相关。


<details>
  <summary>Details</summary>
Motivation: 探索不同问题类型对LLMs在推理任务中准确性的影响，填补研究空白。

Method: 评估五种LLMs在三种问题类型（定量和演绎推理任务）上的表现，分析推理步骤准确性和最终答案选择准确性。

Result: 发现LLMs在不同问题类型上表现差异显著，推理准确性与最终选择准确性无必然关联，选项数量和措辞影响性能。

Conclusion: 问题类型对LLMs性能有显著影响，需在设计评估任务时考虑问题类型和措辞。

Abstract: Large Language Models (LLMs) have been evaluated using diverse question
types, e.g., multiple-choice, true/false, and short/long answers. This study
answers an unexplored question about the impact of different question types on
LLM accuracy on reasoning tasks. We investigate the performance of five LLMs on
three different types of questions using quantitative and deductive reasoning
tasks. The performance metrics include accuracy in the reasoning steps and
choosing the final answer. Key Findings: (1) Significant differences exist in
LLM performance across different question types. (2) Reasoning accuracy does
not necessarily correlate with the final selection accuracy. (3) The number of
options and the choice of words, influence LLM performance.

</details>


### [215] [Chinchunmei at SemEval-2025 Task 11: Boosting the Large Language Model's Capability of Emotion Perception using Contrastive Learning](https://arxiv.org/abs/2507.15714)
*Tian Li,Yujian Sun,Huizhi Liang*

Main category: cs.CL

TL;DR: SemEval-2025 Task 11聚焦多语言情感检测，提出两种对比学习方法，在竞赛中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决情感表达多样性和背景差异带来的挑战，推动情感检测技术的发展。

Method: 采用样本对比学习（CRC）和生成对比学习（DPO、SimPO），基于LLaMa3-Instruct-8B微调。

Result: 英语赛道A第9名、赛道B第6名，其他语言表现优异。

Conclusion: 对比学习方法在多语言情感检测中有效，未来可进一步优化。

Abstract: The SemEval-2025 Task 11, Bridging the Gap in Text-Based Emotion Detection,
introduces an emotion recognition challenge spanning over 28 languages. This
competition encourages researchers to explore more advanced approaches to
address the challenges posed by the diversity of emotional expressions and
background variations. It features two tracks: multi-label classification
(Track A) and emotion intensity prediction (Track B), covering six emotion
categories: anger, fear, joy, sadness, surprise, and disgust. In our work, we
systematically explore the benefits of two contrastive learning approaches:
sample-based (Contrastive Reasoning Calibration) and generation-based (DPO,
SimPO) contrastive learning. The sample-based contrastive approach trains the
model by comparing two samples to generate more reliable predictions. The
generation-based contrastive approach trains the model to differentiate between
correct and incorrect generations, refining its prediction. All models are
fine-tuned from LLaMa3-Instruct-8B. Our system achieves 9th place in Track A
and 6th place in Track B for English, while ranking among the top-tier
performing systems for other languages.

</details>


### [216] [From Queries to Criteria: Understanding How Astronomers Evaluate LLMs](https://arxiv.org/abs/2507.15715)
*Alina Hyk,Kiera McCormick,Mian Zhong,Ioana Ciucă,Sanjib Sharma,John F Wu,J. E. G. Peek,Kartheik G. Iyer,Ziang Xiao,Anjalie Field*

Main category: cs.CL

TL;DR: 研究通过分析天文学家对LLM驱动的天文文献检索生成机器人的使用和评价，提出了改进LLM评估基准的建议。


<details>
  <summary>Details</summary>
Motivation: 由于LLM在科学领域的应用日益广泛，但现有评估基准未能反映用户实际需求，研究旨在通过用户行为分析改进评估方法。

Method: 通过Slack部署LLM驱动的检索生成机器人，收集368个查询并进行归纳编码，随后对11名天文学家进行访谈。

Result: 揭示了用户评价LLM系统的具体标准和问题类型，并基于此构建了改进的评估基准。

Conclusion: 研究为科学领域LLM的评估和实用性提供了改进方向。

Abstract: There is growing interest in leveraging LLMs to aid in astronomy and other
scientific research, but benchmarks for LLM evaluation in general have not kept
pace with the increasingly diverse ways that real people evaluate and use these
models. In this study, we seek to improve evaluation procedures by building an
understanding of how users evaluate LLMs. We focus on a particular use case: an
LLM-powered retrieval-augmented generation bot for engaging with astronomical
literature, which we deployed via Slack. Our inductive coding of 368 queries to
the bot over four weeks and our follow-up interviews with 11 astronomers reveal
how humans evaluated this system, including the types of questions asked and
the criteria for judging responses. We synthesize our findings into concrete
recommendations for building better benchmarks, which we then employ in
constructing a sample benchmark for evaluating LLMs for astronomy. Overall, our
work offers ways to improve LLM evaluation and ultimately usability,
particularly for use in scientific research.

</details>


### [217] [BEnchmarking LLMs for Ophthalmology (BELO) for Ophthalmological Knowledge and Reasoning](https://arxiv.org/abs/2507.15717)
*Sahana Srinivasan,Xuguang Ai,Thaddaeus Wai Soon Lo,Aidan Gilson,Minjie Zou,Ke Zou,Hyunjae Kim,Mingjia Yang,Krithi Pushpanathan,Samantha Yew,Wan Ting Loke,Jocelyn Goh,Yibing Chen,Yiming Kong,Emily Yuelei Fu,Michelle Ongyong Hui,Kristen Nwanyanwu,Amisha Dave,Kelvin Zhenghao Li,Chen-Hsin Sun,Mark Chia,Gabriel Dawei Yang,Wendy Meihua Wong,David Ziyou Chen,Dianbo Liu,Maxwell Singer,Fares Antaki,Lucian V Del Priore,Jost Jonas,Ron Adelman,Qingyu Chen,Yih-Chung Tham*

Main category: cs.CL

TL;DR: BELO是一个标准化的眼科领域大语言模型评估基准，通过专家多轮检查开发，包含900个高质量问题，评估临床准确性和推理质量。


<details>
  <summary>Details</summary>
Motivation: 现有眼科领域的大语言模型评估基准范围有限且过度关注准确性，因此需要更全面的评估工具。

Method: 通过关键词匹配和PubMedBERT模型从多个医学数据集中筛选眼科相关多选题，经专家多轮检查和优化。

Result: BELO包含900个专家审核的问题，评估了六种大语言模型，并建立了公开排行榜。

Conclusion: BELO将作为保留的评估基准，确保未来模型的公平和可重复比较。

Abstract: Current benchmarks evaluating large language models (LLMs) in ophthalmology
are limited in scope and disproportionately prioritise accuracy. We introduce
BELO (BEnchmarking LLMs for Ophthalmology), a standardized and comprehensive
evaluation benchmark developed through multiple rounds of expert checking by 13
ophthalmologists. BELO assesses ophthalmology-related clinical accuracy and
reasoning quality. Using keyword matching and a fine-tuned PubMedBERT model, we
curated ophthalmology-specific multiple-choice-questions (MCQs) from diverse
medical datasets (BCSC, MedMCQA, MedQA, BioASQ, and PubMedQA). The dataset
underwent multiple rounds of expert checking. Duplicate and substandard
questions were systematically removed. Ten ophthalmologists refined the
explanations of each MCQ's correct answer. This was further adjudicated by
three senior ophthalmologists. To illustrate BELO's utility, we evaluated six
LLMs (OpenAI o1, o3-mini, GPT-4o, DeepSeek-R1, Llama-3-8B, and Gemini 1.5 Pro)
using accuracy, macro-F1, and five text-generation metrics (ROUGE-L, BERTScore,
BARTScore, METEOR, and AlignScore). In a further evaluation involving human
experts, two ophthalmologists qualitatively reviewed 50 randomly selected
outputs for accuracy, comprehensiveness, and completeness. BELO consists of 900
high-quality, expert-reviewed questions aggregated from five sources: BCSC
(260), BioASQ (10), MedMCQA (572), MedQA (40), and PubMedQA (18). A public
leaderboard has been established to promote transparent evaluation and
reporting. Importantly, the BELO dataset will remain a hold-out,
evaluation-only benchmark to ensure fair and reproducible comparisons of future
models.

</details>


### [218] [Understanding Large Language Models' Ability on Interdisciplinary Research](https://arxiv.org/abs/2507.15736)
*Yuanhao Shen,Daniel Xavier de Sousa,Ricardo Marçal,Ali Asad,Hongyu Guo,Xiaodan Zhu*

Main category: cs.CL

TL;DR: IDRBench是一个新基准，用于评估大语言模型（LLMs）在跨学科研究（IDR）中提出有价值研究想法的能力，发现LLMs在此领域仍有局限。


<details>
  <summary>Details</summary>
Motivation: 现有基准缺乏对LLMs在跨学科研究中表现的系统评估，阻碍了对LLMs能力的全面理解。

Method: 引入IDRBench，包含专家标注的数据集和任务，覆盖六个学科，评估LLMs在IDR中的表现。

Result: 尽管LLMs展现出一定跨学科意识，但在生成高质量IDR想法方面仍有困难。

Conclusion: IDRBench为评估LLMs在复杂跨学科研究中的表现提供了框架，并揭示了改进方向。

Abstract: Recent advancements in Large Language Models (LLMs) have revealed their
impressive ability to perform multi-step, logic-driven reasoning across complex
domains, positioning them as powerful tools and collaborators in scientific
discovery while challenging the long-held view that inspiration-driven ideation
is uniquely human. However, the lack of a dedicated benchmark that evaluates
LLMs' ability to develop ideas in Interdisciplinary Research (IDR) settings
poses a critical barrier to fully understanding their strengths and
limitations. To address this gap, we introduce IDRBench -- a pioneering
benchmark featuring an expert annotated dataset and a suite of tasks tailored
to evaluate LLMs' capabilities in proposing valuable research ideas from
different scientific domains for interdisciplinary research. This benchmark
aims to provide a systematic framework for assessing LLM performance in
complex, cross-domain scientific research. Our dataset consists of scientific
publications sourced from the ArXiv platform covering six distinct disciplines,
and is annotated by domain experts with diverse academic backgrounds. To ensure
high-quality annotations, we emphasize clearly defined dimensions that
characterize authentic interdisciplinary research. The design of evaluation
tasks in IDRBench follows a progressive, real-world perspective, reflecting the
natural stages of interdisciplinary research development, including 1) IDR
Paper Identification, 2) IDR Idea Integration, and 3) IDR Idea Recommendation.
Using IDRBench, we construct baselines across 10 LLMs and observe that despite
fostering some level of IDR awareness, LLMs still struggle to produce quality
IDR ideas. These findings could not only spark new research directions, but
also help to develop next-generation LLMs that excel in interdisciplinary
research.

</details>


### [219] [A Fisher's exact test justification of the TF-IDF term-weighting scheme](https://arxiv.org/abs/2507.15742)
*Paul Sheridan,Zeyad Ahmed,Aitazaz A. Farooque*

Main category: cs.CL

TL;DR: 本文从显著性检验的角度解释了TF-IDF的合理性，并证明TF-ICF变体与Fisher精确检验的p值负对数密切相关。


<details>
  <summary>Details</summary>
Motivation: 为TF-IDF这一经典信息检索方法提供统计学理论基础，使其对统计学家更具说服力。

Method: 通过分析TF-ICF与Fisher精确检验的p值负对数的关系，并在理想假设下建立联系。

Result: 证明了TF-ICF与Fisher精确检验的p值负对数密切相关，并在无限大文档集合的极限情况下收敛于TF-IDF。

Conclusion: TF-IDF的有效性可以通过Fisher精确检验的统计学视角得到解释，为统计学家提供了理论支持。

Abstract: Term frequency-inverse document frequency, or TF-IDF for short, is arguably
the most celebrated mathematical expression in the history of information
retrieval. Conceived as a simple heuristic quantifying the extent to which a
given term's occurrences are concentrated in any one given document out of
many, TF-IDF and its many variants are routinely used as term-weighting schemes
in diverse text analysis applications. There is a growing body of scholarship
dedicated to placing TF-IDF on a sound theoretical foundation. Building on that
tradition, this paper justifies the use of TF-IDF to the statistics community
by demonstrating how the famed expression can be understood from a significance
testing perspective. We show that the common TF-IDF variant TF-ICF is, under
mild regularity conditions, closely related to the negative logarithm of the
$p$-value from a one-tailed version of Fisher's exact test of statistical
significance. As a corollary, we establish a connection between TF-IDF and the
said negative log-transformed $p$-value under certain idealized assumptions. We
further demonstrate, as a limiting case, that this same quantity converges to
TF-IDF in the limit of an infinitely large document collection. The Fisher's
exact test justification of TF-IDF equips the working statistician with a ready
explanation of the term-weighting scheme's long-established effectiveness.

</details>


### [220] [DialogueForge: LLM Simulation of Human-Chatbot Dialogue](https://arxiv.org/abs/2507.15752)
*Ruizhe Zhu,Hao Zhu,Yaxuan Li,Syang Zhou,Shijing Cai,Malgorzata Lazuka,Elliott Ash*

Main category: cs.CL

TL;DR: DialogueForge是一个生成AI模拟对话的框架，旨在减少人工收集对话数据的成本，支持多种LLM生成任务定制对话，并通过微调提升小模型性能。


<details>
  <summary>Details</summary>
Motivation: 人工收集人机对话数据耗时费力，限制了对话AI的研究。DialogueForge旨在通过AI模拟对话解决这一问题。

Method: 使用真实人机对话的种子提示初始化对话，测试多种LLM（包括大模型和小模型）生成多轮对话，并探索微调技术提升小模型性能。

Result: 大模型（如GPT-4o）生成更真实的对话，小模型（如Llama、Mistral）通过微调性能显著提升，但长对话的连贯性仍是挑战。

Conclusion: DialogueForge为对话AI研究提供了高效工具，大模型表现更优，小模型通过微调具备潜力，但长对话连贯性需进一步改进。

Abstract: Collecting human-chatbot dialogues typically demands substantial manual
effort and is time-consuming, which limits and poses challenges for research on
conversational AI. In this work, we propose DialogueForge - a framework for
generating AI-simulated conversations in human-chatbot style. To initialize
each generated conversation, DialogueForge uses seed prompts extracted from
real human-chatbot interactions. We test a variety of LLMs to simulate the
human chatbot user, ranging from state-of-the-art proprietary models to
small-scale open-source LLMs, and generate multi-turn dialogues tailored to
specific tasks. In addition, we explore fine-tuning techniques to enhance the
ability of smaller models to produce indistinguishable human-like dialogues. We
evaluate the quality of the simulated conversations and compare different
models using the UniEval and GTEval evaluation protocols. Our experiments show
that large proprietary models (e.g., GPT-4o) generally outperform others in
generating more realistic dialogues, while smaller open-source models (e.g.,
Llama, Mistral) offer promising performance with greater customization. We
demonstrate that the performance of smaller models can be significantly
improved by employing supervised fine-tuning techniques. Nevertheless,
maintaining coherent and natural long-form human-like dialogues remains a
common challenge across all models.

</details>


### [221] [Interaction as Intelligence: Deep Research With Human-AI Partnership](https://arxiv.org/abs/2507.15759)
*Lyumanshan Ye,Xiaojie Cai,Xinkai Wang,Junfei Wang,Xiangkun Hu,Jiadi Su,Yang Nan,Sihan Wang,Bohan Zhang,Xiaoze Fan,Jinbin Luo,Yuxiang Zheng,Tianze Xu,Dayuan Fu,Yunze Wu,Pengrui Lu,Zengzhi Wang,Yiwei Qin,Zhen Huang,Yan Ma,Zhulin Hu,Haoyang Zou,Tiantian Mi,Yixin Ye,Ethan Chern,Pengfei Liu*

Main category: cs.CL

TL;DR: 论文提出“交互即智能”概念，重新定义人机关系，强调交互是智能的核心维度，并介绍Deep Cognition系统，通过透明、可控的交互提升研究任务效率。


<details>
  <summary>Details</summary>
Motivation: 传统人机交互模式（输入-等待-输出）存在错误级联、研究边界僵化等问题，无法动态整合人类专业知识。

Method: 提出Deep Cognition系统，实现透明可控的交互、细粒度双向对话及共享认知上下文。

Result: 用户评估显示，该系统在透明度、细粒度交互等六项指标上显著优于基线，研究任务效率提升31.8%至50.0%。

Conclusion: 交互是智能的核心，Deep Cognition通过认知监督模式显著提升人机协作效果。

Abstract: This paper introduces "Interaction as Intelligence" research series,
presenting a reconceptualization of human-AI relationships in deep research
tasks. Traditional approaches treat interaction merely as an interface for
accessing AI capabilities-a conduit between human intent and machine output. We
propose that interaction itself constitutes a fundamental dimension of
intelligence. As AI systems engage in extended thinking processes for research
tasks, meaningful interaction transitions from an optional enhancement to an
essential component of effective intelligence. Current deep research systems
adopt an "input-wait-output" paradigm where users initiate queries and receive
results after black-box processing. This approach leads to error cascade
effects, inflexible research boundaries that prevent question refinement during
investigation, and missed opportunities for expertise integration. To address
these limitations, we introduce Deep Cognition, a system that transforms the
human role from giving instructions to cognitive oversight-a mode of engagement
where humans guide AI thinking processes through strategic intervention at
critical junctures. Deep cognition implements three key innovations:
(1)Transparent, controllable, and interruptible interaction that reveals AI
reasoning and enables intervention at any point; (2)Fine-grained bidirectional
dialogue; and (3)Shared cognitive context where the system observes and adapts
to user behaviors without explicit instruction. User evaluation demonstrates
that this cognitive oversight paradigm outperforms the strongest baseline
across six key metrics: Transparency(+20.0%), Fine-Grained Interaction(+29.2%),
Real-Time Intervention(+18.5%), Ease of Collaboration(+27.7%),
Results-Worth-Effort(+8.8%), and Interruptibility(+20.7%). Evaluations on
challenging research problems show 31.8% to 50.0% points of improvements over
deep research systems.

</details>


### [222] [Supernova: Achieving More with Less in Transformer Architectures](https://arxiv.org/abs/2507.15773)
*Andrei-Valentin Tanase,Elena Pelican*

Main category: cs.CL

TL;DR: Supernova是一个650M参数的解码器专用Transformer，通过架构设计和分词创新，在保持计算效率的同时达到更大模型的性能。


<details>
  <summary>Details</summary>
Motivation: 挑战现有扩展范式，证明架构效率和分词质量可以弥补参数数量的减少。

Method: 结合RoPE、GQA（3:1压缩比）、RMSNorm和SwiGLU激活函数，并使用自定义128,000词汇的字节级BPE分词器。

Result: Supernova仅用100B训练token，达到1B参数模型90%的性能，参数减少53%。

Conclusion: 架构效率和分词创新可显著减少参数需求，挑战了传统扩展方法。

Abstract: We present Supernova, a 650M-parameter decoder-only transformer that
demonstrates how careful architectural design and tokenization innovation can
achieve the performance of larger models while maintaining computational
efficiency. Our architecture combines Rotary Positional Embeddings (RoPE),
Grouped Query Attention (GQA) with a 3:1 compression ratio, RMSNorm for
computational efficiency, and SwiGLU activation functions. A critical
innovation is our custom 128,000-vocabulary byte-level BPE tokenizer, which
achieves state-of-the-art compression performance. Through detailed analysis,
we show that Supernova achieves 90% of the performance of 1B-parameter models
while using 53% fewer parameters and requiring only 100B training tokens--an
order of magnitude less than competing models. Our findings challenge the
prevailing scaling paradigm, demonstrating that architectural efficiency and
tokenization quality can compensate for reduced parameter counts.

</details>


### [223] [Stabilizing Knowledge, Promoting Reasoning: Dual-Token Constraints for RLVR](https://arxiv.org/abs/2507.15778)
*Jiakang Wang,Runze Liu,Fuzheng Zhang,Xiu Li,Guorui Zhou*

Main category: cs.CL

TL;DR: Archer提出了一种基于熵感知的RLVR方法，通过双令牌约束和同步更新，优化了大型语言模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 传统RLVR方法对所有令牌应用统一的训练信号，忽略了知识相关令牌和推理相关令牌的不同作用，可能导致语义依赖断裂。

Method: Archer采用熵感知的双令牌约束策略，对推理令牌应用较弱的KL正则化和较高的裁剪阈值以鼓励探索，同时对知识令牌施加更强的约束以保持事实知识。

Result: 在数学推理和代码生成基准测试中，Archer显著优于之前的RLVR方法，达到或超过同类模型的先进水平。

Conclusion: Archer通过熵感知和双令牌约束，有效提升了大型语言模型的推理能力，同时保持了知识的一致性。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has become an effective
post-training method for improving the reasoning abilities of Large Language
Models (LLMs), mainly by shaping higher-order behaviors such as reflection and
planning. However, previous RLVR algorithms often apply uniform training
signals to all tokens, without considering the different roles of low-entropy
knowledge-related tokens and high-entropy reasoning-related tokens. Some recent
methods try to separate these token types by gradient masking or asynchronous
updates, but these approaches may break semantic dependencies in the model
output and hinder effective learning. In this work, we propose Archer, an
entropy-aware RLVR approach with dual-token constraints and synchronous
updates. Specifically, our method applies weaker KL regularization and higher
clipping thresholds to reasoning tokens to encourage exploration, while using
stronger constraints on knowledge tokens to maintain factual knowledge.
Experimental results on several mathematical reasoning and code generation
benchmarks show that our approach significantly outperforms previous RLVR
methods, reaching or exceeding state-of-the-art performance among models of
comparable size. The code is available at
https://github.com/wizard-III/ArcherCodeR.

</details>


### [224] [Reservoir Computing as a Language Model](https://arxiv.org/abs/2507.15779)
*Felix Köster,Atsushi Uchida*

Main category: cs.CL

TL;DR: 论文探讨了储层计算在自然文本处理中的性能，与传统Transformer架构相比，储层计算在效率和速度上表现更优，但在预测质量上略逊一筹。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型（LLM）在能源消耗和处理速度上的瓶颈问题，探索储层计算在文本处理中的潜力。

Method: 比较了三种字符级语言建模方法：两种储层计算（静态线性读出和注意力增强储层）和Transformer架构，通过统一流程评估性能、计算成本和预测准确性。

Result: Transformer在预测质量上表现最佳，而储层计算在训练和推理速度上更高效。注意力增强储层在动态调整输出权重方面表现更好。

Conclusion: 储层计算在资源受限场景下具有优势，为平衡性能与资源提供了指导。

Abstract: Large Language Models (LLM) have dominated the science and media landscape
duo to their impressive performance on processing large chunks of data and
produce human-like levels of text. Nevertheless, their huge energy demand and
slow processing still a bottleneck for further increasing quality while also
making the models accessible to everyone. To solve this bottleneck, we will
investigate how reservoir computing performs on natural text processing, which
could enable fast and energy efficient hardware implementations. Studies
investigating the use of reservoir computing as a language model remain sparse.
In this paper, we compare three distinct approaches for character-level
language modeling, two different reservoir computing approaches, where only an
output layer is trainable, and the well-known transformer-based architectures,
which fully learn an attention-based sequence representation. We explore the
performance, computational cost and prediction accuracy for both paradigms by
equally varying the number of trainable parameters for all models. Using a
consistent pipeline for all three approaches, we demonstrate that transformers
excel in prediction quality, whereas reservoir computers remain highly
efficient reducing the training and inference speed. Furthermore, we
investigate two types of reservoir computing: a traditional reservoir with a
static linear readout, and an attention-enhanced reservoir that dynamically
adapts its output weights via an attention mechanism. Our findings underline
how these paradigms scale and offer guidelines to balance resource constraints
with performance.

</details>


### [225] [Operationalizing AI for Good: Spotlight on Deployment and Integration of AI Models in Humanitarian Work](https://arxiv.org/abs/2507.15823)
*Anton Abilov,Ke Zhang,Hemank Lamba,Elizabeth M. Olson,Joel R. Tetreault,Alejandro Jaimes*

Main category: cs.CL

TL;DR: 论文探讨了AI for Good领域中实际部署与合作的重要性，填补了现有研究的空白。


<details>
  <summary>Details</summary>
Motivation: 现有AI for Good研究多关注模型开发，而忽略了部署与合作过程及其实际影响。

Method: 通过与H2H组织紧密合作，研究如何在资源受限环境中部署和维护AI模型。

Result: 分享了实际部署经验、维护策略及关键实践建议。

Conclusion: 强调了合作与持续维护对AI for Good项目成功的重要性。

Abstract: Publications in the AI for Good space have tended to focus on the research
and model development that can support high-impact applications. However, very
few AI for Good papers discuss the process of deploying and collaborating with
the partner organization, and the resulting real-world impact. In this work, we
share details about the close collaboration with a humanitarian-to-humanitarian
(H2H) organization and how to not only deploy the AI model in a
resource-constrained environment, but also how to maintain it for continuous
performance updates, and share key takeaways for practitioners.

</details>


### [226] [The Impact of Language Mixing on Bilingual LLM Reasoning](https://arxiv.org/abs/2507.15849)
*Yihao Li,Jiayi Xin,Miranda Muqing Miao,Qi Long,Lyle Ungar*

Main category: cs.CL

TL;DR: 研究发现，中英双语推理模型中的语言切换（如中英混合）能提升推理能力，强制单语解码会降低准确性。强化学习训练阶段是语言混合的关键，且轻量级探针可预测语言切换的利弊。


<details>
  <summary>Details</summary>
Motivation: 探讨语言混合（如中英交替）是否对双语大型语言模型的推理能力有益，并研究其背后的机制。

Method: 通过强化学习训练阶段分析语言混合现象，设计轻量级探针预测语言切换的影响，并验证其对推理任务的准确性提升。

Result: 语言混合提升推理准确性（强制单语解码降低5.6个百分点），探针指导解码可进一步提高准确性（最高6.25个百分点）。

Conclusion: 语言混合是双语模型的策略性推理行为，而非多语言训练的副产品。

Abstract: Proficient multilingual speakers often intentionally switch languages in the
middle of a conversation. Similarly, recent reasoning-focused bilingual large
language models (LLMs) with strong capabilities in both languages exhibit
language mixing--alternating languages within their chain of thought.
Discouraging this behavior in DeepSeek-R1 was found to degrade accuracy,
suggesting that language mixing may benefit reasoning. In this work, we study
language switching in Chinese-English bilingual reasoning models. We identify
reinforcement learning with verifiable rewards (RLVR) as the critical training
stage that leads to language mixing. We demonstrate that language mixing can
enhance reasoning: enforcing monolingual decoding reduces accuracy by 5.6
percentage points on math reasoning tasks. Additionally, a lightweight probe
can be trained to predict whether a potential language switch would benefit or
harm reasoning, and when used to guide decoding, increases accuracy by up to
6.25 percentage points. Our findings suggest that language mixing is not merely
a byproduct of multilingual training, but is a strategic reasoning behavior.

</details>


### [227] [3LM: Bridging Arabic, STEM, and Code through Benchmarking](https://arxiv.org/abs/2507.15850)
*Basma El Amel Boussaha,Leen AlQadi,Mugariya Farooq,Shaikha Alsuwaidi,Giulia Campesan,Ahmed Alzubaidi,Mohammed Alyafeai,Hakim Hacid*

Main category: cs.CL

TL;DR: 论文提出了3LM，一个针对阿拉伯语的三个基准测试套件，涵盖STEM问题和代码生成，填补了现有阿拉伯语LLM研究的空白。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语是世界上使用最广泛的语言之一，但其LLM研究和评估相对有限，尤其在STEM和代码领域缺乏基准测试。

Method: 设计了三个基准测试：1）自然来源的STEM问答对；2）合成生成的STEM问题；3）通过翻译和人工审核构建的代码生成测试。

Result: 发布了公开可用的三个基准测试，支持阿拉伯语LLM研究在STEM和代码领域的发展。

Conclusion: 3LM填补了阿拉伯语LLM研究在关键领域的空白，为未来的研究提供了重要资源。

Abstract: Arabic is one of the most widely spoken languages in the world, yet efforts
to develop and evaluate Large Language Models (LLMs) for Arabic remain
relatively limited. Most existing Arabic benchmarks focus on linguistic,
cultural, or religious content, leaving a significant gap in domains like STEM
and code which are increasingly relevant for real-world LLM applications. To
help bridge this gap, we present 3LM, a suite of three benchmarks designed
specifically for Arabic. The first is a set of STEM-related question-answer
pairs, naturally sourced from Arabic textbooks and educational worksheets. The
second consists of synthetically generated STEM questions, created using the
same sources. The third benchmark focuses on code generation, built through a
careful translation of two widely used code benchmarks, incorporating a
human-in-the-loop process with several rounds of review to ensure high-quality
and faithful translations. We release all three benchmarks publicly to support
the growth of Arabic LLM research in these essential but underrepresented
areas.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [228] [Real-Time Communication-Aware Ride-Sharing Route Planning for Urban Air Mobility: A Multi-Source Hybrid Attention Reinforcement Learning Approach](https://arxiv.org/abs/2507.14249)
*Yuejiao Xie,Maonan Wang,Di Zhou,Man-On Pun,Zhu Han*

Main category: cs.RO

TL;DR: 论文提出了一种基于无线电地图和MSHA-RL框架的UAM路径规划方法，以解决动态乘客需求和通信质量保障问题。


<details>
  <summary>Details</summary>
Motivation: 城市空中交通（UAM）系统需要灵活的路径规划以应对实时乘客需求和通信质量保障，传统方法无法满足这些需求。

Method: 构建无线电地图评估通信质量，提出MSHA-RL框架，通过多源数据对齐和混合注意力机制实现实时路径规划。

Result: 实验表明该方法能减少旅行时间、提高效率，并优先保障乘客安全。

Conclusion: MSHA-RL框架为UAM系统提供了一种高效、安全的路径规划解决方案。

Abstract: Urban Air Mobility (UAM) systems are rapidly emerging as promising solutions
to alleviate urban congestion, with path planning becoming a key focus area.
Unlike ground transportation, UAM trajectory planning has to prioritize
communication quality for accurate location tracking in constantly changing
environments to ensure safety. Meanwhile, a UAM system, serving as an air taxi,
requires adaptive planning to respond to real-time passenger requests,
especially in ride-sharing scenarios where passenger demands are unpredictable
and dynamic. However, conventional trajectory planning strategies based on
predefined routes lack the flexibility to meet varied passenger ride demands.
To address these challenges, this work first proposes constructing a radio map
to evaluate the communication quality of urban airspace. Building on this, we
introduce a novel Multi-Source Hybrid Attention Reinforcement Learning
(MSHA-RL) framework for the challenge of effectively focusing on passengers and
UAM locations, which arises from the significant dimensional disparity between
the representations. This model first generates the alignment among diverse
data sources with large gap dimensions before employing hybrid attention to
balance global and local insights, thereby facilitating responsive, real-time
path planning. Extensive experimental results demonstrate that the approach
enables communication-compliant trajectory planning, reducing travel time and
enhancing operational efficiency while prioritizing passenger safety.

</details>


### [229] [A Recursive Lie-Group Formulation for the Second-Order Time Derivatives of the Inverse Dynamics of parallel Kinematic Manipulators](https://arxiv.org/abs/2507.14274)
*Andreas Mueller,Shivesh Kumar,Thomas Kordik*

Main category: cs.RO

TL;DR: 本文首次提出了一种计算并联运动学机械臂（PKM）配备串联弹性执行器（SEA）时逆动力学解的二阶时间导数的高效算法，填补了文献空白。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注串联机械臂的SEA控制，而PKM配备SEA的轨迹控制尚未探索，关键在于高效计算逆动力学解的二阶时间导数。

Method: 利用PKM的特殊拓扑结构，复用串联机械臂逆动力学的递归算法，并采用李群框架推导所有关系。

Result: 数值实验验证了方法在6自由度Gough-Stewart平台和平面PKM上的有效性，尤其是在平坦性控制方案中的应用。

Conclusion: 本文提出的方法首次解决了PKM配备SEA时的轨迹控制问题，为相关应用提供了理论基础和计算工具。

Abstract: Series elastic actuators (SEA) were introduced for serial robotic arms. Their
model-based trajectory tracking control requires the second time derivatives of
the inverse dynamics solution, for which algorithms were proposed. Trajectory
control of parallel kinematics manipulators (PKM) equipped with SEAs has not
yet been pursued. Key element for this is the computationally efficient
evaluation of the second time derivative of the inverse dynamics solution. This
has not been presented in the literature, and is addressed in the present paper
for the first time. The special topology of PKM is exploited reusing the
recursive algorithms for evaluating the inverse dynamics of serial robots. A
Lie group formulation is used and all relations are derived within this
framework. Numerical results are presented for a 6-DOF Gough-Stewart platform
(as part of an exoskeleton), and for a planar PKM when a flatness-based control
scheme is applied.

</details>


### [230] [Personalized Socially Assistive Robots With End-to-End Speech-Language Models For Well-Being Support](https://arxiv.org/abs/2507.14412)
*Mengxue Fu,Zhonghao Shi,Minyu Huang,Siqi Liu,Mina Kian,Yirui Song,Maja J. Matarić*

Main category: cs.RO

TL;DR: 论文提出使用端到端语音语言模型（SLM）改进社交辅助机器人（SAR）的对话系统，通过用户研究验证其效果，并发现仍需改进的非语言行为和语音反馈问题。


<details>
  <summary>Details</summary>
Motivation: 现有SAR对话系统在实时延迟、反馈和个性化对话方面存在不足，需改进以提升用户体验。

Method: 采用端到端SLM与SAR结合，通过小规模用户研究（N=11）评估系统可用性。

Result: 用户认为SLM-SAR系统能提供共情反馈、自然对话和适应性回应，但非语言行为和语音反馈仍需改进。

Conclusion: 未来需优化机器人动作同步、提示生成和语音表达，以更好地支持心理健康实践。

Abstract: Socially assistive robots (SARs) have shown great potential for supplementing
well-being support. However, prior studies have found that existing dialogue
pipelines for SARs remain limited in real-time latency, back-channeling, and
personalized speech dialogue. Toward addressing these limitations, we propose
using integrated end-to-end speech-language models (SLMs) with SARs. This work
1) evaluated the usability of an SLM-enabled SAR dialogue system through a
small user study, and 2) identified remaining limitations through study user
feedback to inform future improvements. We conducted a small within-participant
user study with university students (N = 11) whose results showed that
participants perceived an SLM-enabled SAR system as capable of providing
empathetic feedback, natural turn-taking, back-channeling, and adaptive
responses. We also found that participants reported the robot's nonverbal
behaviors as lacking variability and synchronization with conversation, and the
SLM's verbal feedback as generic and repetitive. These findings highlighted the
need for real-time robot movement synchronized with conversation, improved
prompting or fine-tuning to generate outputs better aligned with mental health
practices, and more expressive, adaptive vocal generation.

</details>


### [231] [Koopman Operator Based Time-Delay Embeddings and State History Augmented LQR for Periodic Hybrid Systems: Bouncing Pendulum and Bipedal Walking](https://arxiv.org/abs/2507.14455)
*Chun-Ming Yang,Pranav A. Bhounsule*

Main category: cs.RO

TL;DR: 时间延迟嵌入技术用于构建非线性光滑系统的线性状态空间模型，本文将其扩展到周期性非光滑或混合系统，并提出了基于状态历史的线性二次调节器（LQR）。


<details>
  <summary>Details</summary>
Motivation: 探索时间延迟嵌入技术是否适用于周期性非光滑或混合系统，并开发新的控制方法。

Method: 扩展时间延迟嵌入技术，应用于两个周期性混合系统（弹跳摆和简单步行器），并设计状态历史增强的LQR。

Result: 成功构建了线性状态空间模型，并验证了状态历史增强LQR的有效性。

Conclusion: 时间延迟嵌入技术可推广到周期性混合系统，状态历史增强LQR为控制这类系统提供了新方法。

Abstract: Time-delay embedding is a technique that uses snapshots of state history over
time to build a linear state space model of a nonlinear smooth system. We
demonstrate that periodic non-smooth or hybrid system can also be modeled as a
linear state space system using this approach as long as its behavior is
consistent in modes and timings. We extended time-delay embeddings to generate
a linear model of two periodic hybrid systems: the bouncing pendulum and the
simplest walker with control inputs. This leads to a novel state history
augmented linear quadratic regulator (LQR) which uses current and past state
history for feedback control.

</details>


### [232] [A 21-DOF Humanoid Dexterous Hand with Hybrid SMA-Motor Actuation: CYJ Hand-0](https://arxiv.org/abs/2507.14538)
*Jin Chai,Xiang Yao,Mengfan Hou,Yanghong Li,Erbao Dong*

Main category: cs.RO

TL;DR: CYJ Hand-0是一款21自由度的仿人灵巧手，采用混合肌腱驱动系统（结合形状记忆合金和直流电机），通过3D打印金属框架和人工肌腱实现仿生设计。


<details>
  <summary>Details</summary>
Motivation: 设计一种仿人灵巧手，结合多种驱动方式以提升灵活性和功能性。

Method: 使用形状记忆合金（SMA）和直流电机混合驱动，高强钓鱼线作为人工肌腱，3D打印金属框架模拟人手结构。

Result: 机械和运动学实验验证了设计的有效性，展示了仿生灵巧性。

Conclusion: 该设计成功实现了仿人手的灵巧性和功能性。

Abstract: CYJ Hand-0 is a 21-DOF humanoid dexterous hand featuring a hybrid
tendon-driven actuation system that combines shape memory alloys (SMAs) and DC
motors. The hand employs high-strength fishing line as artificial tendons and
uses a fully 3D-printed AlSi10Mg metal frame designed to replicate the skeletal
and tendon-muscle structure of the human hand. A linear motor-driven module
controls finger flexion, while an SMA-based module enables finger extension and
lateral abduction. These modules are integrated into a compact hybrid actuation
unit mounted on a custom rear support structure. Mechanical and kinematic
experiments, conducted under an Arduino Mega 2560-based control system,
validate the effectiveness of the design and demonstrate its biomimetic
dexterity.

</details>


### [233] [BT-TL-DMPs: A Novel Robot TAMP Framework Combining Behavior Tree, Temporal Logic and Dynamical Movement Primitives](https://arxiv.org/abs/2507.14582)
*Zezhi Liu,Shizhen Wu,Hanqian Luo,Deyun Qin,Yongchun Fang*

Main category: cs.RO

TL;DR: 论文提出了一种名为BT-TL-DMPs的分层框架，结合行为树、时序逻辑和动态运动基元，以解决机器人从演示中学习技能并泛化到新场景的挑战。


<details>
  <summary>Details</summary>
Motivation: 在从演示学习（LfD）领域，机器人难以将学到的技能泛化到具有不同任务和运动需求的新环境，尤其是在长时域、多阶段且约束复杂的场景中。

Method: 框架整合了行为树（BT）、时序逻辑（TL）和动态运动基元（DMPs），利用信号时序逻辑（STL）形式化复杂任务需求，并通过STL约束的DMP优化方法调整运动基元。

Result: 仿真和真实实验验证了框架在多种STL约束下和长时域机器人操作任务中的泛化能力。

Conclusion: 该框架有效弥合了符号与运动之间的鸿沟，提升了复杂机器人任务的可靠性和泛化能力。

Abstract: In the field of Learning from Demonstration (LfD), enabling robots to
generalize learned manipulation skills to novel scenarios for long-horizon
tasks remains challenging. Specifically, it is still difficult for robots to
adapt the learned skills to new environments with different task and motion
requirements, especially in long-horizon, multi-stage scenarios with intricate
constraints. This paper proposes a novel hierarchical framework, called
BT-TL-DMPs, that integrates Behavior Tree (BT), Temporal Logic (TL), and
Dynamical Movement Primitives (DMPs) to address this problem. Within this
framework, Signal Temporal Logic (STL) is employed to formally specify complex,
long-horizon task requirements and constraints. These STL specifications are
systematically transformed to generate reactive and modular BTs for high-level
decision-making task structure. An STL-constrained DMP optimization method is
proposed to optimize the DMP forcing term, allowing the learned motion
primitives to adapt flexibly while satisfying intricate spatiotemporal
requirements and, crucially, preserving the essential dynamics learned from
demonstrations. The framework is validated through simulations demonstrating
generalization capabilities under various STL constraints and real-world
experiments on several long-horizon robotic manipulation tasks. The results
demonstrate that the proposed framework effectively bridges the symbolic-motion
gap, enabling more reliable and generalizable autonomous manipulation for
complex robotic tasks.

</details>


### [234] [Koopman Operator Based Linear Model Predictive Control for 2D Quadruped Trotting, Bounding, and Gait Transition](https://arxiv.org/abs/2507.14605)
*Chun-Ming Yang,Pranav A. Bhounsule*

Main category: cs.RO

TL;DR: 论文提出了一种基于Koopman算子理论和EDMD的四足机器人线性模型预测控制方法，用于在线生成多种步态和步态转换。


<details>
  <summary>Details</summary>
Motivation: 在线优化控制四足机器人在新场景中的运动规划，解决LMPC因线性化运动方程导致的解质量差问题。

Method: 利用Koopman算子理论和EDMD在高维空间构建线性模型，保留运动方程的非线性特性，并针对空中和地面接触阶段使用不同线性模型。

Result: 在水平和崎岖地形上实现了跳跃、小跑以及跳跃与小跑之间的步态转换。

Conclusion: 通过Koopman算子理论构建混合模型，成功实现了四足机器人多种步态的在线生成和转换。

Abstract: Online optimal control of quadrupedal robots would enable them to plan their
movement in novel scenarios. Linear Model Predictive Control (LMPC) has emerged
as a practical approach for real-time control. In LMPC, an optimization problem
with a quadratic cost and linear constraints is formulated over a finite
horizon and solved on the fly. However, LMPC relies on linearizing the
equations of motion (EOM), which may lead to poor solution quality. In this
paper, we use Koopman operator theory and the Extended Dynamic Mode
Decomposition (EDMD) to create a linear model of the system in high dimensional
space, thus retaining the nonlinearity of the EOM. We model the aerial phase
and ground contact phases using different linear models. Then, using LMPC, we
demonstrate bounding, trotting, and bound-to-trot and trot-to-bound gait
transitions in level and rough terrains. The main novelty is the use of Koopman
operator theory to create hybrid models of a quadrupedal system and demonstrate
the online generation of multiple gaits and gaits transitions.

</details>


### [235] [Uncertainty-aware Probabilistic 3D Human Motion Forecasting via Invertible Networks](https://arxiv.org/abs/2507.14694)
*Yue Ma,Kanglei Zhou,Fuyang Yu,Frederick W. B. Li,Xiaohui Liang*

Main category: cs.RO

TL;DR: ProbHMI利用可逆网络在解耦潜在空间中参数化姿态，实现概率动力学建模，有效量化不确定性，适用于安全关键场景。


<details>
  <summary>Details</summary>
Motivation: 在安全关键场景（如人机协作）中，量化预测的不确定性至关重要，但现有方法难以实现。

Method: 引入可逆网络参数化姿态，构建解耦潜在空间，并通过预测模块显式预测未来潜在分布。

Result: 在基准测试中表现优异，支持确定性和多样性预测，并验证了不确定性校准。

Conclusion: ProbHMI为风险感知决策提供了有效的不确定性量化方法。

Abstract: 3D human motion forecasting aims to enable autonomous applications.
Estimating uncertainty for each prediction (i.e., confidence based on
probability density or quantile) is essential for safety-critical contexts like
human-robot collaboration to minimize risks. However, existing diverse motion
forecasting approaches struggle with uncertainty quantification due to implicit
probabilistic representations hindering uncertainty modeling. We propose
ProbHMI, which introduces invertible networks to parameterize poses in a
disentangled latent space, enabling probabilistic dynamics modeling. A
forecasting module then explicitly predicts future latent distributions,
allowing effective uncertainty quantification. Evaluated on benchmarks, ProbHMI
achieves strong performance for both deterministic and diverse prediction while
validating uncertainty calibration, critical for risk-aware decision making.

</details>


### [236] [Corridor-based Adaptive Control Barrier and Lyapunov Functions for Safe Mobile Robot Navigation](https://arxiv.org/abs/2507.14700)
*Nicholas Mohammad,Nicola Bezzo*

Main category: cs.RO

TL;DR: 提出了一种结合CLF和CBF的MPCC框架，通过动态调整CBF参数确保安全导航，并在未知杂乱环境中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决现有MPCC方法缺乏正式安全保障的问题，提升机器人在未知杂乱环境中的安全导航能力。

Method: 结合CLF和CBF的MPCC框架，利用SAC策略动态调整CBF参数。

Result: 通过仿真和移动机器人实验验证了方法的有效性。

Conclusion: 该方法为未知杂乱环境中的安全导航提供了可靠解决方案。

Abstract: Safe navigation in unknown and cluttered environments remains a challenging
problem in robotics. Model Predictive Contour Control (MPCC) has shown promise
for performant obstacle avoidance by enabling precise and agile trajectory
tracking, however, existing methods lack formal safety assurances. To address
this issue, we propose a general Control Lyapunov Function (CLF) and Control
Barrier Function (CBF) enabled MPCC framework that enforces safety constraints
derived from a free-space corridor around the planned trajectory. To enhance
feasibility, we dynamically adapt the CBF parameters at runtime using a Soft
Actor-Critic (SAC) policy. The approach is validated with extensive simulations
and an experiment on mobile robot navigation in unknown cluttered environments.

</details>


### [237] [Leveraging Extrinsic Dexterity for Occluded Grasping on Grasp Constraining Walls](https://arxiv.org/abs/2507.14721)
*Keita Kobashi,Masayoshi Tomizuka*

Main category: cs.RO

TL;DR: 提出了一种分层强化学习框架，用于解决遮挡抓取问题，结合Q学习和CVAE，实现了从仿真到现实的泛化。


<details>
  <summary>Details</summary>
Motivation: 解决因环境遮挡导致的主要抓取配置不可用问题，尤其是在没有短墙假设的现实场景中。

Method: 采用分层强化学习框架，高层策略选择动作类型，低层技能在连续空间中采样具体动作，并使用CVAE推断合适位置。

Result: 在仿真中训练并在现实世界中部署，展示了泛化能力和稳健的仿真到现实迁移性能。

Conclusion: 提出的方法在复杂环境中表现出色，成功率高，具有实际应用潜力。

Abstract: This study addresses the problem of occluded grasping, where primary grasp
configurations of an object are not available due to occlusion with
environment. Simple parallel grippers often struggle with such tasks due to
limited dexterity and actuation constraints. Prior works have explored object
pose reorientation such as pivoting by utilizing extrinsic contacts between an
object and an environment feature like a wall, to make the object graspable.
However, such works often assume the presence of a short wall, and this
assumption may not always hold in real-world scenarios. If the wall available
for interaction is too large or too tall, the robot may still fail to grasp the
object even after pivoting, and the robot must combine different types of
actions to grasp. To address this, we propose a hierarchical reinforcement
learning (RL) framework. We use Q-learning to train a high-level policy that
selects the type of action expected to yield the highest reward. The selected
low-level skill then samples a specific robot action in continuous space. To
guide the robot to an appropriate location for executing the selected action,
we adopt a Conditional Variational Autoencoder (CVAE). We condition the CVAE on
the object point cloud and the skill ID, enabling it to infer a suitable
location based on the object geometry and the selected skill. To promote
generalization, we apply domain randomization during the training of low-level
skills. The RL policy is trained entirely in simulation with a box-like object
and deployed to six objects in real world. We conduct experiments to evaluate
our method and demonstrate both its generalizability and robust sim-to-real
transfer performance with promising success rates.

</details>


### [238] [X-Nav: Learning End-to-End Cross-Embodiment Navigation for Mobile Robots](https://arxiv.org/abs/2507.14731)
*Haitong Wang,Aaron Hao Tan,Angus Fung,Goldie Nejat*

Main category: cs.RO

TL;DR: X-Nav是一个跨机器人平台导航框架，通过两阶段学习实现通用策略，支持零样本迁移到新平台。


<details>
  <summary>Details</summary>
Motivation: 现有导航方法局限于特定机器人平台，缺乏通用性，X-Nav旨在解决这一问题。

Method: 1) 训练多个专家策略；2) 通过Nav-ACT蒸馏为通用策略，直接映射观测到控制命令。

Result: 实验证明X-Nav能零样本迁移到新平台和真实环境，性能随训练平台数量提升。

Conclusion: X-Nav展示了跨平台导航的潜力，并通过实验验证了其通用性和可扩展性。

Abstract: Existing navigation methods are primarily designed for specific robot
embodiments, limiting their generalizability across diverse robot platforms. In
this paper, we introduce X-Nav, a novel framework for end-to-end
cross-embodiment navigation where a single unified policy can be deployed
across various embodiments for both wheeled and quadrupedal robots. X-Nav
consists of two learning stages: 1) multiple expert policies are trained using
deep reinforcement learning with privileged observations on a wide range of
randomly generated robot embodiments; and 2) a single general policy is
distilled from the expert policies via navigation action chunking with
transformer (Nav-ACT). The general policy directly maps visual and
proprioceptive observations to low-level control commands, enabling
generalization to novel robot embodiments. Simulated experiments demonstrated
that X-Nav achieved zero-shot transfer to both unseen embodiments and
photorealistic environments. A scalability study showed that the performance of
X-Nav improves when trained with an increasing number of randomly generated
embodiments. An ablation study confirmed the design choices of X-Nav.
Furthermore, real-world experiments were conducted to validate the
generalizability of X-Nav in real-world environments.

</details>


### [239] [KGN-Pro: Keypoint-Based Grasp Prediction through Probabilistic 2D-3D Correspondence Learning](https://arxiv.org/abs/2507.14820)
*Bingran Chen,Baorun Li,Jian Yang,Yong Liu,Guangyao Zhai*

Main category: cs.RO

TL;DR: KGN-Pro是一种新型抓取网络，通过概率PnP层整合直接3D优化，解决了现有方法在6-DoF抓取估计中的局限性，显著提升了抓取成功率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在6-DoF抓取估计中存在小物体和传感器噪声问题，或依赖昂贵的标注和离散化问题，KGN-Pro旨在解决这些挑战。

Method: KGN-Pro通过RGB-D图像生成关键点图和2D置信图，利用概率PnP层进行3D优化，实现端到端学习。

Result: 实验表明，KGN-Pro在抓取覆盖率和成功率上优于现有方法。

Conclusion: KGN-Pro通过整合3D优化，显著提升了6-DoF抓取估计的性能。

Abstract: High-level robotic manipulation tasks demand flexible 6-DoF grasp estimation
to serve as a basic function. Previous approaches either directly generate
grasps from point-cloud data, suffering from challenges with small objects and
sensor noise, or infer 3D information from RGB images, which introduces
expensive annotation requirements and discretization issues. Recent methods
mitigate some challenges by retaining a 2D representation to estimate grasp
keypoints and applying Perspective-n-Point (PnP) algorithms to compute 6-DoF
poses. However, these methods are limited by their non-differentiable nature
and reliance solely on 2D supervision, which hinders the full exploitation of
rich 3D information. In this work, we present KGN-Pro, a novel grasping network
that preserves the efficiency and fine-grained object grasping of previous KGNs
while integrating direct 3D optimization through probabilistic PnP layers.
KGN-Pro encodes paired RGB-D images to generate Keypoint Map, and further
outputs a 2D confidence map to weight keypoint contributions during
re-projection error minimization. By modeling the weighted sum of squared
re-projection errors probabilistically, the network effectively transmits 3D
supervision to its 2D keypoint predictions, enabling end-to-end learning.
Experiments on both simulated and real-world platforms demonstrate that KGN-Pro
outperforms existing methods in terms of grasp cover rate and success rate.

</details>


### [240] [CoMoCAVs: Cohesive Decision-Guided Motion Planning for Connected and Autonomous Vehicles with Multi-Policy Reinforcement Learning](https://arxiv.org/abs/2507.14903)
*Pan Hu*

Main category: cs.RO

TL;DR: 论文提出了一种名为CDGMP的框架，通过混合专家架构和多策略强化学习，将决策（车道选择）与运动规划（控制命令生成）紧密结合，提升自动驾驶的灵活性和安全性。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶中，车道选择和运动规划的紧密集成是一个重要挑战，尤其是在联网自动驾驶车辆（CAVs）中。

Method: 采用混合专家（MoE）架构和多策略强化学习，通过门控机制协调多个子网络，将复杂驾驶任务分解为模块化组件。

Result: 仿真结果显示，CDGMP在车道选择和运动规划中表现可靠，提升了CAVs的适应性和鲁棒性。

Conclusion: CDGMP为自动驾驶提供了一种可扩展的解决方案，其架构原理也为其他高维决策和控制任务提供了基础。

Abstract: Autonomous driving demands reliable and efficient solutions to closely
related problems such as decision-making and motion planning. In this work,
decision-making refers specifically to highway lane selection, while motion
planning involves generating control commands (such as speed and steering) to
reach the chosen lane. In the context of Connected Autonomous Vehicles (CAVs),
achieving both flexible and safe lane selection alongside precise trajectory
execution remains a significant challenge. This paper proposes a framework
called Cohesive Decision-Guided Motion Planning (CDGMP), which tightly
integrates decision-making and motion planning using a Mixture of Experts (MoE)
inspired architecture combined with multi-policy reinforcement learning. By
coordinating multiple specialized sub-networks through a gating mechanism, the
method decomposes the complex driving task into modular components. Each
sub-network focuses on a specific aspect of driving, improving efficiency by
activating only the most relevant modules during inference. This design also
enhances safety through modular specialization. CDGMP improves the adaptability
and robustness of CAVs across diverse traffic scenarios, offering a scalable
solution to real-world autonomy challenges. The architectural principles behind
CDGMP, especially the use of MoE, also provide a strong foundation for other
high-dimensional decision and control tasks. Simulation results (available at
https://youtu.be/_-4OXNHV0UY) demonstrate reliable performance in both lane
selection and motion planning.

</details>


### [241] [One Step Beyond: Feedthrough & Placement-Aware Rectilinear Floorplanner](https://arxiv.org/abs/2507.14914)
*Zhexuan Xu,Jie Wang,Siyuan Xu,Zijie Geng,Mingxuan Yuan,Feng Wu*

Main category: cs.RO

TL;DR: Flora是一个三阶段的布局规划器，通过优化线长、通孔和组件布局，显著提升了芯片设计的PPA指标。


<details>
  <summary>Details</summary>
Motivation: 现有布局规划方法未能与后续物理设计阶段有效整合，导致模块内组件布局不优和模块间通孔过多。

Method: Flora采用三阶段方法：粗粒度优化线长和通孔，固定轮廓下零空白布局，以及基于树搜索的组件放置与边界调整。

Result: 实验显示，Flora在线长（HPWL）、通孔（FTpin和FTmod）和组件布局性能上均优于现有方法。

Conclusion: Flora通过跨阶段优化，显著提升了芯片设计的整体性能。

Abstract: Floorplanning determines the shapes and locations of modules on a chip canvas
and plays a critical role in optimizing the chip's Power, Performance, and Area
(PPA) metrics. However, existing floorplanning approaches often fail to
integrate with subsequent physical design stages, leading to suboptimal
in-module component placement and excessive inter-module feedthrough. To tackle
this challenge, we propose Flora, a three-stage feedthrough and placement aware
rectilinear floorplanner. In the first stage, Flora employs wiremask and
position mask techniques to achieve coarse-grained optimization of HPWL and
feedthrough. In the second stage, under the constraint of a fixed outline,
Flora achieves a zero-whitespace layout by locally resizing module shapes,
thereby performing fine-grained optimization of feedthrough and improving
component placement. In the third stage, Flora utilizes a fast tree
search-based method to efficiently place components-including macros and
standard cells-within each module, subsequently adjusting module boundaries
based on the placement results to enable cross-stage optimization. Experimental
results show that Flora outperforms recent state-of-the-art floorplanning
approaches, achieving an average reduction of 6% in HPWL, 5.16% in FTpin,
29.15% in FTmod, and a 14% improvement in component placement performance.

</details>


### [242] [Digital twin and extended reality for teleoperation of the electric vehicle battery disassembly](https://arxiv.org/abs/2507.14929)
*Tero Kaarlela,Sami Salo,Jose Outeiro*

Main category: cs.RO

TL;DR: 提出了一种用于电动汽车电池（EVB）安全拆解和分类的远程操作系统，结合人工和自动化，提高安全性、适应性和效率。


<details>
  <summary>Details</summary>
Motivation: 当前手动拆解EVB存在安全隐患（如触电和有毒化学品），需要更安全、高效的解决方案。

Method: 采用远程操作系统，结合人工操作和自动化技术，利用RGB摄像头和ROS中间件实现物理与数字孪生对齐。

Result: 在线试点研究表明该方法具有用户友好性和潜在的经济效益。

Conclusion: 该混合方法为EVB拆解和分类提供了安全、高效且经济的解决方案。

Abstract: Disassembling and sorting Electric Vehicle Batteries (EVBs) supports a
sustainable transition to electric vehicles by enabling a closed-loop supply
chain. Currently, the manual disassembly process exposes workers to hazards,
including electrocution and toxic chemicals. We propose a teleoperated system
for the safe disassembly and sorting of EVBs. A human-in-the-loop can create
and save disassembly sequences for unknown EVB types, enabling future
automation. An RGB camera aligns the physical and digital twins of the EVB, and
the digital twin of the robot is based on the Robot Operating System (ROS)
middleware. This hybrid approach combines teleoperation and automation to
improve safety, adaptability, and efficiency in EVB disassembly and sorting.
The economic contribution is realized by reducing labor dependency and
increasing throughput in battery recycling. An online pilot study was set up to
evaluate the usability of the presented approach, and the results demonstrate
the potential as a user-friendly solution.

</details>


### [243] [Designing Robots with, not for: A Co-Design Framework for Empowering Interactions in Forensic Psychiatry](https://arxiv.org/abs/2507.14931)
*Qiaoqiao Ren,Remko Proesmans,Arend Pissens,Lara Dehandschutter,William Denecker,Lotte Rouckhout,Joke Carrette,Peter Vanhopplinus,Tony Belpaeme,Francis wyffels*

Main category: cs.RO

TL;DR: 探讨了在法医心理健康护理中，如何通过共同设计开发一种伴侣机器人，用于监测和调节患者压力，同时记录互动行为以进行长期干预。


<details>
  <summary>Details</summary>
Motivation: 法医心理健康护理环境通常官僚主义严重、风险规避性强且患者自主权受限，导致患者心理压力大。研究旨在通过共同设计改善这一状况。

Method: 在法医精神病诊所进行了四次共同设计工作坊，参与者包括患者、护理人员和治疗师，从初步原型展示到创意构思，逐步完善设计。

Result: 研究发现，在设计过程中赋予患者权力并根据其当前情绪状态调整提案至关重要。

Conclusion: 共同设计有助于患者参与并表达需求，为开发更有效的心理健康干预工具提供了方向。

Abstract: Forensic mental health care involves the treatment of individuals with severe
mental disorders who have committed violent offences. These settings are often
characterized by high levels of bureaucracy, risk avoidance, and restricted
autonomy. Patients frequently experience a profound loss of control over their
lives, leading to heightened psychological stress-sometimes resulting in
isolation as a safety measure. In this study, we explore how co-design can be
used to collaboratively develop a companion robot that helps monitor and
regulate stress while maintaining tracking of the patients' interaction
behaviours for long-term intervention. We conducted four co-design workshops in
a forensic psychiatric clinic with patients, caregivers, and therapists. Our
process began with the presentation of an initial speculative prototype to
therapists, enabling reflection on shared concerns, ethical risks, and
desirable features. This was followed by a creative ideation session with
patients, a third workshop focused on defining desired functions and emotional
responses, and we are planning a final prototype demo to gather direct patient
feedback. Our findings emphasize the importance of empowering patients in the
design process and adapting proposals based on their current emotional state.
The goal was to empower the patient in the design process and ensure each
patient's voice was heard.

</details>


### [244] [Heterogeneous object manipulation on nonlinear soft surface through linear controller](https://arxiv.org/abs/2507.14967)
*Pratik Ingle,Kasper Støy,Andres Faiña*

Main category: cs.RO

TL;DR: 提出了一种基于PID的线性闭环反馈控制策略，用于在低密度驱动阵列上实现异构物体的精确操控。


<details>
  <summary>Details</summary>
Motivation: 高密度驱动阵列的复杂性和高自由度限制了操控表面的实际应用，而学习型控制方法需要大量训练样本且难以泛化。

Method: 采用几何变换驱动的PID控制器，直接将倾斜角度控制输出映射到驱动指令，避免黑盒训练。

Result: 通过仿真和物理实验验证，成功操控了多种几何形状、重量和纹理的物体，包括易碎品。

Conclusion: 该方法具有高度泛化性，为软体机器人操控提供了实用可靠的解决方案，无需大量训练。

Abstract: Manipulation surfaces indirectly control and reposition objects by actively
modifying their shape or properties rather than directly gripping objects.
These surfaces, equipped with dense actuator arrays, generate dynamic
deformations. However, a high-density actuator array introduces considerable
complexity due to increased degrees of freedom (DOF), complicating control
tasks. High DOF restrict the implementation and utilization of manipulation
surfaces in real-world applications as the maintenance and control of such
systems exponentially increase with array/surface size. Learning-based control
approaches may ease the control complexity, but they require extensive training
samples and struggle to generalize for heterogeneous objects. In this study, we
introduce a simple, precise and robust PID-based linear close-loop feedback
control strategy for heterogeneous object manipulation on MANTA-RAY
(Manipulation with Adaptive Non-rigid Textile Actuation with Reduced Actuation
density). Our approach employs a geometric transformation-driven PID
controller, directly mapping tilt angle control outputs(1D/2D) to actuator
commands to eliminate the need for extensive black-box training. We validate
the proposed method through simulations and experiments on a physical system,
successfully manipulating objects with diverse geometries, weights and
textures, including fragile objects like eggs and apples. The outcomes
demonstrate that our approach is highly generalized and offers a practical and
reliable solution for object manipulation on soft robotic manipulation,
facilitating real-world implementation without prohibitive training demands.

</details>


### [245] [FCRF: Flexible Constructivism Reflection for Long-Horizon Robotic Task Planning with Large Language Models](https://arxiv.org/abs/2507.14975)
*Yufan Song,Jiatao Zhang,Zeng Gu,Qingmiao Liang,Tuocheng Hu,Wei Song,Shiqiang Zhu*

Main category: cs.RO

TL;DR: 提出了一种名为FCRF的灵活反思框架，通过导师-执行者架构提升LLMs在复杂任务中的自我反思能力，显著提高了性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLMs的自我反思机制不够灵活，限制了其在复杂任务中的错误纠正效果。

Method: 提出了FCRF框架，结合任务难度和历史经验进行灵活反思。

Result: 在仿真和实际环境中验证，FCRF显著提升了性能和反思灵活性。

Conclusion: FCRF为复杂任务中的自主错误纠正提供了有效解决方案。

Abstract: Autonomous error correction is critical for domestic robots to achieve
reliable execution of complex long-horizon tasks. Prior work has explored
self-reflection in Large Language Models (LLMs) for task planning error
correction; however, existing methods are constrained by inflexible
self-reflection mechanisms that limit their effectiveness. Motivated by these
limitations and inspired by human cognitive adaptation, we propose the Flexible
Constructivism Reflection Framework (FCRF), a novel Mentor-Actor architecture
that enables LLMs to perform flexible self-reflection based on task difficulty,
while constructively integrating historical valuable experience with failure
lessons. We evaluated FCRF on diverse domestic tasks through simulation in
AlfWorld and physical deployment in the real-world environment. Experimental
results demonstrate that FCRF significantly improves overall performance and
self-reflection flexibility in complex long-horizon robotic tasks.

</details>


### [246] [CPED-NCBFs: A Conformal Prediction for Expert Demonstration-based Neural Control Barrier Functions](https://arxiv.org/abs/2507.15022)
*Sumeadh MS,Kevin Dsouza,Ravi Prakash*

Main category: cs.RO

TL;DR: 本文提出了一种基于分形共形预测的验证策略（CPED-NCBFs），用于验证从专家演示中学习的神经控制屏障函数（NCBFs）的安全性。


<details>
  <summary>Details</summary>
Motivation: 现有验证方法（如SMT求解器、混合整数规划等）在验证NCBFs时往往引入宽松或保守的边界，难以确保其在整个状态空间中的安全性。

Method: 采用CPED-NCBFs方法，结合分形共形预测理论，对NCBFs进行验证。

Result: 在点质量系统和非完整模型上验证了该方法的有效性。

Conclusion: CPED-NCBFs方法能够更准确地验证NCBFs的安全性，克服了现有方法的局限性。

Abstract: Among the promising approaches to enforce safety in control systems, learning
Control Barrier Functions (CBFs) from expert demonstrations has emerged as an
effective strategy. However, a critical challenge remains: verifying that the
learned CBFs truly enforce safety across the entire state space. This is
especially difficult when CBF is represented using neural networks (NCBFs).
Several existing verification techniques attempt to address this problem
including SMT-based solvers, mixed-integer programming (MIP), and interval or
bound-propagation methods but these approaches often introduce loose,
conservative bounds. To overcome these limitations, in this work we use
CPED-NCBFs a split-conformal prediction based verification strategy to verify
the learned NCBF from the expert demonstrations. We further validate our method
on point mass systems and unicycle models to demonstrate the effectiveness of
the proposed theory.

</details>


### [247] [Touch in the Wild: Learning Fine-Grained Manipulation with a Portable Visuo-Tactile Gripper](https://arxiv.org/abs/2507.15062)
*Xinyue Zhu,Binghao Huang,Yunzhu Li*

Main category: cs.RO

TL;DR: 提出了一种集成触觉传感器的便携式夹持器，用于同步收集视觉和触觉数据，并提出了一种跨模态表示学习框架，提升了机器人操作的精确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有手持夹持器缺乏触觉反馈，而触觉反馈在精确操作中至关重要。

Method: 开发了便携式夹持器，集成触觉传感器，并提出跨模态表示学习框架，整合视觉和触觉信号。

Result: 在精细任务（如试管插入和移液操作）中表现出更高的准确性和鲁棒性。

Conclusion: 该框架通过多模态反馈支持更高效的策略学习，提升了机器人操作的精确性。

Abstract: Handheld grippers are increasingly used to collect human demonstrations due
to their ease of deployment and versatility. However, most existing designs
lack tactile sensing, despite the critical role of tactile feedback in precise
manipulation. We present a portable, lightweight gripper with integrated
tactile sensors that enables synchronized collection of visual and tactile data
in diverse, real-world, and in-the-wild settings. Building on this hardware, we
propose a cross-modal representation learning framework that integrates visual
and tactile signals while preserving their distinct characteristics. The
learning procedure allows the emergence of interpretable representations that
consistently focus on contacting regions relevant for physical interactions.
When used for downstream manipulation tasks, these representations enable more
efficient and effective policy learning, supporting precise robotic
manipulation based on multimodal feedback. We validate our approach on
fine-grained tasks such as test tube insertion and pipette-based fluid
transfer, demonstrating improved accuracy and robustness under external
disturbances. Our project page is available at
https://binghao-huang.github.io/touch_in_the_wild/ .

</details>


### [248] [Search-Based Autonomous Vehicle Motion Planning Using Game Theory](https://arxiv.org/abs/2507.15088)
*Pouya Panahandeh,Mohammad Pirani,Baris Fidan,Amir Khajepour*

Main category: cs.RO

TL;DR: 提出了一种基于搜索的交互式运动规划方案，用于自动驾驶车辆，采用博弈论方法。


<details>
  <summary>Details</summary>
Motivation: 传统方法将其他道路使用者视为静态障碍，而新方法将其视为智能体，以生成更真实的路径。

Method: 使用博弈论方法，考虑其他道路使用者为智能体，实现低计算时间的实时应用。

Result: 通过实验验证，性能优于现有运动规划技术。

Conclusion: 该方案适用于实时应用，并能生成更真实的路径。

Abstract: In this paper, we propose a search-based interactive motion planning scheme
for autonomous vehicles (AVs), using a game-theoretic approach. In contrast to
traditional search-based approaches, the newly developed approach considers
other road users (e.g. drivers and pedestrians) as intelligent agents rather
than static obstacles. This leads to the generation of a more realistic path
for the AV. Due to the low computational time, the proposed motion planning
scheme is implementable in real-time applications. The performance of the
developed motion planning scheme is compared with existing motion planning
techniques and validated through experiments using WATonoBus, an electrical
all-weather autonomous shuttle bus.

</details>


### [249] [Learning-Based Modeling of a Magnetically Steerable Soft Suction Device for Endoscopic Endonasal Interventions](https://arxiv.org/abs/2507.15155)
*Majid Roshanfar,Alex Zhang,Changyan He,Amir Hooshiar,Dale J. Podolsky,Thomas Looi,Eric Diller*

Main category: cs.RO

TL;DR: 提出了一种基于学习的磁控软吸引装置建模框架，用于内窥镜鼻内脑肿瘤切除，通过实验数据训练模型，实现了亚毫米级的形状预测精度。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够实时反馈形状的磁控软吸引装置，用于微创神经外科手术，解决传统物理模型简化假设的局限性。

Method: 使用3D打印技术制造微型设备，集成FBG传感器；通过实验数据训练神经网络和随机森林模型，比较性能。

Result: 随机森林模型表现更优，控制点预测均方根误差为0.087 mm，形状重建误差为0.064 mm。

Conclusion: 该学习框架为磁控软机器人在微创手术中的智能控制提供了新方法。

Abstract: This letter introduces a novel learning-based modeling framework for a
magnetically steerable soft suction device designed for endoscopic endonasal
brain tumor resection. The device is miniaturized (4 mm outer diameter, 2 mm
inner diameter, 40 mm length), 3D printed using biocompatible SIL 30 material,
and integrates embedded Fiber Bragg Grating (FBG) sensors for real-time shape
feedback. Shape reconstruction is represented using four Bezier control points,
enabling a compact and smooth model of the device's deformation. A data-driven
model was trained on 5,097 experimental samples covering a range of magnetic
field magnitudes (0-14 mT), actuation frequencies (0.2-1.0 Hz), and vertical
tip distances (90-100 mm), using both Neural Network (NN) and Random Forest
(RF) architectures. The RF model outperformed the NN across all metrics,
achieving a mean root mean square error of 0.087 mm in control point prediction
and a mean shape reconstruction error of 0.064 mm. Feature importance analysis
further revealed that magnetic field components predominantly influence distal
control points, while frequency and distance affect the base configuration.
This learning-based approach effectively models the complex nonlinear behavior
of hyperelastic soft robots under magnetic actuation without relying on
simplified physical assumptions. By enabling sub-millimeter shape prediction
accuracy and real-time inference, this work represents an advancement toward
the intelligent control of magnetically actuated soft robotic tools in
minimally invasive neurosurgery.

</details>


### [250] [CHADET: Cross-Hierarchical-Attention for Depth-Completion Using Unsupervised Lightweight Transformer](https://arxiv.org/abs/2507.15189)
*Kevin Christiansen Marsim,Jinwoo Jeon,Yeeun Kim,Myeongwoo Jeong,Hyun Myung*

Main category: cs.RO

TL;DR: 提出了一种轻量级深度补全网络CHADET，通过RGB图像和稀疏深度点生成精确的密集深度图，解决了现有方法在计算效率和准确性之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 深度信息对机器人任务至关重要，但现有方法在实时应用中存在计算效率和准确性不足的问题。

Method: 采用轻量级深度补全网络CHADET，结合深度块特征提取和基于Transformer的解码器，利用跨层次注意力模块优化图像特征。

Result: 在KITTI、NYUv2和VOID数据集上验证了方法的有效性，提升了深度图质量并减少了内存使用。

Conclusion: CHADET在保持轻量级的同时提高了深度补全的准确性和处理速度，适用于实时机器人任务。

Abstract: Depth information which specifies the distance between objects and current
position of the robot is essential for many robot tasks such as navigation.
Recently, researchers have proposed depth completion frameworks to provide
dense depth maps that offer comprehensive information about the surrounding
environment. However, existing methods show significant trade-offs between
computational efficiency and accuracy during inference. The substantial memory
and computational requirements make them unsuitable for real-time applications,
highlighting the need to improve the completeness and accuracy of depth
information while improving processing speed to enhance robot performance in
various tasks. To address these challenges, in this paper, we propose
CHADET(cross-hierarchical-attention depth-completion transformer), a
lightweight depth-completion network that can generate accurate dense depth
maps from RGB images and sparse depth points. For each pair, its feature is
extracted from the depthwise blocks and passed to the equally lightweight
transformer-based decoder. In the decoder, we utilize the novel
cross-hierarchical-attention module that refines the image features from the
depth information. Our approach improves the quality and reduces memory usage
of the depth map prediction, as validated in both KITTI, NYUv2, and VOID
datasets.

</details>


### [251] [VLM-UDMC: VLM-Enhanced Unified Decision-Making and Motion Control for Urban Autonomous Driving](https://arxiv.org/abs/2507.15266)
*Haichao Liu,Haoren Guo,Pei Liu,Benshan Ma,Yuxiang Zhang,Jun Ma,Tong Heng Lee*

Main category: cs.RO

TL;DR: 提出了一种基于视觉语言模型（VLM）的统一决策与运动控制框架VLM-UDMC，通过场景推理和风险感知提升自动驾驶的透明性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 模仿人类驾驶员的认知能力，确保自动驾驶在复杂城市环境中的安全性和有效性。

Method: 采用两级系统：上层慢系统通过RAG和基础模型处理多模态输入，生成风险感知；下层快系统通过轻量级LSTM进行实时轨迹预测。

Result: 仿真和实车实验验证了VLM-UDMC在提升驾驶决策和性能方面的有效性。

Conclusion: VLM-UDMC通过场景理解和注意力分解，显著改善了城市自动驾驶的表现。

Abstract: Scene understanding and risk-aware attentions are crucial for human drivers
to make safe and effective driving decisions. To imitate this cognitive ability
in urban autonomous driving while ensuring the transparency and
interpretability, we propose a vision-language model (VLM)-enhanced unified
decision-making and motion control framework, named VLM-UDMC. This framework
incorporates scene reasoning and risk-aware insights into an upper-level slow
system, which dynamically reconfigures the optimal motion planning for the
downstream fast system. The reconfiguration is based on real-time environmental
changes, which are encoded through context-aware potential functions. More
specifically, the upper-level slow system employs a two-step reasoning policy
with Retrieval-Augmented Generation (RAG), leveraging foundation models to
process multimodal inputs and retrieve contextual knowledge, thereby generating
risk-aware insights. Meanwhile, a lightweight multi-kernel decomposed LSTM
provides real-time trajectory predictions for heterogeneous traffic
participants by extracting smoother trend representations for short-horizon
trajectory prediction. The effectiveness of the proposed VLM-UDMC framework is
verified via both simulations and real-world experiments with a full-size
autonomous vehicle. It is demonstrated that the presented VLM-UDMC effectively
leverages scene understanding and attention decomposition for rational driving
decisions, thus improving the overall urban driving performance. Our
open-source project is available at https://github.com/henryhcliu/vlmudmc.git.

</details>


### [252] [RepILN: Reparameterized Inertial Localization Network](https://arxiv.org/abs/2507.15293)
*Shanshan Zhang,Tianshui Wen,Siyue Wang,Qi Zhang,Ziheng Zhou,Lingxiang Zheng,Yu Yang*

Main category: cs.RO

TL;DR: 提出了一种参数重配置的惯性定位网络，通过多分支训练提升特征提取能力，推理时转为单路径结构以提高效率，同时引入时间尺度稀疏注意力机制和门控卷积单元，显著提升了定位精度与模型紧凑性。


<details>
  <summary>Details</summary>
Motivation: 惯性定位因其成本效益和独立性在物联网设备中具有潜力，但现有方法因复杂网络架构和忽略长期依赖性而受限。

Method: 采用多分支训练结构转为单路径推理，引入时间尺度稀疏注意力机制和门控卷积单元。

Result: 在RoNIN数据集上，绝对轨迹误差降低2.59%，参数数量减少3.86%。

Conclusion: 该方法在精度与模型紧凑性间取得了良好平衡，适用于资源受限的物联网设备。

Abstract: Inertial localization is regarded as a promising positioning solution for
consumer-grade IoT devices due to its cost-effectiveness and independence from
external infrastructure. However, data-driven inertial localization methods
often rely on increasingly complex network architectures to improve accuracy,
which challenges the limited computational resources of IoT devices. Moreover,
these methods frequently overlook the importance of modeling long-term
dependencies in inertial measurements - a critical factor for accurate
trajectory reconstruction - thereby limiting localization performance. To
address these challenges, we propose a reparameterized inertial localization
network that uses a multi-branch structure during training to enhance feature
extraction. At inference time, this structure is transformed into an equivalent
single-path architecture to improve parameter efficiency. To further capture
long-term dependencies in motion trajectories, we introduce a temporal-scale
sparse attention mechanism that selectively emphasizes key trajectory segments
while suppressing noise. Additionally, a gated convolutional unit is
incorporated to effectively integrate long-range dependencies with local
fine-grained features. Extensive experiments on public benchmarks demonstrate
that our method achieves a favorable trade-off between accuracy and model
compactness. For example, on the RoNIN dataset, our approach reduces the
Absolute Trajectory Error (ATE) by 2.59% compared to RoNIN-ResNet while
reducing the number of parameters by 3.86%.

</details>


### [253] [Low-Latency Event-Based Velocimetry for Quadrotor Control in a Narrow Pipe](https://arxiv.org/abs/2507.15444)
*Leonard Bauersfeld,Davide Scaramuzza*

Main category: cs.RO

TL;DR: 该论文提出了一种基于实时流场测量的四旋翼无人机闭环控制系统，用于在狭窄管道中悬停和机动飞行。


<details>
  <summary>Details</summary>
Motivation: 解决四旋翼在狭窄管道中飞行时因气流扰动导致的稳定性问题。

Method: 开发了一种低延迟的事件型烟雾测速方法，结合基于循环卷积神经网络的扰动估计器和强化学习训练的控制器。

Result: 系统在管道横截面横向机动时能有效抵消瞬态气动效应，避免与管壁碰撞。

Conclusion: 该研究首次展示了基于实时流场测量的无人机闭环控制，为复杂气动环境中的飞行研究开辟了新方向。

Abstract: Autonomous quadrotor flight in confined spaces such as pipes and tunnels
presents significant challenges due to unsteady, self-induced aerodynamic
disturbances. Very recent advances have enabled flight in such conditions, but
they either rely on constant motion through the pipe to mitigate airflow
recirculation effects or suffer from limited stability during hovering. In this
work, we present the first closed-loop control system for quadrotors for
hovering in narrow pipes that leverages real-time flow field measurements. We
develop a low-latency, event-based smoke velocimetry method that estimates
local airflow at high temporal resolution. This flow information is used by a
disturbance estimator based on a recurrent convolutional neural network, which
infers force and torque disturbances in real time. The estimated disturbances
are integrated into a learning-based controller trained via reinforcement
learning. The flow-feedback control proves particularly effective during
lateral translation maneuvers in the pipe cross-section. There, the real-time
disturbance information enables the controller to effectively counteract
transient aerodynamic effects, thereby preventing collisions with the pipe
wall. To the best of our knowledge, this work represents the first
demonstration of an aerial robot with closed-loop control informed by real-time
flow field measurements. This opens new directions for research on flight in
aerodynamically complex environments. In addition, our work also sheds light on
the characteristic flow structures that emerge during flight in narrow,
circular pipes, providing new insights at the intersection of robotics and
fluid dynamics.

</details>


### [254] [The Emergence of Deep Reinforcement Learning for Path Planning](https://arxiv.org/abs/2507.15469)
*Thanh Thi Nguyen,Saeid Nahavandi,Imran Razzak,Dung Nguyen,Nhat Truong Pham,Quoc Viet Hung Nguyen*

Main category: cs.RO

TL;DR: 本文综述了路径规划领域的研究进展，包括传统方法和深度强化学习（DRL）的应用，重点分析了算法优缺点，并探讨了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 复杂动态环境中自主系统的需求增长，推动了智能路径规划方法的研究。

Method: 综述了传统图搜索、线性规划和进化计算方法，以及新兴的DRL技术，并分类比较了关键算法。

Result: 分析了不同方法在计算效率、可扩展性、适应性和鲁棒性方面的优劣。

Conclusion: 提出结合DRL与传统方法的混合路径规划是未来研究方向，以实现更强的适应性和可靠性。

Abstract: The increasing demand for autonomous systems in complex and dynamic
environments has driven significant research into intelligent path planning
methodologies. For decades, graph-based search algorithms, linear programming
techniques, and evolutionary computation methods have served as foundational
approaches in this domain. Recently, deep reinforcement learning (DRL) has
emerged as a powerful method for enabling autonomous agents to learn optimal
navigation strategies through interaction with their environments. This survey
provides a comprehensive overview of traditional approaches as well as the
recent advancements in DRL applied to path planning tasks, focusing on
autonomous vehicles, drones, and robotic platforms. Key algorithms across both
conventional and learning-based paradigms are categorized, with their
innovations and practical implementations highlighted. This is followed by a
thorough discussion of their respective strengths and limitations in terms of
computational efficiency, scalability, adaptability, and robustness. The survey
concludes by identifying key open challenges and outlining promising avenues
for future research. Special attention is given to hybrid approaches that
integrate DRL with classical planning techniques to leverage the benefits of
both learning-based adaptability and deterministic reliability, offering
promising directions for robust and resilient autonomous navigation.

</details>


### [255] [All-UWB SLAM Using UWB Radar and UWB AOA](https://arxiv.org/abs/2507.15474)
*Charith Premachandra,Achala Athukorala,U-Xuan Tan*

Main category: cs.RO

TL;DR: 论文提出了一种结合超宽带（UWB）雷达和到达角（AOA）测量的新方法，用于在视觉受限且特征匮乏的环境中提升SLAM的精度和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 在恶劣环境（如烟雾、灰尘）中，光学传感器（如LiDAR、相机）容易失效，而UWB雷达因其低频成分能穿透这些环境，成为SLAM的潜在解决方案。然而，现有UWB雷达方法依赖环境特征，限制了其在特征匮乏环境中的应用。

Method: 提出将UWB AOA测量引入UWB雷达SLAM系统，通过在特征匮乏区域动态部署UWB锚点-标签单元获取AOA数据。

Result: 实验结果表明，结合UWB AOA单元和UWB雷达能在视觉受限且特征匮乏的环境中实现SLAM。

Conclusion: 该方法克服了UWB AOA测量单元的局限性，为恶劣环境中的SLAM提供了有效解决方案。

Abstract: There has been a growing interest in autonomous systems designed to operate
in adverse conditions (e.g. smoke, dust), where the visible light spectrum
fails. In this context, Ultra-wideband (UWB) radar is capable of penetrating
through such challenging environmental conditions due to the lower frequency
components within its broad bandwidth. Therefore, UWB radar has emerged as a
potential sensing technology for Simultaneous Localization and Mapping (SLAM)
in vision-denied environments where optical sensors (e.g. LiDAR, Camera) are
prone to failure. Existing approaches involving UWB radar as the primary
exteroceptive sensor generally extract features in the environment, which are
later initialized as landmarks in a map. However, these methods are constrained
by the number of distinguishable features in the environment. Hence, this paper
proposes a novel method incorporating UWB Angle of Arrival (AOA) measurements
into UWB radar-based SLAM systems to improve the accuracy and scalability of
SLAM in feature-deficient environments. The AOA measurements are obtained using
UWB anchor-tag units which are dynamically deployed by the robot in featureless
areas during mapping of the environment. This paper thoroughly discusses
prevailing constraints associated with UWB AOA measurement units and presents
solutions to overcome them. Our experimental results show that integrating UWB
AOA units with UWB radar enables SLAM in vision-denied feature-deficient
environments.

</details>


### [256] [The Constitutional Controller: Doubt-Calibrated Steering of Compliant Agents](https://arxiv.org/abs/2507.15478)
*Simon Kohaut,Felix Divo,Navid Hamid,Benedict Flade,Julian Eggert,Devendra Singh Dhami,Kristian Kersting*

Main category: cs.RO

TL;DR: 论文提出了一种结合神经符号系统的Constitutional Controller (CoCo)框架，通过深度概率逻辑程序增强自主代理的安全性和可靠性，并在真实世界空中交通研究中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决自主代理在不确定环境中可靠且合规行为的挑战。

Method: 结合概率符号推理模型与深度学习方法，提出CoCo框架，并引入基于怀疑特征的自我怀疑概念。

Result: 在真实世界空中交通研究中，CoCo成功帮助智能系统学习适当怀疑并安全导航。

Conclusion: 神经符号系统为解决自主代理的安全和可靠性问题提供了有效方案。

Abstract: Ensuring reliable and rule-compliant behavior of autonomous agents in
uncertain environments remains a fundamental challenge in modern robotics. Our
work shows how neuro-symbolic systems, which integrate probabilistic, symbolic
white-box reasoning models with deep learning methods, offer a powerful
solution to this challenge. This enables the simultaneous consideration of
explicit rules and neural models trained on noisy data, combining the strength
of structured reasoning with flexible representations. To this end, we
introduce the Constitutional Controller (CoCo), a novel framework designed to
enhance the safety and reliability of agents by reasoning over deep
probabilistic logic programs representing constraints such as those found in
shared traffic spaces. Furthermore, we propose the concept of self-doubt,
implemented as a probability density conditioned on doubt features such as
travel velocity, employed sensors, or health factors. In a real-world aerial
mobility study, we demonstrate CoCo's advantages for intelligent autonomous
systems to learn appropriate doubts and navigate complex and uncertain
environments safely and compliantly.

</details>


### [257] [Robots for Kiwifruit Harvesting and Pollination](https://arxiv.org/abs/2507.15484)
*Jamie Bell*

Main category: cs.RO

TL;DR: 该研究开发了用于猕猴桃果园的移动机器人，实现了定向花粉喷洒和自动化采摘，改进了果实采摘和花粉喷洒的效率。


<details>
  <summary>Details</summary>
Motivation: 解决猕猴桃果园中自动化采摘和人工授粉的挑战，提高效率和覆盖率。

Method: 设计了多种猕猴桃采摘机制，并测试了其中一种；使用喷杆喷洒花粉；利用2D和3D激光雷达进行导航；测试了计算机视觉算法。

Result: 采摘机制覆盖了80%以上的果实，优于之前的70%；花粉喷洒速度达1.4 m/s；3D激光雷达导航系统完成了30公里以上的自动驾驶测试。

Conclusion: 研究成功开发了高效的猕猴桃采摘和花粉喷洒系统，为果园自动化提供了可行方案。

Abstract: This research was a part of a project that developed mobile robots that
performed targeted pollen spraying and automated harvesting in pergola
structured kiwifruit orchards. Multiple kiwifruit detachment mechanisms were
designed and field testing of one of the concepts showed that the mechanism
could reliably pick kiwifruit. Furthermore, this kiwifruit detachment mechanism
was able to reach over 80 percent of fruit in the cluttered kiwifruit canopy,
whereas the previous state of the art mechanism was only able to reach less
than 70 percent of the fruit. Artificial pollination was performed by detecting
flowers and then spraying pollen in solution onto the detected flowers from a
line of sprayers on a boom, while driving at up to 1.4 ms-1. In addition, the
height of the canopy was measured and the spray boom was moved up and down to
keep the boom close enough to the flowers for the spray to reach the flowers,
while minimising collisions with the canopy. Mobile robot navigation was
performed using a 2D lidar in apple orchards and vineyards. Lidar navigation in
kiwifruit orchards was more challenging because the pergola structure only
provides a small amount of data for the direction of rows, compared to the
amount of data from the overhead canopy, the undulating ground and other
objects in the orchards. Multiple methods are presented here for extracting
structure defining features from 3D lidar data in kiwifruit orchards. In
addition, a 3D lidar navigation system -- which performed row following, row
end detection and row end turns -- was tested for over 30 km of autonomous
driving in kiwifruit orchards. Computer vision algorithms for row detection and
row following were also tested. The computer vision algorithm worked as well as
the 3D lidar row following method in testing.

</details>


### [258] [GR-3 Technical Report](https://arxiv.org/abs/2507.15493)
*Chilam Cheang,Sijin Chen,Zhongren Cui,Yingdong Hu,Liqun Huang,Tao Kong,Hang Li,Yifeng Li,Yuxiao Liu,Xiao Ma,Hao Niu,Wenxuan Ou,Wanli Peng,Zeyu Ren,Haixin Shi,Jiawen Tian,Hongtao Wu,Xin Xiao,Yuyang Xiao,Jiafeng Xu,Yichu Yang*

Main category: cs.RO

TL;DR: GR-3是一种大规模视觉-语言-动作模型，展示了在新对象、环境和抽象指令上的强大泛化能力，并能高效微调。结合ByteMini机器人，GR-3在多种任务中超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 推动通用机器人策略的发展，使其能够适应多样化任务并辅助人类日常生活。

Method: 通过多模态训练（包括网络规模视觉-语言数据、VR设备收集的人类轨迹数据和机器人轨迹数据）开发GR-3模型，并结合ByteMini机器人。

Result: GR-3在多种复杂任务中表现优异，超越了现有基准方法π₀。

Conclusion: GR-3为构建通用机器人迈出了重要一步，展示了其在现实任务中的潜力。

Abstract: We report our recent progress towards building generalist robot policies, the
development of GR-3. GR-3 is a large-scale vision-language-action (VLA) model.
It showcases exceptional capabilities in generalizing to novel objects,
environments, and instructions involving abstract concepts. Furthermore, it can
be efficiently fine-tuned with minimal human trajectory data, enabling rapid
and cost-effective adaptation to new settings. GR-3 also excels in handling
long-horizon and dexterous tasks, including those requiring bi-manual
manipulation and mobile movement, showcasing robust and reliable performance.
These capabilities are achieved through a multi-faceted training recipe that
includes co-training with web-scale vision-language data, efficient fine-tuning
from human trajectory data collected via VR devices, and effective imitation
learning with robot trajectory data. In addition, we introduce ByteMini, a
versatile bi-manual mobile robot designed with exceptional flexibility and
reliability, capable of accomplishing a wide range of tasks when integrated
with GR-3. Through extensive real-world experiments, we show GR-3 surpasses the
state-of-the-art baseline method, $\pi_0$, on a wide variety of challenging
tasks. We hope GR-3 can serve as a step towards building generalist robots
capable of assisting humans in daily life.

</details>


### [259] [CLEVER: Stream-based Active Learning for Robust Semantic Perception from Human Instructions](https://arxiv.org/abs/2507.15499)
*Jongseok Lee,Timo Birr,Rudolph Triebel,Tamim Asfour*

Main category: cs.RO

TL;DR: CLEVER是一种基于深度神经网络的主动学习系统，通过在线适应人类指令来提升语义感知的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决深度神经网络在流数据语义感知任务中的失败问题，通过人类支持在线适应模型。

Method: 采用贝叶斯框架编码领域知识作为先验，设计了一个满足多需求的系统。

Result: 通过用户验证研究和实验，证明了系统在真实机器人上的有效性，提升了语义感知的鲁棒性。

Conclusion: CLEVER首次实现了真实机器人上的流式主动学习，为提升DNN语义感知的鲁棒性提供了实践证据。

Abstract: We propose CLEVER, an active learning system for robust semantic perception
with Deep Neural Networks (DNNs). For data arriving in streams, our system
seeks human support when encountering failures and adapts DNNs online based on
human instructions. In this way, CLEVER can eventually accomplish the given
semantic perception tasks. Our main contribution is the design of a system that
meets several desiderata of realizing the aforementioned capabilities. The key
enabler herein is our Bayesian formulation that encodes domain knowledge
through priors. Empirically, we not only motivate CLEVER's design but further
demonstrate its capabilities with a user validation study as well as
experiments on humanoid and deformable objects. To our knowledge, we are the
first to realize stream-based active learning on a real robot, providing
evidence that the robustness of the DNN-based semantic perception can be
improved in practice. The project website can be accessed at
https://sites.google.com/view/thecleversystem.

</details>


### [260] [Estimation of Payload Inertial Parameters from Human Demonstrations by Hand Guiding](https://arxiv.org/abs/2507.15604)
*Johannes Hartwig,Philipp Lienhardt,Dominik Henrich*

Main category: cs.RO

TL;DR: 论文提出了一种方法，通过利用非接触运动部分估计机器人工具的负载惯性参数（PIP），从而无需专用校准即可编程接触运动，提高了非专家用户的操作效率。


<details>
  <summary>Details</summary>
Motivation: 随着协作机器人（cobot）的普及，如何让非编程专家高效操作成为关键。传统方法需要用户了解PIP，限制了工具的灵活更换。

Method: 利用任务中的非接触运动部分，通过已有估计技术计算PIP，避免专用校准。

Result: 实验显示，负载质量估计准确，但质心和惯性张量受噪声和激励不足影响。

Conclusion: 该方法可行，但需足够负载加速度以提高估计精度。

Abstract: As the availability of cobots increases, it is essential to address the needs
of users with little to no programming knowledge to operate such systems
efficiently. Programming concepts often use intuitive interaction modalities,
such as hand guiding, to address this. When programming in-contact motions,
such frameworks require knowledge of the robot tool's payload inertial
parameters (PIP) in addition to the demonstrated velocities and forces to
ensure effective hybrid motion-force control. This paper aims to enable
non-expert users to program in-contact motions more efficiently by eliminating
the need for a dedicated PIP calibration, thereby enabling flexible robot tool
changes. Since demonstrated tasks generally also contain motions with
non-contact, our approach uses these parts to estimate the robot's PIP using
established estimation techniques. The results show that the estimation of the
payload's mass is accurate, whereas the center of mass and the inertia tensor
are affected by noise and a lack of excitation. Overall, these findings show
the feasibility of PIP estimation during hand guiding but also highlight the
need for sufficient payload accelerations for an accurate estimation.

</details>


### [261] [A Universal Vehicle-Trailer Navigation System with Neural Kinematics and Online Residual Learning](https://arxiv.org/abs/2507.15607)
*Yanbo Chen,Yunzhe Tan,Yaojia Wang,Zhengzhe Xu,Junbo Tan,Xueqian Wang*

Main category: cs.RO

TL;DR: 提出了一种新型通用车辆-拖车导航系统，结合混合运动学模型和在线学习模块，提升复杂环境下的导航性能。


<details>
  <summary>Details</summary>
Motivation: 车辆-拖车系统在机场、超市等环境中的自主导航需求迫切，但传统建模方法难以适应带脚轮的拖车。

Method: 采用混合运动学模型（车辆部分基于经典非完整约束，拖车部分基于神经网络）和在线残差学习模块，结合模型预测控制框架。

Result: 通过多种拖车和负载条件的实际实验验证，系统表现稳健，无需手动调整或拖车特定校准。

Conclusion: 该方法显著提升了车辆-拖车系统的导航准确性和安全性，适用于多样化场景。

Abstract: Autonomous navigation of vehicle-trailer systems is crucial in environments
like airports, supermarkets, and concert venues, where various types of
trailers are needed to navigate with different payloads and conditions.
However, accurately modeling such systems remains challenging, especially for
trailers with castor wheels. In this work, we propose a novel universal
vehicle-trailer navigation system that integrates a hybrid nominal kinematic
model--combining classical nonholonomic constraints for vehicles and neural
network-based trailer kinematics--with a lightweight online residual learning
module to correct real-time modeling discrepancies and disturbances.
Additionally, we develop a model predictive control framework with a weighted
model combination strategy that improves long-horizon prediction accuracy and
ensures safer motion planning. Our approach is validated through extensive
real-world experiments involving multiple trailer types and varying payload
conditions, demonstrating robust performance without manual tuning or
trailer-specific calibration.

</details>


### [262] [Optimizing Force Signals from Human Demonstrations of In-Contact Motions](https://arxiv.org/abs/2507.15608)
*Johannes Hartwig,Fabian Viessmann,Dominik Henrich*

Main category: cs.RO

TL;DR: 论文探讨了如何优化力信号以更好地反映人类演示意图，比较了不同信号滤波方法，并提出了一种处理首次接触偏差的峰值检测方法。


<details>
  <summary>Details</summary>
Motivation: 由于非专家用户通过动觉引导编程机器人时输入信号不精确且噪声多，直接复制或用于机器学习时效果不佳，因此需要优化信号以更准确地反映人类意图。

Method: 比较了不同信号滤波方法，并提出了一种峰值检测方法处理首次接触偏差。通过专用误差标准评估方法，并分析关键参数对滤波方法的影响。

Result: 针对单个运动，误差标准可提高多达20%。

Conclusion: 提出的方法能提升机器人编程的可用性及人机交互效果。

Abstract: For non-robot-programming experts, kinesthetic guiding can be an intuitive
input method, as robot programming of in-contact tasks is becoming more
prominent. However, imprecise and noisy input signals from human demonstrations
pose problems when reproducing motions directly or using the signal as input
for machine learning methods. This paper explores optimizing force signals to
correspond better to the human intention of the demonstrated signal. We compare
different signal filtering methods and propose a peak detection method for
dealing with first-contact deviations in the signal. The evaluation of these
methods considers a specialized error criterion between the input and the
human-intended signal. In addition, we analyze the critical parameters'
influence on the filtering methods. The quality for an individual motion could
be increased by up to \SI{20}{\percent} concerning the error criterion. The
proposed contribution can improve the usability of robot programming and the
interaction between humans and robots.

</details>


### [263] [EMP: Executable Motion Prior for Humanoid Robot Standing Upper-body Motion Imitation](https://arxiv.org/abs/2507.15649)
*Haocheng Xu,Haodong Zhang,Zhenghan Chen,Rong Xiong*

Main category: cs.RO

TL;DR: 提出了一种基于强化学习的框架，使人形机器人模仿人类上半身动作并保持整体稳定性。


<details>
  <summary>Details</summary>
Motivation: 研究人形机器人在执行任务时的稳定站立问题，尤其是上半身动作对整体稳定性的影响。

Method: 设计了一个重定向网络生成大规模上半身动作数据集，训练强化学习策略，并引入可执行运动先验（EMP）模块调整目标动作。

Result: 通过仿真和实际测试验证了框架的实用性。

Conclusion: 该框架有效提升了人形机器人在模仿人类动作时的稳定性。

Abstract: To support humanoid robots in performing manipulation tasks, it is essential
to study stable standing while accommodating upper-body motions. However, the
limited controllable range of humanoid robots in a standing position affects
the stability of the entire body. Thus we introduce a reinforcement learning
based framework for humanoid robots to imitate human upper-body motions while
maintaining overall stability. Our approach begins with designing a retargeting
network that generates a large-scale upper-body motion dataset for training the
reinforcement learning (RL) policy, which enables the humanoid robot to track
upper-body motion targets, employing domain randomization for enhanced
robustness. To avoid exceeding the robot's execution capability and ensure
safety and stability, we propose an Executable Motion Prior (EMP) module, which
adjusts the input target movements based on the robot's current state. This
adjustment improves standing stability while minimizing changes to motion
amplitude. We evaluate our framework through simulation and real-world tests,
demonstrating its practical applicability.

</details>


### [264] [Data-Driven MPC with Data Selection for Flexible Cable-Driven Robotic Arms](https://arxiv.org/abs/2507.15677)
*Huayue Liang,Yanbo Chen,Hongyang Cheng,Yanzhao Yu,Shoujie Li,Junbo Tan,Xueqian Wang,Long Zeng*

Main category: cs.RO

TL;DR: 本文提出了一种基于输入输出数据的模型预测控制（MPC）方法，用于提高柔性电缆驱动机械臂（FCRA）的控制精度，无需物理模型。通过数据选择算法（DSA）优化计算效率，并在实验中验证了其性能。


<details>
  <summary>Details</summary>
Motivation: 柔性电缆驱动机械臂（FCRAs）的电缆特性（如弹性、迟滞和摩擦）导致建模和控制困难，需要一种不依赖物理模型的高精度控制方法。

Method: 1. 基于输入输出数据构建隐式模型，并集成到MPC框架中；2. 引入数据选择算法（DSA）优化数据，减少计算时间；3. 通过仿真研究超参数对跟踪误差的影响。

Result: 实验验证显示，平均定位精度约为2.070毫米，跟踪误差为0.541度，优于PID方法的1.418度。计算时间每步减少约80%。

Conclusion: 提出的MPC方法显著提高了FCRA的控制精度和计算效率，适用于实际应用。

Abstract: Flexible cable-driven robotic arms (FCRAs) offer dexterous and compliant
motion. Still, the inherent properties of cables, such as resilience,
hysteresis, and friction, often lead to particular difficulties in modeling and
control. This paper proposes a model predictive control (MPC) method that
relies exclusively on input-output data, without a physical model, to improve
the control accuracy of FCRAs. First, we develop an implicit model based on
input-output data and integrate it into an MPC optimization framework. Second,
a data selection algorithm (DSA) is introduced to filter the data that best
characterize the system, thereby reducing the solution time per step to
approximately 4 ms, which is an improvement of nearly 80%. Lastly, the
influence of hyperparameters on tracking error is investigated through
simulation. The proposed method has been validated on a real FCRA platform,
including five-point positioning accuracy tests, a five-point response tracking
test, and trajectory tracking for letter drawing. The results demonstrate that
the average positioning accuracy is approximately 2.070 mm. Moreover, compared
to the PID method with an average tracking error of 1.418{\deg}, the proposed
method achieves an average tracking error of 0.541{\deg}.

</details>


### [265] [Strong, Accurate, and Low-Cost Robot Manipulator](https://arxiv.org/abs/2507.15693)
*Georges Chebly,Spencer Little,Nisal Perera,Aliya Abedeen,Ken Suzuki,Donghyun Kim*

Main category: cs.RO

TL;DR: Forte是一款完全3D打印的6自由度机械臂，以低成本（<215美元）实现接近工业级性能（0.63 kg负载，0.467 m工作范围，亚毫米级重复精度），适用于教育和AI实验。


<details>
  <summary>Details</summary>
Motivation: 解决低成本教育机械臂性能不足的问题，推动其在教学和科研中的广泛应用。

Method: 采用低成本机械设计，包括基于绞盘的电缆驱动、同步带、简单张紧机构和轻量化3D打印结构，结合拓扑优化提升刚度，并通过精心设计的传动系统减少回差。

Result: 实验验证表明，Forte具有高重复精度和负载能力，性能优于现有低成本机械臂。

Conclusion: Forte为教学和高级机器人研究提供了一个高性能且经济实惠的机器人平台。

Abstract: This paper presents Forte, a fully 3D-printable, 6-DoF robotic arm designed
to achieve near industrial-grade performance - 0.63 kg payload, 0.467 m reach,
and sub-millimeter repeatability - at a material cost under $215. As an
accessible robot for broad applications across classroom education to AI
experiments, Forte pushes forward the performance limitations of existing
low-cost educational arms. We introduce a cost-effective mechanical design that
combines capstan-based cable drives, timing belts, simple tensioning
mechanisms, and lightweight 3D-printed structures, along with topology
optimization for structural stiffness. Through careful drivetrain engineering,
we minimize backlash and maintain control fidelity without relying on
high-power electronics or expensive manufacturing processes. Experimental
validation demonstrates that Forte achieves high repeatability and load
capacity, offering a compelling robotic platform for both classroom instruction
and advanced robotics research.

</details>


### [266] [Selective Densification for Rapid Motion Planning in High Dimensions with Narrow Passages](https://arxiv.org/abs/2507.15710)
*Lu Huang,Lingxiao Meng,Jiankun Wang,Xingjian Jing*

Main category: cs.RO

TL;DR: 提出了一种高效的多分辨率采样规划框架，解决了复杂配置空间中采样效率低的问题。


<details>
  <summary>Details</summary>
Motivation: 现有采样规划算法在复杂配置空间中效率低，且启发式方法缺乏通用性或需要大量训练。

Method: 通过多分辨率采样和稀疏样本偏置，动态调整采样密度，实现高效规划。

Result: 在多种配置空间和机器人实验中，性能优于现有方法。

Conclusion: 该方法在保持规划速度和完整性的同时，显著提升了复杂环境中的规划效率。

Abstract: Sampling-based algorithms are widely used for motion planning in
high-dimensional configuration spaces. However, due to low sampling efficiency,
their performance often diminishes in complex configuration spaces with narrow
corridors. Existing approaches address this issue using handcrafted or learned
heuristics to guide sampling toward useful regions. Unfortunately, these
strategies often lack generalizability to various problems or require extensive
prior training. In this paper, we propose a simple yet efficient sampling-based
planning framework along with its bidirectional version that overcomes these
issues by integrating different levels of planning granularity. Our approach
probes configuration spaces with uniform random samples at varying resolutions
and explores these multi-resolution samples online with a bias towards sparse
samples when traveling large free configuration spaces. By seamlessly
transitioning between sparse and dense samples, our approach can navigate
complex configuration spaces while maintaining planning speed and completeness.
The simulation results demonstrate that our approach outperforms several
state-of-the-art sampling-based planners in $\mathbb{SE}(2)$, $\mathbb{SE}(3)$,
and $\mathbb{R}^{14}$ with challenging terrains. Furthermore, experiments
conducted with the Franka Emika Panda robot operating in a constrained
workspace provide additional evidence of the superiority of the proposed
method.

</details>


### [267] [DiffPF: Differentiable Particle Filtering with Generative Sampling via Conditional Diffusion Models](https://arxiv.org/abs/2507.15716)
*Ziyu Wan,Lin Zhao*

Main category: cs.RO

TL;DR: DiffPF是一种可微分粒子滤波器，利用扩散模型进行动态系统状态估计，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统可微分粒子滤波器依赖预定义或低容量提议分布，限制了性能。DiffPF旨在通过扩散模型学习灵活的后验采样器，提升状态估计精度。

Method: DiffPF通过扩散模型在预测粒子和当前观测条件下学习后验采样器，实现高维、多模态分布的精确采样。

Result: 在仿真和真实任务中表现优异，多模态全局定位任务精度提升82.8%，KITTI视觉里程计任务提升26%。

Conclusion: DiffPF首次将条件扩散模型融入粒子滤波，显著提升后验采样质量和状态估计性能。

Abstract: This paper proposes DiffPF, a differentiable particle filter that leverages
diffusion models for state estimation in dynamic systems. Unlike conventional
differentiable particle filters, which require importance weighting and
typically rely on predefined or low-capacity proposal distributions. DiffPF
learns a flexible posterior sampler by conditioning a diffusion model on
predicted particles and the current observation. This enables accurate,
equally-weighted sampling from complex, high-dimensional, and multimodal
filtering distributions. We evaluate DiffPF across a range of scenarios,
including both unimodal and highly multimodal distributions, and test it on
simulated as well as real-world tasks, where it consistently outperforms
existing filtering baselines. In particular, DiffPF achieves an 82.8%
improvement in estimation accuracy on a highly multimodal global localization
benchmark, and a 26% improvement on the real-world KITTI visual odometry
benchmark, compared to state-of-the-art differentiable filters. To the best of
our knowledge, DiffPF is the first method to integrate conditional diffusion
models into particle filtering, enabling high-quality posterior sampling that
produces more informative particles and significantly improves state
estimation.

</details>


### [268] [Gaze-supported Large Language Model Framework for Bi-directional Human-Robot Interaction](https://arxiv.org/abs/2507.15729)
*Jens V. Rüppel,Andrey Rudenko,Tim Schreiter,Martin Magnusson,Achim J. Lilienthal*

Main category: cs.RO

TL;DR: 论文提出了一种基于LLM的辅助机器人交互系统，通过多模态输入（如视线和语音）支持动态用户任务，提升了适应性和用户体验，但可能产生冗余输出。


<details>
  <summary>Details</summary>
Motivation: 解决双向、多模态和上下文感知的协作任务支持问题，提升人机交互的灵活性和适应性。

Method: 设计了一种模块化、可转移的系统，结合多视觉输入和实时语言交互状态表示，支持动态任务。

Result: 实验表明，基于LLM的系统在适应性和用户参与度上略有提升，但可能产生冗余输出；脚本化管道更适合简单任务。

Conclusion: LLM方法在复杂任务中表现更好，但需优化冗余问题；脚本化方法适合简单任务。

Abstract: The rapid development of Large Language Models (LLMs) creates an exciting
potential for flexible, general knowledge-driven Human-Robot Interaction (HRI)
systems for assistive robots. Existing HRI systems demonstrate great progress
in interpreting and following user instructions, action generation, and robot
task solving. On the other hand, bi-directional, multi-modal, and context-aware
support of the user in collaborative tasks still remains an open challenge. In
this paper, we present a gaze- and speech-informed interface to the assistive
robot, which is able to perceive the working environment from multiple vision
inputs and support the dynamic user in their tasks. Our system is designed to
be modular and transferable to adapt to diverse tasks and robots, and it is
capable of real-time use of language-based interaction state representation and
fast on board perception modules. Its development was supported by multiple
public dissemination events, contributing important considerations for improved
robustness and user experience. Furthermore, in two lab studies, we compare the
performance and user ratings of our system with those of a traditional scripted
HRI pipeline. Our findings indicate that an LLM-based approach enhances
adaptability and marginally improves user engagement and task execution metrics
but may produce redundant output, while a scripted pipeline is well suited for
more straightforward tasks.

</details>


### [269] [Interleaved LLM and Motion Planning for Generalized Multi-Object Collection in Large Scene Graphs](https://arxiv.org/abs/2507.15782)
*Ruochu Yang,Yu Zhou,Fumin Zhang,Mengxue Hou*

Main category: cs.RO

TL;DR: 提出了一种新型的Inter-LLM算法，结合LLM和运动规划，解决家庭机器人多目标收集问题，性能提升30%。


<details>
  <summary>Details</summary>
Motivation: 家庭机器人缺乏人类智能，尤其在开放集对象操作和大环境导航方面。为解决这一问题，研究多目标收集问题。

Method: 设计多模态动作成本相似性函数，结合LLM和运动规划，优化长期任务规划。

Result: 仿真实验显示，算法在任务完成率、成功率和成本方面比现有方法提升30%。

Conclusion: Inter-LLM算法在长期任务规划中表现出色，平衡了质量和效率。

Abstract: Household robots have been a longstanding research topic, but they still lack
human-like intelligence, particularly in manipulating open-set objects and
navigating large environments efficiently and accurately. To push this
boundary, we consider a generalized multi-object collection problem in large
scene graphs, where the robot needs to pick up and place multiple objects
across multiple locations in a long mission of multiple human commands. This
problem is extremely challenging since it requires long-horizon planning in a
vast action-state space under high uncertainties. To this end, we propose a
novel interleaved LLM and motion planning algorithm Inter-LLM. By designing a
multimodal action cost similarity function, our algorithm can both reflect the
history and look into the future to optimize plans, striking a good balance of
quality and efficiency. Simulation experiments demonstrate that compared with
latest works, our algorithm improves the overall mission performance by 30% in
terms of fulfilling human commands, maximizing mission success rates, and
minimizing mission costs.

</details>


### [270] [Look, Focus, Act: Efficient and Robust Robot Learning via Human Gaze and Foveated Vision Transformers](https://arxiv.org/abs/2507.15833)
*Ian Chuang,Andrew Lee,Dechen Gao,Jinyu Zou,Iman Soltani*

Main category: cs.RO

TL;DR: 论文探讨了将人类主动注视机制融入机器人视觉系统，以提高效率和性能。通过结合眼动数据和机器人演示，提出了一种基于ViTs的注视引导方法，显著减少计算量并提升任务表现。


<details>
  <summary>Details</summary>
Motivation: 人类视觉通过注视主动引导注意力，而机器人通常被动处理图像。研究旨在通过模拟人类注视机制提升机器人视觉系统的效率和性能。

Method: 提出了一种基于ViTs的注视引导框架，结合眼动数据和机器人演示，采用两种方法：两阶段模型和端到端联合预测。

Result: 方法显著减少了计算量，提高了高精度任务的性能和对未知干扰的鲁棒性。

Conclusion: 人类视觉机制为机器人视觉系统提供了有效的归纳偏置，未来可进一步优化注视预测和任务适应性。

Abstract: Human vision is a highly active process driven by gaze, which directs
attention and fixation to task-relevant regions and dramatically reduces visual
processing. In contrast, robot learning systems typically rely on passive,
uniform processing of raw camera images. In this work, we explore how
incorporating human-like active gaze into robotic policies can enhance both
efficiency and performance. We build on recent advances in foveated image
processing and apply them to an Active Vision robot system that emulates both
human head movement and eye tracking. Extending prior work on the AV-ALOHA
robot simulation platform, we introduce a framework for simultaneously
collecting eye-tracking data and robot demonstrations from a human operator as
well as a simulation benchmark and dataset for training robot policies that
incorporate human gaze. Given the widespread use of Vision Transformers (ViTs)
in robot learning, we integrate gaze information into ViTs using a foveated
patch tokenization scheme inspired by recent work in image segmentation.
Compared to uniform patch tokenization, this significantly reduces the number
of tokens-and thus computation-without sacrificing visual fidelity near regions
of interest. We also explore two approaches to gaze imitation and prediction
from human data. The first is a two-stage model that predicts gaze to guide
foveation and action; the second integrates gaze into the action space,
allowing the policy to jointly predict gaze and actions end-to-end. Our results
show that our method for foveated robot vision not only drastically reduces
computational overhead, but also improves performance for high precision tasks
and robustness to unseen distractors. Together, these findings suggest that
human-inspired visual processing offers a useful inductive bias for robotic
vision systems. https://ian-chuang.github.io/gaze-av-aloha/

</details>
